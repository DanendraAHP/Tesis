{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.finetuner import FineTuner\n",
    "from src.preprocessor import Preprocessor\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    #BartForConditionalGeneration,\n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainingArguments\n",
    ")\n",
    "from datasets import load_dataset\n",
    "#from indobenchmark import IndoNLGTokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constant\n",
    "max_length = 30\n",
    "text_col = 'content'\n",
    "label_col = 'postprocess_quintuplet'\n",
    "preprocess_type = 'p02'\n",
    "experiment_type = 'p22'\n",
    "SAVE_PATH = f'../models/{experiment_type}_quintuplet'\n",
    "PRETRAINED_MODEL = \"../models/pt-indot5-MLM_TA_PT\"#\"indobenchmark/indobart-v2\"#\"Wikidepia/IndoT5-base\"#\"../models/pt-indot5-MLM_PT\"  \n",
    "TOKENIZER_PATH = \"Wikidepia/IndoT5-base\" #\"indobenchmark/indobart-v2\"\n",
    "DATA_PATH = '../Data/quintuplet/quintuplet_postprocessed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "#tokenizer = IndoNLGTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "preprocessor = Preprocessor(preprocess_type, tokenizer, max_length, text_col, label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/danendra/.cache/huggingface/datasets/csv/default-7c3f713988208aa5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 399.23it/s]\n",
      "Loading cached split indices for dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-7c3f713988208aa5\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-06cdaa4abbd48a43.arrow and C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-7c3f713988208aa5\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-475e0560816dc728.arrow\n",
      "Loading cached processed dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-7c3f713988208aa5\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-294dd2bf963c7f67.arrow\n",
      "Loading cached processed dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-7c3f713988208aa5\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-db2c3864f6d8f691.arrow\n"
     ]
    }
   ],
   "source": [
    "# raw_dataset = load_dataset('csv', data_files={\n",
    "#     'train' : f'{DATA_PATH}_train.csv',\n",
    "#     'test' : f'{DATA_PATH}_test.csv',\n",
    "#     'val' : f'{DATA_PATH}_val.csv'\n",
    "# })\n",
    "raw_dataset = load_dataset('csv', data_files=DATA_PATH)\n",
    "#raw_dataset = raw_dataset.filter(lambda x: x['is_comparative']==False)\n",
    "splitted_dataset = raw_dataset['train'].train_test_split(test_size=100, seed=42)\n",
    "tokenized_dataset = splitted_dataset.map(preprocessor.preprocess_dataset, batched=True, remove_columns=raw_dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1894\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_labels = []\n",
    "len_inputs = []\n",
    "for i in range(len(tokenized_dataset['train'])):\n",
    "    len_labels.append(len(tokenized_dataset['train'][i]['labels']))\n",
    "    len_inputs.append(len(tokenized_dataset['train'][i]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97.55227032734952, 30.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len_labels)/len(len_labels), sum(len_inputs)/len(len_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tapi enaknya akun baru Shopee itu belum ada biaya adminnya ðŸ˜‚ meskipun masih nyeseq ga bisa dibuka https://t.co/3pQxvTTlnI'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_dataset['train']['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tapi enak akun baru shope itu belum ada biaya adminya meski masih nyeseq ga bisa buka</s><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_dataset['train']['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(shopee,akun baru shopee,belum ada biaya adminnya,positive,payment)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_dataset['train']['labels'][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import Seq2SeqTrainer\n",
    "# from transformers import DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(PRETRAINED_MODEL)\n",
    "#model = BartForConditionalGeneration.from_pretrained(PRETRAINED_MODEL)\n",
    "#model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "# trainer = Seq2SeqTrainer(\n",
    "#     model,\n",
    "#     training_args,\n",
    "#     train_dataset=tokenized_dataset[\"train\"],\n",
    "#     eval_dataset=tokenized_dataset[\"test\"],\n",
    "#     data_collator=data_collator,\n",
    "# )\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training argument\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    SAVE_PATH,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=0.0003,\n",
    "    #weight_decay=0.01,\n",
    "    resume_from_checkpoint=True,\n",
    "    num_train_epochs=10,\n",
    "    save_total_limit=2,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "finetuner = FineTuner(model=model, save_path=SAVE_PATH, tokenizer=tokenizer, \n",
    "                      train_dataset=tokenized_dataset['train'], eval_dataset=tokenized_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/2370 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "                                                  \n",
      " 10%|â–ˆ         | 237/2370 [00:56<07:41,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2741573750972748, 'eval_runtime': 0.5273, 'eval_samples_per_second': 189.638, 'eval_steps_per_second': 24.653, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 20%|â–ˆâ–ˆ        | 474/2370 [02:10<07:24,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24826639890670776, 'eval_runtime': 0.5883, 'eval_samples_per_second': 169.978, 'eval_steps_per_second': 22.097, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆ        | 500/2370 [02:39<08:09,  3.82it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1959, 'learning_rate': 0.00023670886075949365, 'epoch': 2.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 711/2370 [03:28<05:56,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24687694013118744, 'eval_runtime': 0.5207, 'eval_samples_per_second': 192.034, 'eval_steps_per_second': 24.964, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 948/2370 [04:46<05:09,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2510281205177307, 'eval_runtime': 0.5293, 'eval_samples_per_second': 188.93, 'eval_steps_per_second': 24.561, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1000/2370 [05:22<05:05,  4.48it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.102, 'learning_rate': 0.00017341772151898733, 'epoch': 4.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1185/2370 [06:04<04:14,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27470269799232483, 'eval_runtime': 0.5321, 'eval_samples_per_second': 187.919, 'eval_steps_per_second': 24.43, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1422/2370 [07:23<03:23,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2975703477859497, 'eval_runtime': 0.537, 'eval_samples_per_second': 186.215, 'eval_steps_per_second': 24.208, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1500/2370 [08:07<07:44,  1.87it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0553, 'learning_rate': 0.000110126582278481, 'epoch': 6.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1659/2370 [08:45<02:32,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31456196308135986, 'eval_runtime': 0.5408, 'eval_samples_per_second': 184.909, 'eval_steps_per_second': 24.038, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1896/2370 [10:06<01:48,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33110669255256653, 'eval_runtime': 0.588, 'eval_samples_per_second': 170.058, 'eval_steps_per_second': 22.107, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2000/2370 [10:53<01:21,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0325, 'learning_rate': 4.683544303797468e-05, 'epoch': 8.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2133/2370 [11:24<00:50,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35090363025665283, 'eval_runtime': 0.5259, 'eval_samples_per_second': 190.143, 'eval_steps_per_second': 24.719, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2370/2370 [12:45<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35784682631492615, 'eval_runtime': 0.5221, 'eval_samples_per_second': 191.525, 'eval_steps_per_second': 24.898, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2370/2370 [13:11<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 791.6358, 'train_samples_per_second': 23.925, 'train_steps_per_second': 2.994, 'train_loss': 0.5070209623892096, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "finetuner.fine_tune(training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(SAVE_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/danendra/.cache/huggingface/datasets/csv/default-564c7144e159da05/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 420.36it/s]\n",
      "Loading cached processed dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-564c7144e159da05\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-0619265f74d98b9e.arrow\n",
      "Loading cached split indices for dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-564c7144e159da05\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-5d08aae3a84c90c6.arrow and C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-564c7144e159da05\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-4bae551a5fe5658f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] preprocessing dataset for experiment p0\n",
      "[INFO] training model for experiment p0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2260 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "                                                  \n",
      "  5%|â–Œ         | 113/2260 [00:21<06:26,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2919058799743652, 'eval_runtime': 1.0607, 'eval_samples_per_second': 213.077, 'eval_steps_per_second': 27.342, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 10%|â–ˆ         | 226/2260 [01:01<05:36,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6935251951217651, 'eval_runtime': 1.0732, 'eval_samples_per_second': 210.577, 'eval_steps_per_second': 27.021, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 15%|â–ˆâ–Œ        | 339/2260 [01:49<05:20,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5075335502624512, 'eval_runtime': 1.0707, 'eval_samples_per_second': 211.073, 'eval_steps_per_second': 27.085, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 20%|â–ˆâ–ˆ        | 452/2260 [02:31<05:03,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3850293159484863, 'eval_runtime': 1.2142, 'eval_samples_per_second': 186.125, 'eval_steps_per_second': 23.883, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 501/2260 [03:02<05:13,  5.61it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.05, 'learning_rate': 1.5575221238938054e-05, 'epoch': 4.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 25%|â–ˆâ–ˆâ–Œ       | 565/2260 [03:16<05:58,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2826519012451172, 'eval_runtime': 1.2596, 'eval_samples_per_second': 179.425, 'eval_steps_per_second': 23.024, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 678/2260 [04:02<04:11,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.204469919204712, 'eval_runtime': 1.0775, 'eval_samples_per_second': 209.749, 'eval_steps_per_second': 26.915, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 791/2260 [04:47<04:13,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1226141452789307, 'eval_runtime': 1.0959, 'eval_samples_per_second': 206.225, 'eval_steps_per_second': 26.463, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 904/2260 [05:30<03:48,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0495717525482178, 'eval_runtime': 1.0682, 'eval_samples_per_second': 211.579, 'eval_steps_per_second': 27.149, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1001/2260 [06:10<03:44,  5.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.045, 'learning_rate': 1.1150442477876106e-05, 'epoch': 8.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1017/2260 [06:13<03:23,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9821604490280151, 'eval_runtime': 1.0893, 'eval_samples_per_second': 207.474, 'eval_steps_per_second': 26.623, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1130/2260 [06:56<03:08,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9229294061660767, 'eval_runtime': 1.0675, 'eval_samples_per_second': 211.715, 'eval_steps_per_second': 27.167, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1243/2260 [07:41<02:40,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8679027557373047, 'eval_runtime': 1.0689, 'eval_samples_per_second': 211.441, 'eval_steps_per_second': 27.132, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1356/2260 [08:28<02:28,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8150554895401001, 'eval_runtime': 1.0805, 'eval_samples_per_second': 209.163, 'eval_steps_per_second': 26.839, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1469/2260 [09:12<02:17,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7708607316017151, 'eval_runtime': 1.0873, 'eval_samples_per_second': 207.849, 'eval_steps_per_second': 26.671, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1501/2260 [09:40<02:18,  5.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7085, 'learning_rate': 6.72566371681416e-06, 'epoch': 13.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1582/2260 [09:54<02:02,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7399626970291138, 'eval_runtime': 1.1075, 'eval_samples_per_second': 204.063, 'eval_steps_per_second': 26.185, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1695/2260 [10:42<01:31,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7208396196365356, 'eval_runtime': 1.0364, 'eval_samples_per_second': 218.056, 'eval_steps_per_second': 27.981, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1808/2260 [11:25<01:28,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.709347128868103, 'eval_runtime': 1.1228, 'eval_samples_per_second': 201.283, 'eval_steps_per_second': 25.828, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1921/2260 [12:09<01:02,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7004119753837585, 'eval_runtime': 1.1687, 'eval_samples_per_second': 193.384, 'eval_steps_per_second': 24.815, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2001/2260 [12:49<00:48,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5465, 'learning_rate': 2.3008849557522127e-06, 'epoch': 17.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2034/2260 [12:56<00:35,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6968504190444946, 'eval_runtime': 1.0491, 'eval_samples_per_second': 215.42, 'eval_steps_per_second': 27.642, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2147/2260 [13:40<00:18,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6941794157028198, 'eval_runtime': 1.0858, 'eval_samples_per_second': 208.147, 'eval_steps_per_second': 26.709, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2260/2260 [14:22<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6934356689453125, 'eval_runtime': 1.0919, 'eval_samples_per_second': 206.971, 'eval_steps_per_second': 26.558, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2260/2260 [14:48<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 888.7706, 'train_samples_per_second': 20.32, 'train_steps_per_second': 2.543, 'train_loss': 1.0219785707186808, 'epoch': 20.0}\n",
      "[INFO] preprocessing dataset for experiment p1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model for experiment p1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 113/2260 [00:18<05:34,  6.42it/s]\n",
      "  5%|â–Œ         | 113/2260 [00:20<05:34,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2919058799743652, 'eval_runtime': 1.0349, 'eval_samples_per_second': 218.388, 'eval_steps_per_second': 28.023, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 226/2260 [01:01<05:29,  6.18it/s]  \n",
      " 10%|â–ˆ         | 226/2260 [01:02<05:29,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6935251951217651, 'eval_runtime': 1.0327, 'eval_samples_per_second': 218.839, 'eval_steps_per_second': 28.081, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 339/2260 [01:46<05:30,  5.81it/s]  \n",
      " 15%|â–ˆâ–Œ        | 339/2260 [01:47<05:30,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5075335502624512, 'eval_runtime': 1.1001, 'eval_samples_per_second': 205.441, 'eval_steps_per_second': 26.362, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 452/2260 [02:33<05:25,  5.55it/s]  \n",
      " 20%|â–ˆâ–ˆ        | 452/2260 [02:34<05:25,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3850293159484863, 'eval_runtime': 1.1684, 'eval_samples_per_second': 193.431, 'eval_steps_per_second': 24.821, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 501/2260 [03:06<05:20,  5.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.05, 'learning_rate': 1.5575221238938054e-05, 'epoch': 4.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 565/2260 [03:17<04:33,  6.19it/s]\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 565/2260 [03:18<04:33,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2826519012451172, 'eval_runtime': 1.0303, 'eval_samples_per_second': 219.356, 'eval_steps_per_second': 28.147, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 678/2260 [04:01<04:19,  6.10it/s]  \n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 678/2260 [04:02<04:19,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.204469919204712, 'eval_runtime': 1.1313, 'eval_samples_per_second': 199.773, 'eval_steps_per_second': 25.635, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 791/2260 [04:47<03:59,  6.13it/s]  \n",
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 791/2260 [04:48<03:59,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1226141452789307, 'eval_runtime': 1.0519, 'eval_samples_per_second': 214.851, 'eval_steps_per_second': 27.569, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 904/2260 [05:30<03:56,  5.73it/s]  \n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 904/2260 [05:31<03:56,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0495717525482178, 'eval_runtime': 1.0573, 'eval_samples_per_second': 213.749, 'eval_steps_per_second': 27.428, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1001/2260 [06:11<03:51,  5.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.045, 'learning_rate': 1.1150442477876106e-05, 'epoch': 8.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1017/2260 [06:14<03:29,  5.93it/s]\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1017/2260 [06:15<03:29,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9821604490280151, 'eval_runtime': 1.0913, 'eval_samples_per_second': 207.1, 'eval_steps_per_second': 26.575, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1130/2260 [07:00<03:09,  5.95it/s]  \n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1130/2260 [07:01<03:09,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9229294061660767, 'eval_runtime': 1.056, 'eval_samples_per_second': 214.025, 'eval_steps_per_second': 27.463, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1243/2260 [07:44<02:51,  5.92it/s]  \n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1243/2260 [07:46<02:51,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8679027557373047, 'eval_runtime': 1.0721, 'eval_samples_per_second': 210.809, 'eval_steps_per_second': 27.051, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1356/2260 [08:26<02:27,  6.14it/s]  \n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1356/2260 [08:27<02:27,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8150554895401001, 'eval_runtime': 1.0697, 'eval_samples_per_second': 211.267, 'eval_steps_per_second': 27.11, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1469/2260 [09:15<02:14,  5.90it/s]  \n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1469/2260 [09:16<02:14,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7708607316017151, 'eval_runtime': 1.0648, 'eval_samples_per_second': 212.245, 'eval_steps_per_second': 27.235, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1501/2260 [09:44<02:16,  5.54it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7085, 'learning_rate': 6.72566371681416e-06, 'epoch': 13.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1582/2260 [09:58<01:57,  5.76it/s]\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1582/2260 [09:59<01:57,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7399626970291138, 'eval_runtime': 1.0733, 'eval_samples_per_second': 210.569, 'eval_steps_per_second': 27.02, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1695/2260 [10:40<01:36,  5.86it/s]  \n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1695/2260 [10:41<01:36,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7208396196365356, 'eval_runtime': 1.0949, 'eval_samples_per_second': 206.409, 'eval_steps_per_second': 26.486, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1808/2260 [11:30<01:14,  6.07it/s]  \n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1808/2260 [11:31<01:14,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.709347128868103, 'eval_runtime': 1.0885, 'eval_samples_per_second': 207.623, 'eval_steps_per_second': 26.642, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1921/2260 [12:13<00:58,  5.76it/s]\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1921/2260 [12:14<00:58,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7004119753837585, 'eval_runtime': 1.0818, 'eval_samples_per_second': 208.912, 'eval_steps_per_second': 26.807, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2001/2260 [12:53<00:48,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5465, 'learning_rate': 2.3008849557522127e-06, 'epoch': 17.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2034/2260 [12:59<00:37,  6.04it/s]\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2034/2260 [13:00<00:37,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6968504190444946, 'eval_runtime': 1.1267, 'eval_samples_per_second': 200.579, 'eval_steps_per_second': 25.738, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2147/2260 [13:48<00:18,  6.08it/s]\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2147/2260 [13:49<00:18,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6941794157028198, 'eval_runtime': 1.0729, 'eval_samples_per_second': 210.637, 'eval_steps_per_second': 27.029, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2260/2260 [14:31<00:00,  6.03it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2260/2260 [14:32<00:00,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6934356689453125, 'eval_runtime': 1.0964, 'eval_samples_per_second': 206.125, 'eval_steps_per_second': 26.45, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2260/2260 [14:54<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 894.7418, 'train_samples_per_second': 20.185, 'train_steps_per_second': 2.526, 'train_loss': 1.0219785707186808, 'epoch': 20.0}\n",
      "[INFO] preprocessing dataset for experiment p2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model for experiment p2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  5%|â–Œ         | 113/2260 [00:19<05:43,  6.24it/s]\n",
      "  5%|â–Œ         | 113/2260 [00:20<05:43,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2919058799743652, 'eval_runtime': 1.029, 'eval_samples_per_second': 219.637, 'eval_steps_per_second': 28.184, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 226/2260 [01:07<06:09,  5.50it/s]  \n",
      " 10%|â–ˆ         | 226/2260 [01:08<06:09,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6935251951217651, 'eval_runtime': 1.2246, 'eval_samples_per_second': 184.554, 'eval_steps_per_second': 23.682, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 339/2260 [01:50<05:28,  5.84it/s]  \n",
      " 15%|â–ˆâ–Œ        | 339/2260 [01:51<05:28,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5075335502624512, 'eval_runtime': 1.0791, 'eval_samples_per_second': 209.424, 'eval_steps_per_second': 26.873, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 452/2260 [02:34<05:10,  5.83it/s]  \n",
      " 20%|â–ˆâ–ˆ        | 452/2260 [02:35<05:10,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3850293159484863, 'eval_runtime': 1.072, 'eval_samples_per_second': 210.814, 'eval_steps_per_second': 27.051, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 501/2260 [03:11<05:29,  5.34it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.05, 'learning_rate': 1.5575221238938054e-05, 'epoch': 4.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 565/2260 [03:23<05:08,  5.49it/s]\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 565/2260 [03:24<05:08,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2826519012451172, 'eval_runtime': 1.1115, 'eval_samples_per_second': 203.333, 'eval_steps_per_second': 26.091, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 678/2260 [04:07<04:32,  5.80it/s]  \n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 678/2260 [04:09<04:32,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.204469919204712, 'eval_runtime': 1.1775, 'eval_samples_per_second': 191.932, 'eval_steps_per_second': 24.628, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 791/2260 [04:50<04:11,  5.84it/s]  \n",
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 791/2260 [04:51<04:11,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1226141452789307, 'eval_runtime': 1.0925, 'eval_samples_per_second': 206.857, 'eval_steps_per_second': 26.544, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 904/2260 [05:37<03:55,  5.75it/s]  \n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 904/2260 [05:38<03:55,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0495717525482178, 'eval_runtime': 1.1311, 'eval_samples_per_second': 199.809, 'eval_steps_per_second': 25.639, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1001/2260 [06:18<03:47,  5.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.045, 'learning_rate': 1.1150442477876106e-05, 'epoch': 8.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1017/2260 [06:21<03:30,  5.90it/s]\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1017/2260 [06:22<03:30,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9821604490280151, 'eval_runtime': 1.1075, 'eval_samples_per_second': 204.06, 'eval_steps_per_second': 26.185, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1130/2260 [07:06<03:13,  5.84it/s]  \n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1130/2260 [07:07<03:13,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9229294061660767, 'eval_runtime': 1.1007, 'eval_samples_per_second': 205.333, 'eval_steps_per_second': 26.348, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1243/2260 [07:52<03:02,  5.59it/s]  \n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1243/2260 [07:53<03:02,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8679027557373047, 'eval_runtime': 1.1222, 'eval_samples_per_second': 201.396, 'eval_steps_per_second': 25.843, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1356/2260 [08:38<02:44,  5.51it/s]  \n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1356/2260 [08:39<02:44,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8150554895401001, 'eval_runtime': 1.1029, 'eval_samples_per_second': 204.92, 'eval_steps_per_second': 26.295, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1469/2260 [09:22<02:14,  5.87it/s]  \n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1469/2260 [09:23<02:14,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7708607316017151, 'eval_runtime': 1.0803, 'eval_samples_per_second': 209.208, 'eval_steps_per_second': 26.845, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1501/2260 [09:55<02:19,  5.44it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7085, 'learning_rate': 6.72566371681416e-06, 'epoch': 13.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1582/2260 [10:09<01:59,  5.65it/s]\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1582/2260 [10:10<01:59,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7399626970291138, 'eval_runtime': 1.1943, 'eval_samples_per_second': 189.231, 'eval_steps_per_second': 24.282, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1695/2260 [10:56<01:33,  6.04it/s]  \n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1695/2260 [10:57<01:33,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7208396196365356, 'eval_runtime': 1.1384, 'eval_samples_per_second': 198.532, 'eval_steps_per_second': 25.475, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1808/2260 [11:39<01:20,  5.63it/s]  \n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1808/2260 [11:40<01:20,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.709347128868103, 'eval_runtime': 1.1043, 'eval_samples_per_second': 204.658, 'eval_steps_per_second': 26.261, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1921/2260 [12:26<01:01,  5.52it/s]  \n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1921/2260 [12:27<01:01,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7004119753837585, 'eval_runtime': 1.1255, 'eval_samples_per_second': 200.795, 'eval_steps_per_second': 25.766, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2001/2260 [13:05<00:48,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5465, 'learning_rate': 2.3008849557522127e-06, 'epoch': 17.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2034/2260 [13:11<00:38,  5.89it/s]\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2034/2260 [13:12<00:38,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6968504190444946, 'eval_runtime': 1.1239, 'eval_samples_per_second': 201.085, 'eval_steps_per_second': 25.803, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2147/2260 [13:56<00:19,  5.94it/s]\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2147/2260 [13:57<00:19,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6941794157028198, 'eval_runtime': 1.1049, 'eval_samples_per_second': 204.537, 'eval_steps_per_second': 26.246, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2260/2260 [14:43<00:00,  5.82it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2260/2260 [14:44<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6934356689453125, 'eval_runtime': 1.1093, 'eval_samples_per_second': 203.73, 'eval_steps_per_second': 26.142, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2260/2260 [15:08<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 909.6609, 'train_samples_per_second': 19.854, 'train_steps_per_second': 2.484, 'train_loss': 1.0219785707186808, 'epoch': 20.0}\n",
      "[INFO] preprocessing dataset for experiment p3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model for experiment p3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  5%|â–Œ         | 113/2260 [00:20<05:55,  6.04it/s]\n",
      "  5%|â–Œ         | 113/2260 [00:21<05:55,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2919058799743652, 'eval_runtime': 1.0951, 'eval_samples_per_second': 206.369, 'eval_steps_per_second': 26.481, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 226/2260 [01:03<05:43,  5.93it/s]  \n",
      " 10%|â–ˆ         | 226/2260 [01:04<05:43,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6935251951217651, 'eval_runtime': 1.0952, 'eval_samples_per_second': 206.348, 'eval_steps_per_second': 26.478, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 339/2260 [01:50<05:31,  5.79it/s]  \n",
      " 15%|â–ˆâ–Œ        | 339/2260 [01:51<05:31,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5075335502624512, 'eval_runtime': 1.099, 'eval_samples_per_second': 205.641, 'eval_steps_per_second': 26.388, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 452/2260 [02:36<05:14,  5.74it/s]  \n",
      " 20%|â–ˆâ–ˆ        | 452/2260 [02:37<05:14,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3850293159484863, 'eval_runtime': 1.0881, 'eval_samples_per_second': 207.701, 'eval_steps_per_second': 26.652, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 501/2260 [03:10<05:24,  5.42it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.05, 'learning_rate': 1.5575221238938054e-05, 'epoch': 4.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 565/2260 [03:21<04:48,  5.87it/s]\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 565/2260 [03:22<04:48,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2826519012451172, 'eval_runtime': 1.0873, 'eval_samples_per_second': 207.858, 'eval_steps_per_second': 26.672, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 678/2260 [04:07<04:25,  5.96it/s]  \n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 678/2260 [04:08<04:25,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.204469919204712, 'eval_runtime': 1.0891, 'eval_samples_per_second': 207.51, 'eval_steps_per_second': 26.627, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 791/2260 [04:54<04:11,  5.84it/s]  \n",
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 791/2260 [04:55<04:11,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1226141452789307, 'eval_runtime': 1.1001, 'eval_samples_per_second': 205.434, 'eval_steps_per_second': 26.361, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 904/2260 [05:39<03:52,  5.84it/s]  \n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 904/2260 [05:40<03:52,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0495717525482178, 'eval_runtime': 1.0918, 'eval_samples_per_second': 207.004, 'eval_steps_per_second': 26.563, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1001/2260 [06:21<03:59,  5.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.045, 'learning_rate': 1.1150442477876106e-05, 'epoch': 8.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1017/2260 [06:24<03:37,  5.71it/s]\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1017/2260 [06:25<03:37,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9821604490280151, 'eval_runtime': 1.1376, 'eval_samples_per_second': 198.67, 'eval_steps_per_second': 25.493, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1130/2260 [07:08<03:25,  5.49it/s]  \n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1130/2260 [07:09<03:25,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9229294061660767, 'eval_runtime': 1.1407, 'eval_samples_per_second': 198.123, 'eval_steps_per_second': 25.423, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1243/2260 [07:53<02:49,  5.99it/s]  \n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1243/2260 [07:54<02:49,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8679027557373047, 'eval_runtime': 1.0878, 'eval_samples_per_second': 207.766, 'eval_steps_per_second': 26.66, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1356/2260 [08:40<02:26,  6.17it/s]  \n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1356/2260 [08:42<02:26,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8150554895401001, 'eval_runtime': 1.1085, 'eval_samples_per_second': 203.877, 'eval_steps_per_second': 26.161, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1469/2260 [09:24<02:12,  5.98it/s]  \n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1469/2260 [09:26<02:12,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7708607316017151, 'eval_runtime': 1.0683, 'eval_samples_per_second': 211.542, 'eval_steps_per_second': 27.145, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1501/2260 [09:54<02:14,  5.66it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7085, 'learning_rate': 6.72566371681416e-06, 'epoch': 13.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1582/2260 [10:08<01:55,  5.90it/s]\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1582/2260 [10:09<01:55,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7399626970291138, 'eval_runtime': 1.0748, 'eval_samples_per_second': 210.267, 'eval_steps_per_second': 26.981, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1695/2260 [10:51<01:31,  6.16it/s]  \n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1695/2260 [10:52<01:31,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7208396196365356, 'eval_runtime': 1.0813, 'eval_samples_per_second': 209.009, 'eval_steps_per_second': 26.82, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1808/2260 [11:35<01:18,  5.74it/s]  \n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1808/2260 [11:36<01:18,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.709347128868103, 'eval_runtime': 1.0783, 'eval_samples_per_second': 209.59, 'eval_steps_per_second': 26.894, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1921/2260 [12:20<00:56,  6.01it/s]\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1921/2260 [12:21<00:56,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7004119753837585, 'eval_runtime': 1.0659, 'eval_samples_per_second': 212.024, 'eval_steps_per_second': 27.207, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2001/2260 [13:03<00:46,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5465, 'learning_rate': 2.3008849557522127e-06, 'epoch': 17.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2034/2260 [13:09<00:37,  6.01it/s]\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2034/2260 [13:10<00:37,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6968504190444946, 'eval_runtime': 1.161, 'eval_samples_per_second': 194.665, 'eval_steps_per_second': 24.979, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2147/2260 [13:52<00:20,  5.63it/s]\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2147/2260 [13:54<00:20,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6941794157028198, 'eval_runtime': 1.3898, 'eval_samples_per_second': 162.617, 'eval_steps_per_second': 20.867, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2260/2260 [14:37<00:00,  5.71it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2260/2260 [14:38<00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6934356689453125, 'eval_runtime': 1.2494, 'eval_samples_per_second': 180.889, 'eval_steps_per_second': 23.211, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2260/2260 [15:05<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 905.9792, 'train_samples_per_second': 19.934, 'train_steps_per_second': 2.495, 'train_loss': 1.0219785707186808, 'epoch': 20.0}\n"
     ]
    }
   ],
   "source": [
    "#constant\n",
    "SAVE_PATH = f'../models/preprocess_T5'\n",
    "PRETRAINED_MODEL = \"Wikidepia/IndoT5-base\"\n",
    "DATA_PATH = '../Data/quadruplet/quadruplet_annottated_sample_dataset_clean.csv'\n",
    "#variable\n",
    "max_length = 128\n",
    "text_col = 'content'\n",
    "label_col = 'quadruplet'\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "#training argument\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    SAVE_PATH,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    resume_from_checkpoint=True,\n",
    "    num_train_epochs=20,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "#read dataset\n",
    "raw_dataset = load_dataset('csv', data_files=DATA_PATH)\n",
    "#model training\n",
    "for i in range(4):\n",
    "    preprocess_type = f'p0{i}'\n",
    "    print(f\"[INFO] preprocessing dataset for experiment {preprocess_type}\")\n",
    "    #preprocess dataset\n",
    "    preprocessor = Preprocessor(f'{preprocess_type}', tokenizer, max_length, text_col, label_col)\n",
    "    tokenized_dataset = raw_dataset.map(preprocessor.preprocess_dataset, batched=True, remove_columns=raw_dataset['train'].column_names)\n",
    "    splitted_dataset = tokenized_dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
    "    print(f\"[INFO] training model for experiment {preprocess_type}\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained(PRETRAINED_MODEL)\n",
    "    finetuner = FineTuner(model=model, save_path=f\"{SAVE_PATH}_{preprocess_type}\", tokenizer=tokenizer, \n",
    "                      train_dataset=splitted_dataset['train'], eval_dataset=splitted_dataset['test'])\n",
    "    finetuner.fine_tune(training_args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference import ModelInference\n",
    "from src.preprocessor import Preprocessor\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constant\n",
    "max_length = 30\n",
    "text_col = 'content'\n",
    "label_col = 'postprocess_quintuplet'\n",
    "preprocess_type = 'p00'\n",
    "SAVE_PATH = f'../models/quintuplet_t5_MLM-PT'\n",
    "PRETRAINED_MODEL = \"Wikidepia/IndoT5-base\"#\"../models/pt-indot5-MLM_PT\" #\"Wikidepia/IndoT5-base\" \n",
    "TOKENIZER_PATH = \"Wikidepia/IndoT5-base\"\n",
    "DATA_PATH = '../Data/quintuplet/quintuplet_postprocessed_1000.csv'\n",
    "inference_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(SAVE_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(preprocess_type, tokenizer, max_length, text_col, label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/danendra/.cache/huggingface/datasets/csv/default-e45b5c90cd924547/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 500.04it/s]\n",
      "Loading cached split indices for dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-e45b5c90cd924547\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-ff1816f6c2c3ba58.arrow and C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-e45b5c90cd924547\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-64790f2f7fbaf197.arrow\n",
      "Loading cached processed dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-e45b5c90cd924547\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-b27f5c338b779ada.arrow\n",
      "Loading cached processed dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-e45b5c90cd924547\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-dcb7bbaf5e5d3995.arrow\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = load_dataset('csv', data_files=DATA_PATH)\n",
    "splitted_dataset = raw_dataset['train'].train_test_split(test_size=0.1, seed=42)\n",
    "tokenized_dataset = splitted_dataset.map(preprocessor.preprocess_dataset, batched=True, remove_columns=raw_dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pakai test data asli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "model_inference = ModelInference(batch_size=8, dataset=tokenized_dataset['test'], model=model, \n",
    "                                 tokenizer=tokenizer, inference_len=512)\n",
    "pred_text = model_inference.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.52ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59610"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = splitted_dataset['test']\n",
    "test_dataset = test_dataset.add_column(f'{preprocess_type}_model_prediction', pred_text)\n",
    "test_dataset.to_csv('../Data/quintuplet/test_data_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## buat dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-7c3f713988208aa5\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-2c42dbc24aa38187.arrow and C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-7c3f713988208aa5\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-f5003ba921be7c84.arrow\n",
      "Loading cached split indices for dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-7c3f713988208aa5\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-52fb2de3f9cb2504.arrow and C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-7c3f713988208aa5\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-29b8e9a42cc5be2e.arrow\n",
      "Creating CSV from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 86.83ba/s]\n",
      "Creating CSV from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 117.52ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "105907"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#membuat dummy dataset\n",
    "# dummy_dataset = splitted_dataset['train'].train_test_split(test_size=400, seed=42)\n",
    "# test_dataset = dummy_dataset['test'].train_test_split(test_size=200, seed=42)\n",
    "# test_dataset['train'].to_csv('../Data/quintuplet/val_data.csv') \n",
    "# test_dataset['test'].to_csv('../Data/quintuplet/test_data.csv') \n",
    "#.map(preprocessor.preprocess_dataset, batched=True, remove_columns=raw_dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/danendra/.cache/huggingface/datasets/csv/default-b8dcae55ca6bd5c3/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<?, ?it/s]\n",
      "Extracting data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 51.24it/s]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/danendra/.cache/huggingface/datasets/csv/default-b8dcae55ca6bd5c3/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 49.95it/s]\n",
      "Found cached dataset csv (C:/Users/danendra/.cache/huggingface/datasets/csv/default-ae888e11fe36b0d0/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 500.81it/s]\n",
      "Loading cached processed dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-ae888e11fe36b0d0\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-71127a19e7f0cb1f.arrow\n"
     ]
    }
   ],
   "source": [
    "#raw dataset\n",
    "val_dataset = load_dataset('csv', data_files='../Data/quintuplet/val_data.csv')\n",
    "test_dataset = load_dataset('csv', data_files='../Data/quintuplet/test_data.csv')\n",
    "#tokenized dataset\n",
    "tokenized_val_dataset = val_dataset.map(preprocessor.preprocess_dataset, batched=True, remove_columns=val_dataset['train'].column_names)\n",
    "tokenized_test_dataset = test_dataset.map(preprocessor.preprocess_dataset, batched=True, remove_columns=test_dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:17<00:00,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "model_inference = ModelInference(batch_size=8, dataset=tokenized_val_dataset['train'], model=model, \n",
    "                                 tokenizer=tokenizer, inference_len=512)\n",
    "pred_text = model_inference.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.90ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "509672"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset['train'] = val_dataset['train'].add_column(f'{experiment_type}_model_prediction', pred_text)\n",
    "val_dataset['train'].to_csv('../Data/quintuplet/val_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 8/237 [00:06<02:54,  1.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model_inference \u001b[39m=\u001b[39m ModelInference(batch_size\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, dataset\u001b[39m=\u001b[39mtokenized_dataset[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m], model\u001b[39m=\u001b[39mmodel, \n\u001b[0;32m      2\u001b[0m                                  tokenizer\u001b[39m=\u001b[39mtokenizer, inference_len\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m pred_text \u001b[39m=\u001b[39m model_inference\u001b[39m.\u001b[39;49minference()\n",
      "File \u001b[1;32md:\\Kuliah\\S2\\Tesis\\Code\\Buatan Sendiri\\experiments\\src\\inference.py:23\u001b[0m, in \u001b[0;36mModelInference.inference\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     21\u001b[0m pred_text \u001b[39m=\u001b[39m []\n\u001b[0;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(inference_dataset[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size)):\n\u001b[1;32m---> 23\u001b[0m     generated_text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(inference_dataset[\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m][i:i\u001b[39m+\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size]\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice), max_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference_len)\n\u001b[0;32m     24\u001b[0m     decoded_text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mbatch_decode(generated_text, skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m     pred_text\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mdecoded_text\n",
      "File \u001b[1;32mc:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\generation\\utils.py:1437\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, streamer, **kwargs)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1432\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnum_return_sequences has to be 1, but is \u001b[39m\u001b[39m{\u001b[39;00mgeneration_config\u001b[39m.\u001b[39mnum_return_sequences\u001b[39m}\u001b[39;00m\u001b[39m when doing\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1433\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m greedy search.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1434\u001b[0m         )\n\u001b[0;32m   1436\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[1;32m-> 1437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgreedy_search(\n\u001b[0;32m   1438\u001b[0m         input_ids,\n\u001b[0;32m   1439\u001b[0m         logits_processor\u001b[39m=\u001b[39mlogits_processor,\n\u001b[0;32m   1440\u001b[0m         stopping_criteria\u001b[39m=\u001b[39mstopping_criteria,\n\u001b[0;32m   1441\u001b[0m         pad_token_id\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mpad_token_id,\n\u001b[0;32m   1442\u001b[0m         eos_token_id\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39meos_token_id,\n\u001b[0;32m   1443\u001b[0m         output_scores\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39moutput_scores,\n\u001b[0;32m   1444\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mreturn_dict_in_generate,\n\u001b[0;32m   1445\u001b[0m         synced_gpus\u001b[39m=\u001b[39msynced_gpus,\n\u001b[0;32m   1446\u001b[0m         streamer\u001b[39m=\u001b[39mstreamer,\n\u001b[0;32m   1447\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1448\u001b[0m     )\n\u001b[0;32m   1450\u001b[0m \u001b[39melif\u001b[39;00m is_contrastive_search_gen_mode:\n\u001b[0;32m   1451\u001b[0m     \u001b[39mif\u001b[39;00m generation_config\u001b[39m.\u001b[39mnum_return_sequences \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\generation\\utils.py:2248\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2245\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2247\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2248\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(\n\u001b[0;32m   2249\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_inputs,\n\u001b[0;32m   2250\u001b[0m     return_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   2251\u001b[0m     output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[0;32m   2252\u001b[0m     output_hidden_states\u001b[39m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   2253\u001b[0m )\n\u001b[0;32m   2255\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2256\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1716\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1713\u001b[0m         decoder_attention_mask \u001b[39m=\u001b[39m decoder_attention_mask\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mfirst_device)\n\u001b[0;32m   1715\u001b[0m \u001b[39m# Decode\u001b[39;00m\n\u001b[1;32m-> 1716\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[0;32m   1717\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[0;32m   1718\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[0;32m   1719\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[0;32m   1720\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1721\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[0;32m   1722\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1723\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[0;32m   1724\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[0;32m   1725\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1726\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1727\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1728\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1729\u001b[0m )\n\u001b[0;32m   1731\u001b[0m sequence_output \u001b[39m=\u001b[39m decoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1733\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1086\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1073\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[0;32m   1074\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m   1075\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     )\n\u001b[0;32m   1085\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1086\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m   1087\u001b[0m         hidden_states,\n\u001b[0;32m   1088\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1089\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[0;32m   1090\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1091\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1092\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[0;32m   1093\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[0;32m   1094\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[0;32m   1095\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[0;32m   1096\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1097\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1098\u001b[0m     )\n\u001b[0;32m   1100\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[0;32m   1102\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:693\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    691\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 693\u001b[0m self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m0\u001b[39;49m](\n\u001b[0;32m    694\u001b[0m     hidden_states,\n\u001b[0;32m    695\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    696\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[0;32m    697\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[0;32m    698\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[0;32m    699\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    700\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    701\u001b[0m )\n\u001b[0;32m    702\u001b[0m hidden_states, present_key_value_state \u001b[39m=\u001b[39m self_attention_outputs[:\u001b[39m2\u001b[39m]\n\u001b[0;32m    703\u001b[0m attention_outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m2\u001b[39m:]  \u001b[39m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:600\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    590\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    591\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    597\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    598\u001b[0m ):\n\u001b[0;32m    599\u001b[0m     normed_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[1;32m--> 600\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSelfAttention(\n\u001b[0;32m    601\u001b[0m         normed_hidden_states,\n\u001b[0;32m    602\u001b[0m         mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    603\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[0;32m    604\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[0;32m    605\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[0;32m    606\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    607\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    608\u001b[0m     )\n\u001b[0;32m    609\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_output[\u001b[39m0\u001b[39m])\n\u001b[0;32m    610\u001b[0m     outputs \u001b[39m=\u001b[39m (hidden_states,) \u001b[39m+\u001b[39m attention_output[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:525\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[1;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[39m# get key/value states\u001b[39;00m\n\u001b[0;32m    522\u001b[0m key_states \u001b[39m=\u001b[39m project(\n\u001b[0;32m    523\u001b[0m     hidden_states, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk, key_value_states, past_key_value[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    524\u001b[0m )\n\u001b[1;32m--> 525\u001b[0m value_states \u001b[39m=\u001b[39m project(\n\u001b[0;32m    526\u001b[0m     hidden_states, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv, key_value_states, past_key_value[\u001b[39m1\u001b[39;49m] \u001b[39mif\u001b[39;49;00m past_key_value \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    529\u001b[0m \u001b[39m# compute scores\u001b[39;00m\n\u001b[0;32m    530\u001b[0m scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(\n\u001b[0;32m    531\u001b[0m     query_states, key_states\u001b[39m.\u001b[39mtranspose(\u001b[39m3\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m    532\u001b[0m )  \u001b[39m# equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:496\u001b[0m, in \u001b[0;36mT5Attention.forward.<locals>.project\u001b[1;34m(hidden_states, proj_layer, key_value_states, past_key_value)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39m\"\"\"projects hidden states correctly to key/query states\"\"\"\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[39mif\u001b[39;00m key_value_states \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m     \u001b[39m# self-attn\u001b[39;00m\n\u001b[0;32m    495\u001b[0m     \u001b[39m# (batch_size, n_heads, seq_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m--> 496\u001b[0m     hidden_states \u001b[39m=\u001b[39m shape(proj_layer(hidden_states))\n\u001b[0;32m    497\u001b[0m \u001b[39melif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m     \u001b[39m# cross-attn\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[39m# (batch_size, n_heads, seq_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     hidden_states \u001b[39m=\u001b[39m shape(proj_layer(key_value_states))\n",
      "File \u001b[1;32mc:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_inference = ModelInference(batch_size=8, dataset=tokenized_dataset['train'], model=model, \n",
    "                                 tokenizer=tokenizer, inference_len=512)\n",
    "pred_text = model_inference.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 39.96ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "543439"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = splitted_dataset['train']\n",
    "train_dataset = train_dataset.add_column(f'{preprocess_type}_model_prediction', pred_text)\n",
    "train_dataset.to_csv('../Data/quintuplet/model_1000-data_predictions_train.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.evaluator import Evaluator\n",
    "from src.postprocessor import PostProcessor\n",
    "from src.utils import extract_triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aoriginal_id</th>\n",
       "      <th>content</th>\n",
       "      <th>final_sentiment</th>\n",
       "      <th>baseline_aspect_category</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>corrected_label</th>\n",
       "      <th>keterangan</th>\n",
       "      <th>quintuplet_label</th>\n",
       "      <th>postprocess_quintuplet</th>\n",
       "      <th>p00_model_prediction</th>\n",
       "      <th>p01_model_prediction</th>\n",
       "      <th>p02_model_prediction</th>\n",
       "      <th>p03_model_prediction</th>\n",
       "      <th>p02_bart_model_prediction</th>\n",
       "      <th>p20_model_prediction</th>\n",
       "      <th>p21_model_prediction</th>\n",
       "      <th>p22_model_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1648822375587381249</td>\n",
       "      <td>@JNE_ID JT78364921062 ,, Ma,af no resi itu ,, ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>price; produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>JT78364921062 ,, Ma,af no resi itu ,, order d...</td>\n",
       "      <td>(shopee, order, blm sampe ke alamat penerimany...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(shopee, order, blm sampe ke alamat penerimany...</td>\n",
       "      <td>(shopee,order,blm sampe ke alamat penerimanya,...</td>\n",
       "      <td>(shopee,order,blm sampe ke alamat penerimanya,...</td>\n",
       "      <td>(shopee,order,blm sampe ke alamat penerimanya,...</td>\n",
       "      <td>(shopee,order,blm sampe ke alamat penerimanya,...</td>\n",
       "      <td>(shopee,order,blm sampe ke alamat penerimanya,...</td>\n",
       "      <td>(shopee,shopee express,cepet,positive,deliver...</td>\n",
       "      <td>(shopee,order,blm sampe ke alamat penerimanya,...</td>\n",
       "      <td>(shopee,order,blm sampe ke alamat penerimanya,...</td>\n",
       "      <td>(shopee,order,blm sampe ke alamat penerimanya,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1639829371166015489</td>\n",
       "      <td>@sbtcon Jodantae sama shopee express soalnya a...</td>\n",
       "      <td>negative</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>Jodantae sama shopee express soalnya abang ab...</td>\n",
       "      <td>(shopee, shopee express, cepet, positive, deli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(shopee, shopee express, cepet, positive, deli...</td>\n",
       "      <td>(shopee,shopee express,cepet,positive,delivery)</td>\n",
       "      <td>(shopee,shopee express,cepet,positive,delivery)</td>\n",
       "      <td>(shopee,shopee express,cepet,positive,delivery)</td>\n",
       "      <td>(shopee,shopee express,cepet,positive,delivery)</td>\n",
       "      <td>(shopee,shopee express,cepet,positive,delivery)</td>\n",
       "      <td>(shopee,shopee express,cepet,positive,deliver...</td>\n",
       "      <td>(shopee,shopee express,cepet,positive,delivery)</td>\n",
       "      <td>(shopee,shopee express,cepet,positive,delivery)</td>\n",
       "      <td>(shopee,shopee express,cepet,positive,delivery)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1640221429517156352</td>\n",
       "      <td>Berubah ketika barang sampai.yg tadinya ada ja...</td>\n",
       "      <td>negative</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>Berubah ketika barang sampai.yg tadinya ada ja...</td>\n",
       "      <td>(tokopedia, invoice, bisa ubah invoice seenak ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(tokopedia, invoice, bisa ubah invoice seenak ...</td>\n",
       "      <td>(tokopedia,invoice,bisa ubah invoice seenak me...</td>\n",
       "      <td>(_,barang,sampai skrng,negative,delivery)</td>\n",
       "      <td>(_,barang,ubah barang dari yg tadinya jadi ila...</td>\n",
       "      <td>(tokopedia,barang,sampai yg tadi ada jd ilang,...</td>\n",
       "      <td>(tokopedia,pengubah barang,jadi lenyap,negativ...</td>\n",
       "      <td>(shopee,shopee express,cepet,positive,deliver...</td>\n",
       "      <td>(tokopedia,barang,sampai yg tadi ada jadi leny...</td>\n",
       "      <td>(tokopedia,barang,tiba2 jadi lenyap,negative,d...</td>\n",
       "      <td>(tokopedia,barang,nyasar,negative,delivery)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          aoriginal_id                                            content  \\\n",
       "0  1648822375587381249  @JNE_ID JT78364921062 ,, Ma,af no resi itu ,, ...   \n",
       "1  1639829371166015489  @sbtcon Jodantae sama shopee express soalnya a...   \n",
       "2  1640221429517156352  Berubah ketika barang sampai.yg tadinya ada ja...   \n",
       "\n",
       "  final_sentiment baseline_aspect_category  tweet_type  \\\n",
       "0        negative           price; produk;  SUBJECTIVE   \n",
       "1        negative                  produk;  SUBJECTIVE   \n",
       "2        negative                  produk;  SUBJECTIVE   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0   JT78364921062 ,, Ma,af no resi itu ,, order d...   \n",
       "1   Jodantae sama shopee express soalnya abang ab...   \n",
       "2  Berubah ketika barang sampai.yg tadinya ada ja...   \n",
       "\n",
       "                                               label corrected_label  \\\n",
       "0  (shopee, order, blm sampe ke alamat penerimany...             NaN   \n",
       "1  (shopee, shopee express, cepet, positive, deli...             NaN   \n",
       "2  (tokopedia, invoice, bisa ubah invoice seenak ...             NaN   \n",
       "\n",
       "  keterangan                                   quintuplet_label  \\\n",
       "0        NaN  (shopee, order, blm sampe ke alamat penerimany...   \n",
       "1        NaN  (shopee, shopee express, cepet, positive, deli...   \n",
       "2        NaN  (tokopedia, invoice, bisa ubah invoice seenak ...   \n",
       "\n",
       "                              postprocess_quintuplet  \\\n",
       "0  (shopee,order,blm sampe ke alamat penerimanya,...   \n",
       "1    (shopee,shopee express,cepet,positive,delivery)   \n",
       "2  (tokopedia,invoice,bisa ubah invoice seenak me...   \n",
       "\n",
       "                                p00_model_prediction  \\\n",
       "0  (shopee,order,blm sampe ke alamat penerimanya,...   \n",
       "1    (shopee,shopee express,cepet,positive,delivery)   \n",
       "2          (_,barang,sampai skrng,negative,delivery)   \n",
       "\n",
       "                                p01_model_prediction  \\\n",
       "0  (shopee,order,blm sampe ke alamat penerimanya,...   \n",
       "1    (shopee,shopee express,cepet,positive,delivery)   \n",
       "2  (_,barang,ubah barang dari yg tadinya jadi ila...   \n",
       "\n",
       "                                p02_model_prediction  \\\n",
       "0  (shopee,order,blm sampe ke alamat penerimanya,...   \n",
       "1    (shopee,shopee express,cepet,positive,delivery)   \n",
       "2  (tokopedia,barang,sampai yg tadi ada jd ilang,...   \n",
       "\n",
       "                                p03_model_prediction  \\\n",
       "0  (shopee,order,blm sampe ke alamat penerimanya,...   \n",
       "1    (shopee,shopee express,cepet,positive,delivery)   \n",
       "2  (tokopedia,pengubah barang,jadi lenyap,negativ...   \n",
       "\n",
       "                           p02_bart_model_prediction  \\\n",
       "0   (shopee,shopee express,cepet,positive,deliver...   \n",
       "1   (shopee,shopee express,cepet,positive,deliver...   \n",
       "2   (shopee,shopee express,cepet,positive,deliver...   \n",
       "\n",
       "                                p20_model_prediction  \\\n",
       "0  (shopee,order,blm sampe ke alamat penerimanya,...   \n",
       "1    (shopee,shopee express,cepet,positive,delivery)   \n",
       "2  (tokopedia,barang,sampai yg tadi ada jadi leny...   \n",
       "\n",
       "                                p21_model_prediction  \\\n",
       "0  (shopee,order,blm sampe ke alamat penerimanya,...   \n",
       "1    (shopee,shopee express,cepet,positive,delivery)   \n",
       "2  (tokopedia,barang,tiba2 jadi lenyap,negative,d...   \n",
       "\n",
       "                                p22_model_prediction  \n",
       "0  (shopee,order,blm sampe ke alamat penerimanya,...  \n",
       "1    (shopee,shopee express,cepet,positive,delivery)  \n",
       "2        (tokopedia,barang,nyasar,negative,delivery)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/quintuplet/val_data.csv')\n",
    "df['postprocess_quintuplet'] = df['postprocess_quintuplet'].apply(lambda x:x.lower())\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessor = PostProcessor(use_postprocess=False)\n",
    "evaluator = Evaluator(task_type='quintuplet', postprocessor=postprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 100054.96it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_scores, all_labels, all_preds = evaluator.evaluate(pred_seqs=df[f'{experiment_type}_model_prediction'],\n",
    "                   gold_seqs=df['postprocess_quintuplet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.858, 'recall': 0.85, 'f1': 0.854}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aoriginal_id</th>\n",
       "      <th>content</th>\n",
       "      <th>final_sentiment</th>\n",
       "      <th>baseline_aspect_category</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>corrected_label</th>\n",
       "      <th>keterangan</th>\n",
       "      <th>quintuplet_label</th>\n",
       "      <th>postprocess_quintuplet</th>\n",
       "      <th>p00_model_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1647261067511496704</td>\n",
       "      <td>eh mau lebaran kyk gini ekspedisi kan lagi hec...</td>\n",
       "      <td>negative</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>eh mau lebaran kyk gini ekspedisi kan lagi hec...</td>\n",
       "      <td>(shopee, shopee xpress, ekpsedisi kan lagi hec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(shopee, shopee xpress, ekpsedisi kan lagi hec...</td>\n",
       "      <td>(shopee,shopee xpress,ekpsedisi kan lagi hecti...</td>\n",
       "      <td>(shopee,shopee xpress,ekspedisi kan lagi hecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1646546316204597248</td>\n",
       "      <td>@tanyakanrl asli pernah lewat beranda tbtb ada...</td>\n",
       "      <td>negative</td>\n",
       "      <td>delivery; website&amp;apps; produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>asli pernah lewat beranda tbtb ada yg jual ko...</td>\n",
       "      <td>(shopee, konten dewasa, parah si kok bisa lolo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(shopee, konten dewasa, parah si kok bisa lolo...</td>\n",
       "      <td>(shopee,konten dewasa,parah si kok bisa lolos ...</td>\n",
       "      <td>(shopee,konten dewasa,parah si kok bisa lolos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1647243563443388416</td>\n",
       "      <td>Adeuh, ini barang gua dri shopee blm nyampai2 ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>delivery; customerservice; produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>Adeuh, ini barang gua dri shopee blm nyampai2 ...</td>\n",
       "      <td>(shopee, barang, blm nyampai2 jg woy, negative...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(shopee, barang, blm nyampai2 jg woy, negative...</td>\n",
       "      <td>(shopee,barang,blm nyampai2 jg woy,negative,de...</td>\n",
       "      <td>(shopee,barang,blm nyampai2 jg woy,negative,de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          aoriginal_id                                            content  \\\n",
       "0  1647261067511496704  eh mau lebaran kyk gini ekspedisi kan lagi hec...   \n",
       "1  1646546316204597248  @tanyakanrl asli pernah lewat beranda tbtb ada...   \n",
       "2  1647243563443388416  Adeuh, ini barang gua dri shopee blm nyampai2 ...   \n",
       "\n",
       "  final_sentiment            baseline_aspect_category  tweet_type  \\\n",
       "0        negative                             produk;  SUBJECTIVE   \n",
       "1        negative     delivery; website&apps; produk;  SUBJECTIVE   \n",
       "2        negative  delivery; customerservice; produk;  SUBJECTIVE   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  eh mau lebaran kyk gini ekspedisi kan lagi hec...   \n",
       "1   asli pernah lewat beranda tbtb ada yg jual ko...   \n",
       "2  Adeuh, ini barang gua dri shopee blm nyampai2 ...   \n",
       "\n",
       "                                               label corrected_label  \\\n",
       "0  (shopee, shopee xpress, ekpsedisi kan lagi hec...             NaN   \n",
       "1  (shopee, konten dewasa, parah si kok bisa lolo...             NaN   \n",
       "2  (shopee, barang, blm nyampai2 jg woy, negative...             NaN   \n",
       "\n",
       "  keterangan                                   quintuplet_label  \\\n",
       "0        NaN  (shopee, shopee xpress, ekpsedisi kan lagi hec...   \n",
       "1        NaN  (shopee, konten dewasa, parah si kok bisa lolo...   \n",
       "2        NaN  (shopee, barang, blm nyampai2 jg woy, negative...   \n",
       "\n",
       "                              postprocess_quintuplet  \\\n",
       "0  (shopee,shopee xpress,ekpsedisi kan lagi hecti...   \n",
       "1  (shopee,konten dewasa,parah si kok bisa lolos ...   \n",
       "2  (shopee,barang,blm nyampai2 jg woy,negative,de...   \n",
       "\n",
       "                                p00_model_prediction  \n",
       "0  (shopee,shopee xpress,ekspedisi kan lagi hecti...  \n",
       "1  (shopee,konten dewasa,parah si kok bisa lolos ...  \n",
       "2  (shopee,barang,blm nyampai2 jg woy,negative,de...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/quintuplet/model_1000-data_predictions_train.csv')\n",
    "df['postprocess_quintuplet'] = df['postprocess_quintuplet'].apply(lambda x:x.lower())\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 930/930 [00:00<00:00, 109199.15it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_scores, all_labels, all_preds = evaluator.evaluate(pred_seqs=df['p00_model_prediction'],\n",
    "                   gold_seqs=df['postprocess_quintuplet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.6540483701366983,\n",
       " 'recall': 0.6032977691561591,\n",
       " 'f1': 0.627648839556004}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

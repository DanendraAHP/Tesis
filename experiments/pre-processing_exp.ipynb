{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.finetuner import FineTuner\n",
    "from src.preprocessor import Preprocessor\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainingArguments\n",
    ")\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constant\n",
    "max_length = 30\n",
    "text_col = 'content'\n",
    "label_col = 'postprocess_quintuplet'\n",
    "preprocess_type = 'p00'\n",
    "SAVE_PATH = f'../models/quintuplet_t5_MLM-PT'\n",
    "PRETRAINED_MODEL = \"../models/pt-indot5-MLM_PT\"#\"../models/pt-indot5-MLM_PT\" #\"Wikidepia/IndoT5-base\" \n",
    "TOKENIZER_PATH = \"Wikidepia/IndoT5-base\"\n",
    "DATA_PATH = '../Data/quintuplet/quintuplet_postprocessed_1000.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "preprocessor = Preprocessor(preprocess_type, tokenizer, max_length, text_col, label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/danendra/.cache/huggingface/datasets/csv/default-e45b5c90cd924547/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 497.07it/s]\n",
      "Loading cached split indices for dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-e45b5c90cd924547\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-ff1816f6c2c3ba58.arrow and C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-e45b5c90cd924547\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-64790f2f7fbaf197.arrow\n",
      "Loading cached processed dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-e45b5c90cd924547\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-b27f5c338b779ada.arrow\n",
      "Loading cached processed dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-e45b5c90cd924547\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-dcb7bbaf5e5d3995.arrow\n"
     ]
    }
   ],
   "source": [
    "# raw_dataset = load_dataset('csv', data_files={\n",
    "#     'train' : f'{DATA_PATH}_train.csv',\n",
    "#     'test' : f'{DATA_PATH}_test.csv',\n",
    "#     'val' : f'{DATA_PATH}_val.csv'\n",
    "# })\n",
    "raw_dataset = load_dataset('csv', data_files=DATA_PATH)\n",
    "#raw_dataset = raw_dataset.filter(lambda x: x['is_comparative']==False)\n",
    "splitted_dataset = raw_dataset['train'].train_test_split(test_size=0.1, seed=42)\n",
    "tokenized_dataset = splitted_dataset.map(preprocessor.preprocess_dataset, batched=True, remove_columns=raw_dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 930\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 104\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_labels = []\n",
    "len_inputs = []\n",
    "for i in range(len(tokenized_dataset['train'])):\n",
    "    len_labels.append(len(tokenized_dataset['train'][i]['labels']))\n",
    "    len_inputs.append(len(tokenized_dataset['train'][i]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106.0, 30.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len_labels)/len(len_labels), sum(len_inputs)/len(len_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shope aja, di dom aku termasuk cepat dengan kondisi yang skrng ini</s><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_dataset['test']['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(shopee,_,cepet dgn kondisi yg skrng ini,positive,delivery)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_dataset['test']['labels'][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(PRETRAINED_MODEL)\n",
    "#model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training argument\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    SAVE_PATH,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=0.0003,\n",
    "    #weight_decay=0.01,\n",
    "    resume_from_checkpoint=True,\n",
    "    num_train_epochs=10,\n",
    "    save_total_limit=2,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "finetuner = FineTuner(model=model, save_path=SAVE_PATH, tokenizer=tokenizer, \n",
    "                      train_dataset=tokenized_dataset['train'], eval_dataset=tokenized_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/1170 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "                                                  \n",
      " 10%|█         | 117/1170 [00:28<03:27,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7088098526000977, 'eval_runtime': 0.5397, 'eval_samples_per_second': 192.715, 'eval_steps_per_second': 24.089, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 20%|██        | 234/1170 [01:20<03:07,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.336075097322464, 'eval_runtime': 0.5099, 'eval_samples_per_second': 203.975, 'eval_steps_per_second': 25.497, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 30%|███       | 351/1170 [02:10<02:40,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25344759225845337, 'eval_runtime': 0.5248, 'eval_samples_per_second': 198.171, 'eval_steps_per_second': 24.771, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 40%|████      | 468/1170 [03:01<02:14,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25331756472587585, 'eval_runtime': 0.5322, 'eval_samples_per_second': 195.415, 'eval_steps_per_second': 24.427, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 500/1170 [03:31<02:28,  4.52it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0021, 'learning_rate': 0.00017179487179487177, 'epoch': 4.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 50%|█████     | 585/1170 [03:51<02:08,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2551606595516205, 'eval_runtime': 0.5242, 'eval_samples_per_second': 198.398, 'eval_steps_per_second': 24.8, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 60%|██████    | 702/1170 [04:41<01:31,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.266947478055954, 'eval_runtime': 0.5302, 'eval_samples_per_second': 196.168, 'eval_steps_per_second': 24.521, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 70%|███████   | 819/1170 [05:37<01:08,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2837437093257904, 'eval_runtime': 0.5702, 'eval_samples_per_second': 182.379, 'eval_steps_per_second': 22.797, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 80%|████████  | 936/1170 [06:27<00:46,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28445443511009216, 'eval_runtime': 0.5783, 'eval_samples_per_second': 179.839, 'eval_steps_per_second': 22.48, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1001/1170 [07:06<00:39,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0794, 'learning_rate': 4.358974358974359e-05, 'epoch': 8.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 90%|█████████ | 1053/1170 [07:17<00:22,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29689183831214905, 'eval_runtime': 0.5136, 'eval_samples_per_second': 202.473, 'eval_steps_per_second': 25.309, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|██████████| 1170/1170 [08:10<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30097663402557373, 'eval_runtime': 0.5049, 'eval_samples_per_second': 205.992, 'eval_steps_per_second': 25.749, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1170/1170 [08:35<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 515.828, 'train_samples_per_second': 18.029, 'train_steps_per_second': 2.268, 'train_loss': 0.896937206463936, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "finetuner.fine_tune(training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(SAVE_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/danendra/.cache/huggingface/datasets/csv/default-564c7144e159da05/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 420.36it/s]\n",
      "Loading cached processed dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-564c7144e159da05\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-0619265f74d98b9e.arrow\n",
      "Loading cached split indices for dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-564c7144e159da05\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-5d08aae3a84c90c6.arrow and C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-564c7144e159da05\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-4bae551a5fe5658f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] preprocessing dataset for experiment p0\n",
      "[INFO] training model for experiment p0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2260 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "                                                  \n",
      "  5%|▌         | 113/2260 [00:21<06:26,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2919058799743652, 'eval_runtime': 1.0607, 'eval_samples_per_second': 213.077, 'eval_steps_per_second': 27.342, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 10%|█         | 226/2260 [01:01<05:36,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6935251951217651, 'eval_runtime': 1.0732, 'eval_samples_per_second': 210.577, 'eval_steps_per_second': 27.021, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 15%|█▌        | 339/2260 [01:49<05:20,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5075335502624512, 'eval_runtime': 1.0707, 'eval_samples_per_second': 211.073, 'eval_steps_per_second': 27.085, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 20%|██        | 452/2260 [02:31<05:03,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3850293159484863, 'eval_runtime': 1.2142, 'eval_samples_per_second': 186.125, 'eval_steps_per_second': 23.883, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 501/2260 [03:02<05:13,  5.61it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.05, 'learning_rate': 1.5575221238938054e-05, 'epoch': 4.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 25%|██▌       | 565/2260 [03:16<05:58,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2826519012451172, 'eval_runtime': 1.2596, 'eval_samples_per_second': 179.425, 'eval_steps_per_second': 23.024, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 30%|███       | 678/2260 [04:02<04:11,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.204469919204712, 'eval_runtime': 1.0775, 'eval_samples_per_second': 209.749, 'eval_steps_per_second': 26.915, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 35%|███▌      | 791/2260 [04:47<04:13,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1226141452789307, 'eval_runtime': 1.0959, 'eval_samples_per_second': 206.225, 'eval_steps_per_second': 26.463, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 40%|████      | 904/2260 [05:30<03:48,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0495717525482178, 'eval_runtime': 1.0682, 'eval_samples_per_second': 211.579, 'eval_steps_per_second': 27.149, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1001/2260 [06:10<03:44,  5.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.045, 'learning_rate': 1.1150442477876106e-05, 'epoch': 8.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 45%|████▌     | 1017/2260 [06:13<03:23,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9821604490280151, 'eval_runtime': 1.0893, 'eval_samples_per_second': 207.474, 'eval_steps_per_second': 26.623, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 50%|█████     | 1130/2260 [06:56<03:08,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9229294061660767, 'eval_runtime': 1.0675, 'eval_samples_per_second': 211.715, 'eval_steps_per_second': 27.167, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 55%|█████▌    | 1243/2260 [07:41<02:40,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8679027557373047, 'eval_runtime': 1.0689, 'eval_samples_per_second': 211.441, 'eval_steps_per_second': 27.132, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 60%|██████    | 1356/2260 [08:28<02:28,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8150554895401001, 'eval_runtime': 1.0805, 'eval_samples_per_second': 209.163, 'eval_steps_per_second': 26.839, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 65%|██████▌   | 1469/2260 [09:12<02:17,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7708607316017151, 'eval_runtime': 1.0873, 'eval_samples_per_second': 207.849, 'eval_steps_per_second': 26.671, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 1501/2260 [09:40<02:18,  5.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7085, 'learning_rate': 6.72566371681416e-06, 'epoch': 13.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 70%|███████   | 1582/2260 [09:54<02:02,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7399626970291138, 'eval_runtime': 1.1075, 'eval_samples_per_second': 204.063, 'eval_steps_per_second': 26.185, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 75%|███████▌  | 1695/2260 [10:42<01:31,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7208396196365356, 'eval_runtime': 1.0364, 'eval_samples_per_second': 218.056, 'eval_steps_per_second': 27.981, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 80%|████████  | 1808/2260 [11:25<01:28,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.709347128868103, 'eval_runtime': 1.1228, 'eval_samples_per_second': 201.283, 'eval_steps_per_second': 25.828, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 85%|████████▌ | 1921/2260 [12:09<01:02,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7004119753837585, 'eval_runtime': 1.1687, 'eval_samples_per_second': 193.384, 'eval_steps_per_second': 24.815, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 2001/2260 [12:49<00:48,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5465, 'learning_rate': 2.3008849557522127e-06, 'epoch': 17.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 90%|█████████ | 2034/2260 [12:56<00:35,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6968504190444946, 'eval_runtime': 1.0491, 'eval_samples_per_second': 215.42, 'eval_steps_per_second': 27.642, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 95%|█████████▌| 2147/2260 [13:40<00:18,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6941794157028198, 'eval_runtime': 1.0858, 'eval_samples_per_second': 208.147, 'eval_steps_per_second': 26.709, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|██████████| 2260/2260 [14:22<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6934356689453125, 'eval_runtime': 1.0919, 'eval_samples_per_second': 206.971, 'eval_steps_per_second': 26.558, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [14:48<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 888.7706, 'train_samples_per_second': 20.32, 'train_steps_per_second': 2.543, 'train_loss': 1.0219785707186808, 'epoch': 20.0}\n",
      "[INFO] preprocessing dataset for experiment p1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model for experiment p1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 113/2260 [00:18<05:34,  6.42it/s]\n",
      "  5%|▌         | 113/2260 [00:20<05:34,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2919058799743652, 'eval_runtime': 1.0349, 'eval_samples_per_second': 218.388, 'eval_steps_per_second': 28.023, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 226/2260 [01:01<05:29,  6.18it/s]  \n",
      " 10%|█         | 226/2260 [01:02<05:29,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6935251951217651, 'eval_runtime': 1.0327, 'eval_samples_per_second': 218.839, 'eval_steps_per_second': 28.081, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 339/2260 [01:46<05:30,  5.81it/s]  \n",
      " 15%|█▌        | 339/2260 [01:47<05:30,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5075335502624512, 'eval_runtime': 1.1001, 'eval_samples_per_second': 205.441, 'eval_steps_per_second': 26.362, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 452/2260 [02:33<05:25,  5.55it/s]  \n",
      " 20%|██        | 452/2260 [02:34<05:25,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3850293159484863, 'eval_runtime': 1.1684, 'eval_samples_per_second': 193.431, 'eval_steps_per_second': 24.821, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 501/2260 [03:06<05:20,  5.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.05, 'learning_rate': 1.5575221238938054e-05, 'epoch': 4.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 565/2260 [03:17<04:33,  6.19it/s]\n",
      " 25%|██▌       | 565/2260 [03:18<04:33,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2826519012451172, 'eval_runtime': 1.0303, 'eval_samples_per_second': 219.356, 'eval_steps_per_second': 28.147, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 678/2260 [04:01<04:19,  6.10it/s]  \n",
      " 30%|███       | 678/2260 [04:02<04:19,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.204469919204712, 'eval_runtime': 1.1313, 'eval_samples_per_second': 199.773, 'eval_steps_per_second': 25.635, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 791/2260 [04:47<03:59,  6.13it/s]  \n",
      " 35%|███▌      | 791/2260 [04:48<03:59,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1226141452789307, 'eval_runtime': 1.0519, 'eval_samples_per_second': 214.851, 'eval_steps_per_second': 27.569, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 904/2260 [05:30<03:56,  5.73it/s]  \n",
      " 40%|████      | 904/2260 [05:31<03:56,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0495717525482178, 'eval_runtime': 1.0573, 'eval_samples_per_second': 213.749, 'eval_steps_per_second': 27.428, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1001/2260 [06:11<03:51,  5.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.045, 'learning_rate': 1.1150442477876106e-05, 'epoch': 8.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1017/2260 [06:14<03:29,  5.93it/s]\n",
      " 45%|████▌     | 1017/2260 [06:15<03:29,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9821604490280151, 'eval_runtime': 1.0913, 'eval_samples_per_second': 207.1, 'eval_steps_per_second': 26.575, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1130/2260 [07:00<03:09,  5.95it/s]  \n",
      " 50%|█████     | 1130/2260 [07:01<03:09,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9229294061660767, 'eval_runtime': 1.056, 'eval_samples_per_second': 214.025, 'eval_steps_per_second': 27.463, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1243/2260 [07:44<02:51,  5.92it/s]  \n",
      " 55%|█████▌    | 1243/2260 [07:46<02:51,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8679027557373047, 'eval_runtime': 1.0721, 'eval_samples_per_second': 210.809, 'eval_steps_per_second': 27.051, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1356/2260 [08:26<02:27,  6.14it/s]  \n",
      " 60%|██████    | 1356/2260 [08:27<02:27,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8150554895401001, 'eval_runtime': 1.0697, 'eval_samples_per_second': 211.267, 'eval_steps_per_second': 27.11, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1469/2260 [09:15<02:14,  5.90it/s]  \n",
      " 65%|██████▌   | 1469/2260 [09:16<02:14,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7708607316017151, 'eval_runtime': 1.0648, 'eval_samples_per_second': 212.245, 'eval_steps_per_second': 27.235, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 1501/2260 [09:44<02:16,  5.54it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7085, 'learning_rate': 6.72566371681416e-06, 'epoch': 13.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1582/2260 [09:58<01:57,  5.76it/s]\n",
      " 70%|███████   | 1582/2260 [09:59<01:57,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7399626970291138, 'eval_runtime': 1.0733, 'eval_samples_per_second': 210.569, 'eval_steps_per_second': 27.02, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1695/2260 [10:40<01:36,  5.86it/s]  \n",
      " 75%|███████▌  | 1695/2260 [10:41<01:36,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7208396196365356, 'eval_runtime': 1.0949, 'eval_samples_per_second': 206.409, 'eval_steps_per_second': 26.486, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1808/2260 [11:30<01:14,  6.07it/s]  \n",
      " 80%|████████  | 1808/2260 [11:31<01:14,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.709347128868103, 'eval_runtime': 1.0885, 'eval_samples_per_second': 207.623, 'eval_steps_per_second': 26.642, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1921/2260 [12:13<00:58,  5.76it/s]\n",
      " 85%|████████▌ | 1921/2260 [12:14<00:58,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7004119753837585, 'eval_runtime': 1.0818, 'eval_samples_per_second': 208.912, 'eval_steps_per_second': 26.807, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 2001/2260 [12:53<00:48,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5465, 'learning_rate': 2.3008849557522127e-06, 'epoch': 17.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 2034/2260 [12:59<00:37,  6.04it/s]\n",
      " 90%|█████████ | 2034/2260 [13:00<00:37,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6968504190444946, 'eval_runtime': 1.1267, 'eval_samples_per_second': 200.579, 'eval_steps_per_second': 25.738, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 2147/2260 [13:48<00:18,  6.08it/s]\n",
      " 95%|█████████▌| 2147/2260 [13:49<00:18,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6941794157028198, 'eval_runtime': 1.0729, 'eval_samples_per_second': 210.637, 'eval_steps_per_second': 27.029, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [14:31<00:00,  6.03it/s]\n",
      "100%|██████████| 2260/2260 [14:32<00:00,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6934356689453125, 'eval_runtime': 1.0964, 'eval_samples_per_second': 206.125, 'eval_steps_per_second': 26.45, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [14:54<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 894.7418, 'train_samples_per_second': 20.185, 'train_steps_per_second': 2.526, 'train_loss': 1.0219785707186808, 'epoch': 20.0}\n",
      "[INFO] preprocessing dataset for experiment p2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model for experiment p2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  5%|▌         | 113/2260 [00:19<05:43,  6.24it/s]\n",
      "  5%|▌         | 113/2260 [00:20<05:43,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2919058799743652, 'eval_runtime': 1.029, 'eval_samples_per_second': 219.637, 'eval_steps_per_second': 28.184, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 226/2260 [01:07<06:09,  5.50it/s]  \n",
      " 10%|█         | 226/2260 [01:08<06:09,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6935251951217651, 'eval_runtime': 1.2246, 'eval_samples_per_second': 184.554, 'eval_steps_per_second': 23.682, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 339/2260 [01:50<05:28,  5.84it/s]  \n",
      " 15%|█▌        | 339/2260 [01:51<05:28,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5075335502624512, 'eval_runtime': 1.0791, 'eval_samples_per_second': 209.424, 'eval_steps_per_second': 26.873, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 452/2260 [02:34<05:10,  5.83it/s]  \n",
      " 20%|██        | 452/2260 [02:35<05:10,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3850293159484863, 'eval_runtime': 1.072, 'eval_samples_per_second': 210.814, 'eval_steps_per_second': 27.051, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 501/2260 [03:11<05:29,  5.34it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.05, 'learning_rate': 1.5575221238938054e-05, 'epoch': 4.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 565/2260 [03:23<05:08,  5.49it/s]\n",
      " 25%|██▌       | 565/2260 [03:24<05:08,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2826519012451172, 'eval_runtime': 1.1115, 'eval_samples_per_second': 203.333, 'eval_steps_per_second': 26.091, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 678/2260 [04:07<04:32,  5.80it/s]  \n",
      " 30%|███       | 678/2260 [04:09<04:32,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.204469919204712, 'eval_runtime': 1.1775, 'eval_samples_per_second': 191.932, 'eval_steps_per_second': 24.628, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 791/2260 [04:50<04:11,  5.84it/s]  \n",
      " 35%|███▌      | 791/2260 [04:51<04:11,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1226141452789307, 'eval_runtime': 1.0925, 'eval_samples_per_second': 206.857, 'eval_steps_per_second': 26.544, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 904/2260 [05:37<03:55,  5.75it/s]  \n",
      " 40%|████      | 904/2260 [05:38<03:55,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0495717525482178, 'eval_runtime': 1.1311, 'eval_samples_per_second': 199.809, 'eval_steps_per_second': 25.639, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1001/2260 [06:18<03:47,  5.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.045, 'learning_rate': 1.1150442477876106e-05, 'epoch': 8.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1017/2260 [06:21<03:30,  5.90it/s]\n",
      " 45%|████▌     | 1017/2260 [06:22<03:30,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9821604490280151, 'eval_runtime': 1.1075, 'eval_samples_per_second': 204.06, 'eval_steps_per_second': 26.185, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1130/2260 [07:06<03:13,  5.84it/s]  \n",
      " 50%|█████     | 1130/2260 [07:07<03:13,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9229294061660767, 'eval_runtime': 1.1007, 'eval_samples_per_second': 205.333, 'eval_steps_per_second': 26.348, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1243/2260 [07:52<03:02,  5.59it/s]  \n",
      " 55%|█████▌    | 1243/2260 [07:53<03:02,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8679027557373047, 'eval_runtime': 1.1222, 'eval_samples_per_second': 201.396, 'eval_steps_per_second': 25.843, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1356/2260 [08:38<02:44,  5.51it/s]  \n",
      " 60%|██████    | 1356/2260 [08:39<02:44,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8150554895401001, 'eval_runtime': 1.1029, 'eval_samples_per_second': 204.92, 'eval_steps_per_second': 26.295, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1469/2260 [09:22<02:14,  5.87it/s]  \n",
      " 65%|██████▌   | 1469/2260 [09:23<02:14,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7708607316017151, 'eval_runtime': 1.0803, 'eval_samples_per_second': 209.208, 'eval_steps_per_second': 26.845, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 1501/2260 [09:55<02:19,  5.44it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7085, 'learning_rate': 6.72566371681416e-06, 'epoch': 13.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1582/2260 [10:09<01:59,  5.65it/s]\n",
      " 70%|███████   | 1582/2260 [10:10<01:59,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7399626970291138, 'eval_runtime': 1.1943, 'eval_samples_per_second': 189.231, 'eval_steps_per_second': 24.282, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1695/2260 [10:56<01:33,  6.04it/s]  \n",
      " 75%|███████▌  | 1695/2260 [10:57<01:33,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7208396196365356, 'eval_runtime': 1.1384, 'eval_samples_per_second': 198.532, 'eval_steps_per_second': 25.475, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1808/2260 [11:39<01:20,  5.63it/s]  \n",
      " 80%|████████  | 1808/2260 [11:40<01:20,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.709347128868103, 'eval_runtime': 1.1043, 'eval_samples_per_second': 204.658, 'eval_steps_per_second': 26.261, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1921/2260 [12:26<01:01,  5.52it/s]  \n",
      " 85%|████████▌ | 1921/2260 [12:27<01:01,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7004119753837585, 'eval_runtime': 1.1255, 'eval_samples_per_second': 200.795, 'eval_steps_per_second': 25.766, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 2001/2260 [13:05<00:48,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5465, 'learning_rate': 2.3008849557522127e-06, 'epoch': 17.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 2034/2260 [13:11<00:38,  5.89it/s]\n",
      " 90%|█████████ | 2034/2260 [13:12<00:38,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6968504190444946, 'eval_runtime': 1.1239, 'eval_samples_per_second': 201.085, 'eval_steps_per_second': 25.803, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 2147/2260 [13:56<00:19,  5.94it/s]\n",
      " 95%|█████████▌| 2147/2260 [13:57<00:19,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6941794157028198, 'eval_runtime': 1.1049, 'eval_samples_per_second': 204.537, 'eval_steps_per_second': 26.246, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [14:43<00:00,  5.82it/s]\n",
      "100%|██████████| 2260/2260 [14:44<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6934356689453125, 'eval_runtime': 1.1093, 'eval_samples_per_second': 203.73, 'eval_steps_per_second': 26.142, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [15:08<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 909.6609, 'train_samples_per_second': 19.854, 'train_steps_per_second': 2.484, 'train_loss': 1.0219785707186808, 'epoch': 20.0}\n",
      "[INFO] preprocessing dataset for experiment p3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model for experiment p3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  5%|▌         | 113/2260 [00:20<05:55,  6.04it/s]\n",
      "  5%|▌         | 113/2260 [00:21<05:55,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2919058799743652, 'eval_runtime': 1.0951, 'eval_samples_per_second': 206.369, 'eval_steps_per_second': 26.481, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 226/2260 [01:03<05:43,  5.93it/s]  \n",
      " 10%|█         | 226/2260 [01:04<05:43,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6935251951217651, 'eval_runtime': 1.0952, 'eval_samples_per_second': 206.348, 'eval_steps_per_second': 26.478, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 339/2260 [01:50<05:31,  5.79it/s]  \n",
      " 15%|█▌        | 339/2260 [01:51<05:31,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5075335502624512, 'eval_runtime': 1.099, 'eval_samples_per_second': 205.641, 'eval_steps_per_second': 26.388, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 452/2260 [02:36<05:14,  5.74it/s]  \n",
      " 20%|██        | 452/2260 [02:37<05:14,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3850293159484863, 'eval_runtime': 1.0881, 'eval_samples_per_second': 207.701, 'eval_steps_per_second': 26.652, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 501/2260 [03:10<05:24,  5.42it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.05, 'learning_rate': 1.5575221238938054e-05, 'epoch': 4.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 565/2260 [03:21<04:48,  5.87it/s]\n",
      " 25%|██▌       | 565/2260 [03:22<04:48,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2826519012451172, 'eval_runtime': 1.0873, 'eval_samples_per_second': 207.858, 'eval_steps_per_second': 26.672, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 678/2260 [04:07<04:25,  5.96it/s]  \n",
      " 30%|███       | 678/2260 [04:08<04:25,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.204469919204712, 'eval_runtime': 1.0891, 'eval_samples_per_second': 207.51, 'eval_steps_per_second': 26.627, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 791/2260 [04:54<04:11,  5.84it/s]  \n",
      " 35%|███▌      | 791/2260 [04:55<04:11,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1226141452789307, 'eval_runtime': 1.1001, 'eval_samples_per_second': 205.434, 'eval_steps_per_second': 26.361, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 904/2260 [05:39<03:52,  5.84it/s]  \n",
      " 40%|████      | 904/2260 [05:40<03:52,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0495717525482178, 'eval_runtime': 1.0918, 'eval_samples_per_second': 207.004, 'eval_steps_per_second': 26.563, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1001/2260 [06:21<03:59,  5.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.045, 'learning_rate': 1.1150442477876106e-05, 'epoch': 8.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1017/2260 [06:24<03:37,  5.71it/s]\n",
      " 45%|████▌     | 1017/2260 [06:25<03:37,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9821604490280151, 'eval_runtime': 1.1376, 'eval_samples_per_second': 198.67, 'eval_steps_per_second': 25.493, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1130/2260 [07:08<03:25,  5.49it/s]  \n",
      " 50%|█████     | 1130/2260 [07:09<03:25,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9229294061660767, 'eval_runtime': 1.1407, 'eval_samples_per_second': 198.123, 'eval_steps_per_second': 25.423, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1243/2260 [07:53<02:49,  5.99it/s]  \n",
      " 55%|█████▌    | 1243/2260 [07:54<02:49,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8679027557373047, 'eval_runtime': 1.0878, 'eval_samples_per_second': 207.766, 'eval_steps_per_second': 26.66, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1356/2260 [08:40<02:26,  6.17it/s]  \n",
      " 60%|██████    | 1356/2260 [08:42<02:26,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8150554895401001, 'eval_runtime': 1.1085, 'eval_samples_per_second': 203.877, 'eval_steps_per_second': 26.161, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1469/2260 [09:24<02:12,  5.98it/s]  \n",
      " 65%|██████▌   | 1469/2260 [09:26<02:12,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7708607316017151, 'eval_runtime': 1.0683, 'eval_samples_per_second': 211.542, 'eval_steps_per_second': 27.145, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 1501/2260 [09:54<02:14,  5.66it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7085, 'learning_rate': 6.72566371681416e-06, 'epoch': 13.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1582/2260 [10:08<01:55,  5.90it/s]\n",
      " 70%|███████   | 1582/2260 [10:09<01:55,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7399626970291138, 'eval_runtime': 1.0748, 'eval_samples_per_second': 210.267, 'eval_steps_per_second': 26.981, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1695/2260 [10:51<01:31,  6.16it/s]  \n",
      " 75%|███████▌  | 1695/2260 [10:52<01:31,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7208396196365356, 'eval_runtime': 1.0813, 'eval_samples_per_second': 209.009, 'eval_steps_per_second': 26.82, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1808/2260 [11:35<01:18,  5.74it/s]  \n",
      " 80%|████████  | 1808/2260 [11:36<01:18,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.709347128868103, 'eval_runtime': 1.0783, 'eval_samples_per_second': 209.59, 'eval_steps_per_second': 26.894, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1921/2260 [12:20<00:56,  6.01it/s]\n",
      " 85%|████████▌ | 1921/2260 [12:21<00:56,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7004119753837585, 'eval_runtime': 1.0659, 'eval_samples_per_second': 212.024, 'eval_steps_per_second': 27.207, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 2001/2260 [13:03<00:46,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5465, 'learning_rate': 2.3008849557522127e-06, 'epoch': 17.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 2034/2260 [13:09<00:37,  6.01it/s]\n",
      " 90%|█████████ | 2034/2260 [13:10<00:37,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6968504190444946, 'eval_runtime': 1.161, 'eval_samples_per_second': 194.665, 'eval_steps_per_second': 24.979, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 2147/2260 [13:52<00:20,  5.63it/s]\n",
      " 95%|█████████▌| 2147/2260 [13:54<00:20,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6941794157028198, 'eval_runtime': 1.3898, 'eval_samples_per_second': 162.617, 'eval_steps_per_second': 20.867, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [14:37<00:00,  5.71it/s]\n",
      "100%|██████████| 2260/2260 [14:38<00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6934356689453125, 'eval_runtime': 1.2494, 'eval_samples_per_second': 180.889, 'eval_steps_per_second': 23.211, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [15:05<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 905.9792, 'train_samples_per_second': 19.934, 'train_steps_per_second': 2.495, 'train_loss': 1.0219785707186808, 'epoch': 20.0}\n"
     ]
    }
   ],
   "source": [
    "#constant\n",
    "SAVE_PATH = f'../models/preprocess_T5'\n",
    "PRETRAINED_MODEL = \"Wikidepia/IndoT5-base\"\n",
    "DATA_PATH = '../Data/quadruplet/quadruplet_annottated_sample_dataset_clean.csv'\n",
    "#variable\n",
    "max_length = 128\n",
    "text_col = 'content'\n",
    "label_col = 'quadruplet'\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "#training argument\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    SAVE_PATH,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    resume_from_checkpoint=True,\n",
    "    num_train_epochs=20,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "#read dataset\n",
    "raw_dataset = load_dataset('csv', data_files=DATA_PATH)\n",
    "#model training\n",
    "for i in range(4):\n",
    "    preprocess_type = f'p0{i}'\n",
    "    print(f\"[INFO] preprocessing dataset for experiment {preprocess_type}\")\n",
    "    #preprocess dataset\n",
    "    preprocessor = Preprocessor(f'{preprocess_type}', tokenizer, max_length, text_col, label_col)\n",
    "    tokenized_dataset = raw_dataset.map(preprocessor.preprocess_dataset, batched=True, remove_columns=raw_dataset['train'].column_names)\n",
    "    splitted_dataset = tokenized_dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
    "    print(f\"[INFO] training model for experiment {preprocess_type}\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained(PRETRAINED_MODEL)\n",
    "    finetuner = FineTuner(model=model, save_path=f\"{SAVE_PATH}_{preprocess_type}\", tokenizer=tokenizer, \n",
    "                      train_dataset=splitted_dataset['train'], eval_dataset=splitted_dataset['test'])\n",
    "    finetuner.fine_tune(training_args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference import ModelInference\n",
    "from src.preprocessor import Preprocessor\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constant\n",
    "max_length = 20\n",
    "text_col = 'content'\n",
    "label_col = 'postprocess_quad'\n",
    "preprocess_type = 'p00'\n",
    "SAVE_PATH = f'../models/quintuplet_t5_MLM-PT'\n",
    "PRETRAINED_MODEL = \"../models/pt-indot5-MLM_PT\" #\"Wikidepia/IndoT5-base\" \"../models/pt-indot5-MLM_PT\"\n",
    "TOKENIZER_PATH = \"Wikidepia/IndoT5-base\"\n",
    "DATA_PATH = '../Data/quadruplet/quadruplet_1k_clean.csv'\n",
    "inference_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(SAVE_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(preprocess_type, tokenizer, max_length, text_col, label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/danendra/.cache/huggingface/datasets/csv/default-afb3349ada6b2db0/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "Loading cached split indices for dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-afb3349ada6b2db0\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-0909deac7a1dd8f9.arrow and C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-afb3349ada6b2db0\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-1f57e62b69639f7c.arrow\n",
      "Loading cached processed dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-afb3349ada6b2db0\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-27503055701ea386.arrow\n",
      "                                                   \r"
     ]
    }
   ],
   "source": [
    "# raw_dataset = load_dataset('csv', data_files={\n",
    "#     'train' : f'{DATA_PATH}_train.csv',\n",
    "#     'test' : f'{DATA_PATH}_test.csv',\n",
    "#     'val' : f'{DATA_PATH}_val.csv'\n",
    "# })\n",
    "raw_dataset = load_dataset('csv', data_files=DATA_PATH)\n",
    "splitted_dataset = raw_dataset['train'].train_test_split(test_size=100, seed=42)\n",
    "tokenized_dataset = splitted_dataset.map(preprocessor.preprocess_dataset, batched=True, remove_columns=raw_dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anjim shope coan po hari bahkan kebatal gk dikirim, padahal kata c</s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_dataset['test']['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(shopee,coan po,kebatal gk dikirim,negative,delivery)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_dataset['test']['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:06<00:00,  1.86it/s]\n"
     ]
    }
   ],
   "source": [
    "model_inference = ModelInference(batch_size=8, dataset=tokenized_dataset['test'], model=model, \n",
    "                                 tokenizer=tokenizer, inference_len=512)\n",
    "pred_text = model_inference.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(shopee,_,di dom aku termasuk cepet dengan kondisi yg sekarang ini,positive,delivery)',\n",
       " '(shopee,_,lemot banget,negative,website&apps)',\n",
       " '(tiktok,scorl,susah,negative,produk)',\n",
       " '(olx,_,mengaku budget nya minim,negative,price)',\n",
       " '(shopee,shopee express,aman kok,positive,delivery)',\n",
       " '(bukalapak,top up,uang gue habis,negative,website&apps)',\n",
       " '(shopee,baju,sold out terus,negative,produk)',\n",
       " '(shopee,tempe,lebih enak,positive,produk)',\n",
       " '(shopee,_,kepencet2 sendiri,negative,website&apps)',\n",
       " '(shopee,paket,belum ada kabar,negative,delivery)',\n",
       " '(shopee,cs chat,tidak masalah,negative,website&apps)',\n",
       " '(shopee,shopee express,lama banget,negative,delivery)',\n",
       " '(olx,beli hp ini di tokobagus,positive,produk)',\n",
       " '(shopee,_,jadi jamet gini,negative,produk)',\n",
       " '(shopee,sepatu,bagus gak,positive,produk)',\n",
       " '(shopee,paket,kiriman dari &amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp',\n",
       " '(blibli,apps,aneh,negative,website&apps)',\n",
       " '(shopee,_,error,negative,website&apps)',\n",
       " '(shopee,buku dropbox,di ganti apa gimana,negative,website&apps)',\n",
       " '(shopee,status pengiriman,ngestuck,negative,delivery)',\n",
       " '(shopee,shopee,pada sulit dicari,negative,website&apps)',\n",
       " '(shopee,baju,ga secantik di gambar,negative,produk)',\n",
       " '(shopee,shopee express,sehari sampe,positive,delivery)',\n",
       " '(shopee,kemeja flanel,sold out,negative,produk)',\n",
       " '(shopee,komplen,parah sih,negative,customerservice)',\n",
       " '(shopee,shopee express,pake shopee express,positive,delivery)',\n",
       " '(shopee,apps,jelek bgt,negative,website&apps)',\n",
       " '(shopee,first impresionku,bagus itu,positive,produk)',\n",
       " '(shopee,insight shade,bagus bgt,positive,produk)',\n",
       " '(shopee,sicepat,seminggu ga berubah2 jd resi,negative,delivery)',\n",
       " '(shopee,paket,batalin sm sistem shopee,negative,delivery)',\n",
       " '(shopee,shopee expedisi,lebih cepat di dalam,positive,delivery)',\n",
       " '(shopee,_,lagi delay,negative,delivery)',\n",
       " '(lazada,_,mahal bgt,negative,price)',\n",
       " '(shopee,fs shopee era,kurang seneng,negative,website&apps)',\n",
       " '(shopee,shopee ofc store,lagi diskon juga,positive,price)',\n",
       " '(shopee,_,bisa turu tapi malah milih buka shopee,negative,website&apps)',\n",
       " '(shopee,shopee ex,gabisa milih ekspedisi apa ya,negative,delivery)',\n",
       " '(shopee,order via shopee,paling lama nyampe,negative,delivery)',\n",
       " '(shopee,review,positive,produk)',\n",
       " '(shopee,pengembalian dana,udah lewat dari jadwal kirim,negative,delivery)',\n",
       " '(lazada,gratong,bakal ada lagi ga ya,neutral,price)',\n",
       " '(shopee,chat shopee,dah dibalas semua,positive,customerservice)',\n",
       " '(olx,_,gajinya lumayan cuy,positive,price)',\n",
       " '(shopee,cs shopee,pengiriman lambat,negative,delivery)',\n",
       " '(shopee,ongkir,murah,positive,price)',\n",
       " '(lazada,diskon,suka bnyk,positive,price)',\n",
       " '(shopee,pengiriman shopee,emang muter\" ya,negative,delivery)',\n",
       " '(shopee,drop point,bisa banget ambil sendiri,positive,produk)',\n",
       " '(shopee,shopee pay later,lmbt bayar dia punya cal berkali2,negative,payment)',\n",
       " '(shopee,makelar,gampang bgt,positive,website&apps)',\n",
       " '(shopee,shopee paylater,metode pembayaran selalu kepencet,negative,payment)',\n",
       " '(shopee,barang2 di shopee,lucu2 bgt,positive,produk)',\n",
       " '(shopee,anteraja,besok iya di drop,negative,delivery)',\n",
       " '(shopee,jualan,bisa galaku,negative,price)',\n",
       " '(shopee,belanjanya,murah ye,positive,price)',\n",
       " '(shopee,shopee express,ngaco banget ini paket,negative,delivery)',\n",
       " '(shopee,haetomugi,trusted,positive,produk)',\n",
       " '(shopee,tarik saldo,stres bgt,negative,website&apps)',\n",
       " '(olx,kosan,murah2 dijual,positive,price)',\n",
       " '(shopee,paket,belum pada nyampe,negative,delivery)',\n",
       " '(shopee,paket,udah jam 12 malem,negative,delivery)',\n",
       " '(shopee,top up spay,ga keisi,negative,website&apps)',\n",
       " '(shopee,admin shopee,engga gede,negative,price)',\n",
       " '(shopee,shopee instant,gabisa,negative,website&apps)',\n",
       " '(shopee,bel,ga berpengaruh,negative,website&apps)',\n",
       " '(shopee,pesugihan,ada dark sidenya,negative,produk)',\n",
       " '(shopee,shopee express,biasanya lama bgt,negative,delivery)',\n",
       " '(shopee,paket,nyasar,negative,delivery)',\n",
       " '(shopee,_,tidak freeongkir,negative,price)',\n",
       " '(_,ninja xpress,ngestuck,negative,delivery)',\n",
       " '(shopee,checkout shopee,kurir bener,positive,website&apps)',\n",
       " '(shopee,notifnya spam,negative,website&apps)',\n",
       " '(olx,check cek harga,biasanya via online,positive,price)',\n",
       " '(shopee,baju,asli,positive,produk)',\n",
       " '(lazada,voc gratong,cuma dapet voc gratong,negative,price)',\n",
       " '(shopee,payment via shopee,ngelag gak jelas,negative,payment)',\n",
       " '(shopee,ongkir,bisa2nya ganti2,negative,price)',\n",
       " '(shopee,link,kuirim ke shopee,positive,website&apps)',\n",
       " '(shopee,visual,nyambung,positive,website&apps)',\n",
       " '(shopee,shopee express,lama bgt bangke,negative,delivery)',\n",
       " '(shopee,co shopee,pembayaran cod,gamau ditagih,negative,delivery)',\n",
       " '(bukalapak,kode ku,dpt tambahan cashback 50k,positive,price)',\n",
       " '(shopee,bajunya,lebih lucu,positive,produk)',\n",
       " '(shopee,paket jaemin dino,nyampe di home shopee,positive,delivery)',\n",
       " '(shopee,ekspedisi,pake reguler kirim smpe skrng,negative,delivery)',\n",
       " '(shopee,ekspedisi,lamanya minta ampun,negative,delivery)',\n",
       " '(shopee,pengiriman,emang pada delay,negative,delivery)',\n",
       " '(shopee,akun,dibatasi f02,negative,website&apps)',\n",
       " '(shopee,kurir shopee,kasian bgt,negative,delivery)',\n",
       " '(shopee,paket,tidak sesuai dengan yang diiklankan,negative,delivery)',\n",
       " '(shopee,barangku,ga diantar2,negative,delivery)',\n",
       " '(shopee,shopee express,cepet banget aman,positive,delivery)',\n",
       " '(shopee,shopee express,kurirnya berbicara sembarangan,negative,delivery)',\n",
       " '(shopee,shopee standar,lama bgt ini,negative,delivery)',\n",
       " '(shopee,stok mereka,baik2 aja,positive,produk)',\n",
       " '(blibli,voucher,menurun,negative,price)',\n",
       " '(shopee,cs shopee,pesanan pun batalkan,negative,customerservice)',\n",
       " '(blibli,tagihan telekomunikasi,gak bisa bayar,negative,payment)',\n",
       " '(shopee,shopee express,antri banget,negative,delivery)',\n",
       " '(lazada,voucher,banyak,positive,price)',\n",
       " '(shopee,shopee sicepat,barang gue tersesat,negative,delivery)',\n",
       " '(shopee,jnt,enak bgt,positive,produk)',\n",
       " '(shopee,notif pengembalian dana,gada gerak,negative,website&apps)']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-e45b5c90cd924547\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-3bb670568ff76367.arrow\n",
      "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 17.44ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61274"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = splitted_dataset['test']\n",
    "test_dataset = test_dataset.add_column(f'{preprocess_type}_model_prediction', pred_text)\n",
    "test_dataset.to_csv('../Data/quintuplet/mlm-model_1000-data_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['aoriginal_id', 'content', 'final_sentiment', 'baseline_aspect_category', 'tweet_type', 'clean_tweet', 'label', 'corrected_label', 'keterangan', 'quintuplet_label', 'postprocess_quintuplet', 'p00_model_prediction'],\n",
       "    num_rows: 104\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [01:01<00:00,  1.90it/s]\n"
     ]
    }
   ],
   "source": [
    "model_inference = ModelInference(batch_size=8, dataset=tokenized_dataset['train'], model=model, \n",
    "                                 tokenizer=tokenizer, inference_len=512)\n",
    "pred_text = model_inference.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\danendra\\.cache\\huggingface\\datasets\\csv\\default-e45b5c90cd924547\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-a9483cc938a1ab79.arrow\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 79.96ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "543207"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = splitted_dataset['train']\n",
    "train_dataset = train_dataset.add_column(f'{preprocess_type}_model_prediction', pred_text)\n",
    "train_dataset.to_csv('../Data/quintuplet/mlm-model_1000-data_predictions_train.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.evaluator import Evaluator\n",
    "from src.postprocessor import PostProcessor\n",
    "from src.utils import extract_triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aoriginal_id</th>\n",
       "      <th>content</th>\n",
       "      <th>final_sentiment</th>\n",
       "      <th>baseline_aspect_category</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>corrected_label</th>\n",
       "      <th>keterangan</th>\n",
       "      <th>quintuplet_label</th>\n",
       "      <th>postprocess_quintuplet</th>\n",
       "      <th>p00_model_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1646959047613227008</td>\n",
       "      <td>@discountfess Shopee aja, di dom aku termasuk ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>Shopee aja, di dom aku termasuk cepet dgn kon...</td>\n",
       "      <td>(shopee, shopee, cepet dgn kondisi yg skrng in...</td>\n",
       "      <td>(shopee, _, cepet dgn kondisi yg skrng ini, po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(shopee, _, cepet dgn kondisi yg skrng ini, po...</td>\n",
       "      <td>(shopee,_,cepet dgn kondisi yg skrng ini,posit...</td>\n",
       "      <td>(shopee,_,masuk akal dengan kondisi sekarang,p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1647278516495613954</td>\n",
       "      <td>shopee jelek bgt dah lemotnyaaaa</td>\n",
       "      <td>negative</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>shopee jelek bgt dah lemotnyaaaa</td>\n",
       "      <td>(shopee, shopee, jelek bgt dah lemotnyaaa, neg...</td>\n",
       "      <td>(shopee, _, jelek bgt dah lemotnyaaa, negative...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(shopee, _, jelek bgt dah lemotnyaaa, negative...</td>\n",
       "      <td>(shopee,_,jelek bgt dah lemotnyaaa,negative,we...</td>\n",
       "      <td>(shopee,_,lemot banget,negative,website&amp;apps)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1646549004757639168</td>\n",
       "      <td>@itsbeautyfess Aku juga susah nyari warna ston...</td>\n",
       "      <td>negative</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>Aku juga susah nyari warna stone pusing bgt s...</td>\n",
       "      <td>(shopee, warna stone, susah nyari, negative, p...</td>\n",
       "      <td>(shopee, warna stone, susah nyari, negative, p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(shopee, warna stone, susah nyari, negative, p...</td>\n",
       "      <td>(shopee,warna stone,susah nyari,negative,produ...</td>\n",
       "      <td>(shopee,warna stone,pusing bgt scorl,negative,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          aoriginal_id                                            content  \\\n",
       "0  1646959047613227008  @discountfess Shopee aja, di dom aku termasuk ...   \n",
       "1  1647278516495613954                   shopee jelek bgt dah lemotnyaaaa   \n",
       "2  1646549004757639168  @itsbeautyfess Aku juga susah nyari warna ston...   \n",
       "\n",
       "  final_sentiment baseline_aspect_category  tweet_type  \\\n",
       "0         neutral                  produk;  SUBJECTIVE   \n",
       "1        negative                  produk;  SUBJECTIVE   \n",
       "2        negative                  produk;  SUBJECTIVE   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0   Shopee aja, di dom aku termasuk cepet dgn kon...   \n",
       "1                   shopee jelek bgt dah lemotnyaaaa   \n",
       "2   Aku juga susah nyari warna stone pusing bgt s...   \n",
       "\n",
       "                                               label  \\\n",
       "0  (shopee, shopee, cepet dgn kondisi yg skrng in...   \n",
       "1  (shopee, shopee, jelek bgt dah lemotnyaaa, neg...   \n",
       "2  (shopee, warna stone, susah nyari, negative, p...   \n",
       "\n",
       "                                     corrected_label keterangan  \\\n",
       "0  (shopee, _, cepet dgn kondisi yg skrng ini, po...        NaN   \n",
       "1  (shopee, _, jelek bgt dah lemotnyaaa, negative...        NaN   \n",
       "2  (shopee, warna stone, susah nyari, negative, p...        NaN   \n",
       "\n",
       "                                    quintuplet_label  \\\n",
       "0  (shopee, _, cepet dgn kondisi yg skrng ini, po...   \n",
       "1  (shopee, _, jelek bgt dah lemotnyaaa, negative...   \n",
       "2  (shopee, warna stone, susah nyari, negative, p...   \n",
       "\n",
       "                              postprocess_quintuplet  \\\n",
       "0  (shopee,_,cepet dgn kondisi yg skrng ini,posit...   \n",
       "1  (shopee,_,jelek bgt dah lemotnyaaa,negative,we...   \n",
       "2  (shopee,warna stone,susah nyari,negative,produ...   \n",
       "\n",
       "                                p00_model_prediction  \n",
       "0  (shopee,_,masuk akal dengan kondisi sekarang,p...  \n",
       "1      (shopee,_,lemot banget,negative,website&apps)  \n",
       "2  (shopee,warna stone,pusing bgt scorl,negative,...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/quintuplet/mlm-model_1000-data_predictions.csv')\n",
    "df['postprocess_quintuplet'] = df['postprocess_quintuplet'].apply(lambda x:x.lower())\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessor = PostProcessor(use_postprocess=False)\n",
    "evaluator = Evaluator(task_type='quintuplet', postprocessor=postprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [00:00<00:00, 52009.97it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_scores, all_labels, all_preds = evaluator.evaluate(pred_seqs=df['p00_model_prediction'],\n",
    "                   gold_seqs=df['postprocess_quintuplet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.04672897196261682,\n",
       " 'recall': 0.04424778761061947,\n",
       " 'f1': 0.04545454545454546}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aoriginal_id</th>\n",
       "      <th>content</th>\n",
       "      <th>final_sentiment</th>\n",
       "      <th>baseline_aspect_category</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>corrected_label</th>\n",
       "      <th>keterangan</th>\n",
       "      <th>quintuplet_label</th>\n",
       "      <th>postprocess_quintuplet</th>\n",
       "      <th>p00_model_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1647261067511496704</td>\n",
       "      <td>eh mau lebaran kyk gini ekspedisi kan lagi hec...</td>\n",
       "      <td>negative</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>eh mau lebaran kyk gini ekspedisi kan lagi hec...</td>\n",
       "      <td>(shopee, shopee xpress, ekpsedisi kan lagi hec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(shopee, shopee xpress, ekpsedisi kan lagi hec...</td>\n",
       "      <td>(shopee,shopee xpress,ekpsedisi kan lagi hecti...</td>\n",
       "      <td>(shopee,shopee xpress,cepet pake,positive,deli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1646546316204597248</td>\n",
       "      <td>@tanyakanrl asli pernah lewat beranda tbtb ada...</td>\n",
       "      <td>negative</td>\n",
       "      <td>delivery; website&amp;apps; produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>asli pernah lewat beranda tbtb ada yg jual ko...</td>\n",
       "      <td>(shopee, konten dewasa, parah si kok bisa lolo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(shopee, konten dewasa, parah si kok bisa lolo...</td>\n",
       "      <td>(shopee,konten dewasa,parah si kok bisa lolos ...</td>\n",
       "      <td>(shopee,konten dewasa,parah si kok bisa lolos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1647243563443388416</td>\n",
       "      <td>Adeuh, ini barang gua dri shopee blm nyampai2 ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>delivery; customerservice; produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>Adeuh, ini barang gua dri shopee blm nyampai2 ...</td>\n",
       "      <td>(shopee, barang, blm nyampai2 jg woy, negative...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(shopee, barang, blm nyampai2 jg woy, negative...</td>\n",
       "      <td>(shopee,barang,blm nyampai2 jg woy,negative,de...</td>\n",
       "      <td>(shopee,barang,blm nyampai2 jg woy,negative,de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          aoriginal_id                                            content  \\\n",
       "0  1647261067511496704  eh mau lebaran kyk gini ekspedisi kan lagi hec...   \n",
       "1  1646546316204597248  @tanyakanrl asli pernah lewat beranda tbtb ada...   \n",
       "2  1647243563443388416  Adeuh, ini barang gua dri shopee blm nyampai2 ...   \n",
       "\n",
       "  final_sentiment            baseline_aspect_category  tweet_type  \\\n",
       "0        negative                             produk;  SUBJECTIVE   \n",
       "1        negative     delivery; website&apps; produk;  SUBJECTIVE   \n",
       "2        negative  delivery; customerservice; produk;  SUBJECTIVE   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  eh mau lebaran kyk gini ekspedisi kan lagi hec...   \n",
       "1   asli pernah lewat beranda tbtb ada yg jual ko...   \n",
       "2  Adeuh, ini barang gua dri shopee blm nyampai2 ...   \n",
       "\n",
       "                                               label corrected_label  \\\n",
       "0  (shopee, shopee xpress, ekpsedisi kan lagi hec...             NaN   \n",
       "1  (shopee, konten dewasa, parah si kok bisa lolo...             NaN   \n",
       "2  (shopee, barang, blm nyampai2 jg woy, negative...             NaN   \n",
       "\n",
       "  keterangan                                   quintuplet_label  \\\n",
       "0        NaN  (shopee, shopee xpress, ekpsedisi kan lagi hec...   \n",
       "1        NaN  (shopee, konten dewasa, parah si kok bisa lolo...   \n",
       "2        NaN  (shopee, barang, blm nyampai2 jg woy, negative...   \n",
       "\n",
       "                              postprocess_quintuplet  \\\n",
       "0  (shopee,shopee xpress,ekpsedisi kan lagi hecti...   \n",
       "1  (shopee,konten dewasa,parah si kok bisa lolos ...   \n",
       "2  (shopee,barang,blm nyampai2 jg woy,negative,de...   \n",
       "\n",
       "                                p00_model_prediction  \n",
       "0  (shopee,shopee xpress,cepet pake,positive,deli...  \n",
       "1  (shopee,konten dewasa,parah si kok bisa lolos ...  \n",
       "2  (shopee,barang,blm nyampai2 jg woy,negative,de...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/quintuplet/mlm-model_1000-data_predictions_train.csv')\n",
    "df['postprocess_quintuplet'] = df['postprocess_quintuplet'].apply(lambda x:x.lower())\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 930/930 [00:00<00:00, 116092.34it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_scores, all_labels, all_preds = evaluator.evaluate(pred_seqs=df['p00_model_prediction'],\n",
    "                   gold_seqs=df['postprocess_quintuplet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.6859852476290832,\n",
       " 'recall': 0.6314258001939864,\n",
       " 'f1': 0.6575757575757576}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

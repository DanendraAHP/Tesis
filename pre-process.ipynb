{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_28324\\2852429949.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train = pd.read_csv('Data/post-train/ASTE/train.txt', sep='.####', header=None, names=['input', 'label'])\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_28324\\2852429949.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test = pd.read_csv('Data/post-train/ASTE/dev.txt', sep='.####', header=None, names=['input', 'label'])\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_28324\\2852429949.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dev = pd.read_csv('Data/post-train/ASTE/test.txt', sep='.####', header=None, names=['input', 'label'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pelayanan ramah , kamar nyaman dan fasilitas l...</td>\n",
       "      <td>([0], [1], 'POS'), ([3], [4], 'POS'), ([6], [7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tidak terlalu jauh dari pusat kota</td>\n",
       "      <td>([3, 4, 5], [0, 1, 2], 'POS')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dengan harga terjangkau kita sudah mendapatkan...</td>\n",
       "      <td>([1], [2], 'POS'), ([6], [8], 'POS')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kondisinya cukup baik , hanya dapatnya tempat ...</td>\n",
       "      <td>([0], [1, 2], 'POS'), ([5, 6], [8, 9], 'NEG'),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kamar bersih , bentuknya unik , tetapi sinyal ...</td>\n",
       "      <td>([0], [1], 'POS'), ([3], [4], 'POS'), ([7, 8],...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  pelayanan ramah , kamar nyaman dan fasilitas l...   \n",
       "1                tidak terlalu jauh dari pusat kota    \n",
       "2  dengan harga terjangkau kita sudah mendapatkan...   \n",
       "3  kondisinya cukup baik , hanya dapatnya tempat ...   \n",
       "4  kamar bersih , bentuknya unik , tetapi sinyal ...   \n",
       "\n",
       "                                               label  \n",
       "0  ([0], [1], 'POS'), ([3], [4], 'POS'), ([6], [7...  \n",
       "1                      ([3, 4, 5], [0, 1, 2], 'POS')  \n",
       "2               ([1], [2], 'POS'), ([6], [8], 'POS')  \n",
       "3  ([0], [1, 2], 'POS'), ([5, 6], [8, 9], 'NEG'),...  \n",
       "4  ([0], [1], 'POS'), ([3], [4], 'POS'), ([7, 8],...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "train = pd.read_csv('Data/post-train/ASTE/train.txt', sep='.####', header=None, names=['input', 'label'])\n",
    "train['label'] = train['label'].apply(lambda x:x[1:-1])\n",
    "#test\n",
    "test = pd.read_csv('Data/post-train/ASTE/dev.txt', sep='.####', header=None, names=['input', 'label'])\n",
    "test['label'] = test['label'].apply(lambda x:x[1:-1])\n",
    "#dev\n",
    "dev = pd.read_csv('Data/post-train/ASTE/test.txt', sep='.####', header=None, names=['input', 'label'])\n",
    "dev['label'] = dev['label'].apply(lambda x:x[1:-1])\n",
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]+test.shape[0]+dev.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_int(duplet):\n",
    "    for d in range(len(duplet)):\n",
    "        for i in range(len(duplet[d])):\n",
    "            duplet[d][i]=int(duplet[d][i])\n",
    "    return duplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_duplet(out):\n",
    "    #untuk 1 output\n",
    "    all_triplet = out.split(\"),\")\n",
    "    #find all in closed bracket\n",
    "    duplet = [re.findall('\\[(.*?)\\]', triplet) for triplet in all_triplet]\n",
    "    duplet = [[i.split(',') for i in d] for d in duplet]\n",
    "    duplet = [convert_int(d) for d in duplet]\n",
    "    #find all sentiment\n",
    "    sentiment = [re.findall(\"\\'.*?\\'\", triplet) for triplet in all_triplet]\n",
    "    sentiment = [sent[0][1:-1] for sent in sentiment]\n",
    "    return duplet, sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ubah angka ke kata\n",
    "def convert_int_string(inp, duplet):\n",
    "    inp_list = inp.split()\n",
    "    for i in range(len(duplet)):\n",
    "        for j in range(len(duplet[i])):\n",
    "            for k in range(len(duplet[i][j])):\n",
    "                duplet[i][j][k] = inp_list[duplet[i][j][k]]\n",
    "    return duplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_triplet(inp, out):\n",
    "    duplet, sentiment = convert_duplet(out)\n",
    "    duplet = convert_int_string(inp, duplet)\n",
    "    label = [duplet[i]+[sentiment[i]] for i in range(len(duplet))]\n",
    "    #all triplet in triplets\n",
    "    triplet_str_arr = []\n",
    "    for i,triplet in enumerate(label):\n",
    "        triplet_str = \"\"\n",
    "        #get all tuple\n",
    "        for j,tuple in enumerate(triplet):\n",
    "            #get all aspect from the same tuple\n",
    "            if type(tuple)==str:\n",
    "                triplet_str+=tuple\n",
    "            else:\n",
    "                triplet_str+=\" \".join(tuple)\n",
    "            if j<(len(triplet)-1):\n",
    "                triplet_str+=','\n",
    "        triplet_str=f'({triplet_str})'\n",
    "        if i<(len(label)-1):\n",
    "            triplet_str+=';'\n",
    "        triplet_str_arr.append(triplet_str)\n",
    "    label = \"\".join(triplet_str_arr)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_label(df, x, y):\n",
    "    labels = []\n",
    "    errors = []\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            row = df.iloc[i]\n",
    "            inp = row[x]\n",
    "            out = row[y]\n",
    "            triplet = convert_triplet(inp, out)\n",
    "            labels.append(triplet)\n",
    "        except:\n",
    "            errors.append(i)\n",
    "    return labels, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, train_errors = transform_label(train, 'input', 'label')\n",
    "y_test, test_errors = transform_label(test, 'input', 'label')\n",
    "y_dev, dev_errors = transform_label(dev, 'input', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train_errors)\n",
    "test = test.drop(test_errors)\n",
    "dev = dev.drop(dev_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['triplet'] = y_train\n",
    "test['triplet'] = y_test\n",
    "dev['triplet'] = y_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('Data/post-train/ASTE/train.csv', index=False)\n",
    "test.to_csv('Data/post-train/ASTE/test.csv', index=False)\n",
    "dev.to_csv('Data/post-train/ASTE/dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([train, test, dev]).to_csv('Data/post-train/ASTE/all_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danendra\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>('place', 'restaurant general', 'negative')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We , there were four of us , arrived at noon -...</td>\n",
       "      <td>('staff', 'service general', 'negative')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles , ...</td>\n",
       "      <td>('NULL', 'service general', 'negative')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>('food', 'food quality', 'negative'), ('portio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After all that , they complained to me about t...</td>\n",
       "      <td>('NULL', 'service general', 'negative')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  Judging from previous posts this used to be a ...   \n",
       "1  We , there were four of us , arrived at noon -...   \n",
       "2  They never brought us complimentary noodles , ...   \n",
       "3  The food was lousy - too sweet or too salty an...   \n",
       "4  After all that , they complained to me about t...   \n",
       "\n",
       "                                               label  \n",
       "0        ('place', 'restaurant general', 'negative')  \n",
       "1           ('staff', 'service general', 'negative')  \n",
       "2            ('NULL', 'service general', 'negative')  \n",
       "3  ('food', 'food quality', 'negative'), ('portio...  \n",
       "4            ('NULL', 'service general', 'negative')  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "train = pd.read_csv('D:/Kuliah/S2/Tesis/Code/Generative-ABSA-main/data/tasd/rest15/train.txt', sep='.####', header=None, names=['input', 'label'])\n",
    "train['label'] = train['label'].apply(lambda x:x[1:-1])\n",
    "#test\n",
    "test = pd.read_csv('D:/Kuliah/S2/Tesis/Code/Generative-ABSA-main/data/tasd/rest15/test.txt', sep='.####', header=None, names=['input', 'label'])\n",
    "test['label'] = test['label'].apply(lambda x:x[1:-1])\n",
    "#dev\n",
    "dev = pd.read_csv('D:/Kuliah/S2/Tesis/Code/Generative-ABSA-main/data/tasd/rest15/dev.txt', sep='.####', header=None, names=['input', 'label'])\n",
    "dev['label'] = dev['label'].apply(lambda x:x[1:-1])\n",
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>('place', 'restaurant general', 'negative')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We , there were four of us , arrived at noon -...</td>\n",
       "      <td>('staff', 'service general', 'negative')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles , ...</td>\n",
       "      <td>('NULL', 'service general', 'negative')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>('food', 'food quality', 'negative'), ('portio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After all that , they complained to me about t...</td>\n",
       "      <td>('NULL', 'service general', 'negative')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Avoid this place</td>\n",
       "      <td>('place', 'restaurant general', 'negative')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I have eaten at Saul , many times , the food i...</td>\n",
       "      <td>('food', 'food quality', 'positive')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Saul is the best restaurant on Smith Street an...</td>\n",
       "      <td>('Saul', 'restaurant general', 'positive')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The duck confit is always amazing and the foie...</td>\n",
       "      <td>('foie gras terrine with figs', 'food quality'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The wine list is interesting and has many good...</td>\n",
       "      <td>('wine list', 'drinks style_options', 'positiv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1712 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                input  \\\n",
       "0   Judging from previous posts this used to be a ...   \n",
       "1   We , there were four of us , arrived at noon -...   \n",
       "2   They never brought us complimentary noodles , ...   \n",
       "3   The food was lousy - too sweet or too salty an...   \n",
       "4   After all that , they complained to me about t...   \n",
       "..                                                ...   \n",
       "5                                   Avoid this place    \n",
       "6   I have eaten at Saul , many times , the food i...   \n",
       "7   Saul is the best restaurant on Smith Street an...   \n",
       "8   The duck confit is always amazing and the foie...   \n",
       "9   The wine list is interesting and has many good...   \n",
       "\n",
       "                                                label  \n",
       "0         ('place', 'restaurant general', 'negative')  \n",
       "1            ('staff', 'service general', 'negative')  \n",
       "2             ('NULL', 'service general', 'negative')  \n",
       "3   ('food', 'food quality', 'negative'), ('portio...  \n",
       "4             ('NULL', 'service general', 'negative')  \n",
       "..                                                ...  \n",
       "5         ('place', 'restaurant general', 'negative')  \n",
       "6                ('food', 'food quality', 'positive')  \n",
       "7          ('Saul', 'restaurant general', 'positive')  \n",
       "8   ('foie gras terrine with figs', 'food quality'...  \n",
       "9   ('wine list', 'drinks style_options', 'positiv...  \n",
       "\n",
       "[1712 rows x 2 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasd_df = pd.concat([train, test, dev])\n",
    "tasd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>aste_label</th>\n",
       "      <th>triplet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>([10], [9], 'NEG')</td>\n",
       "      <td>(place,good,NEG)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We , there were four of us , arrived at noon -...</td>\n",
       "      <td>([19], [31], 'NEG')</td>\n",
       "      <td>(staff,rude,NEG)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>([1], [3], 'NEG'), ([1], [5, 6], 'NEG'), ([1],...</td>\n",
       "      <td>(food,lousy,NEG);(food,too sweet,NEG);(food,to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avoid this place</td>\n",
       "      <td>([2], [0], 'NEG')</td>\n",
       "      <td>(place,Avoid,NEG)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have eaten at Saul , many times , the food i...</td>\n",
       "      <td>([10], [16], 'POS')</td>\n",
       "      <td>(food,good,POS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>The food is okay and the prices here are medio...</td>\n",
       "      <td>([1], [3], 'NEU')</td>\n",
       "      <td>(food,okay,NEU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>Baluchi 's has solid food and a nice decor at ...</td>\n",
       "      <td>([4], [3], 'POS'), ([8], [7], 'POS'), ([0, 1],...</td>\n",
       "      <td>(food,solid,POS);(decor,nice,POS);(Baluchi 's,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>$ 20 for all you can eat sushi can not be beaten</td>\n",
       "      <td>([3, 4, 5, 6, 7], [11], 'POS')</td>\n",
       "      <td>(all you can eat sushi,beaten,POS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>The vibe is very relaxed and cozy , service wa...</td>\n",
       "      <td>([1], [4], 'POS'), ([1], [6], 'POS'), ([8], [1...</td>\n",
       "      <td>(vibe,relaxed,POS);(vibe,cozy,POS);(service,gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>Never have I had such dramatic delivery guys (...</td>\n",
       "      <td>([6, 7], [5], 'NEG')</td>\n",
       "      <td>(delivery guys,dramatic,NEG)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1075 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  input  \\\n",
       "0     Judging from previous posts this used to be a ...   \n",
       "1     We , there were four of us , arrived at noon -...   \n",
       "2     The food was lousy - too sweet or too salty an...   \n",
       "3                                     Avoid this place    \n",
       "4     I have eaten at Saul , many times , the food i...   \n",
       "...                                                 ...   \n",
       "1070  The food is okay and the prices here are medio...   \n",
       "1071  Baluchi 's has solid food and a nice decor at ...   \n",
       "1072  $ 20 for all you can eat sushi can not be beaten    \n",
       "1073  The vibe is very relaxed and cozy , service wa...   \n",
       "1074  Never have I had such dramatic delivery guys (...   \n",
       "\n",
       "                                             aste_label  \\\n",
       "0                                    ([10], [9], 'NEG')   \n",
       "1                                   ([19], [31], 'NEG')   \n",
       "2     ([1], [3], 'NEG'), ([1], [5, 6], 'NEG'), ([1],...   \n",
       "3                                     ([2], [0], 'NEG')   \n",
       "4                                   ([10], [16], 'POS')   \n",
       "...                                                 ...   \n",
       "1070                                  ([1], [3], 'NEU')   \n",
       "1071  ([4], [3], 'POS'), ([8], [7], 'POS'), ([0, 1],...   \n",
       "1072                     ([3, 4, 5, 6, 7], [11], 'POS')   \n",
       "1073  ([1], [4], 'POS'), ([1], [6], 'POS'), ([8], [1...   \n",
       "1074                               ([6, 7], [5], 'NEG')   \n",
       "\n",
       "                                                triplet  \n",
       "0                                      (place,good,NEG)  \n",
       "1                                      (staff,rude,NEG)  \n",
       "2     (food,lousy,NEG);(food,too sweet,NEG);(food,to...  \n",
       "3                                     (place,Avoid,NEG)  \n",
       "4                                       (food,good,POS)  \n",
       "...                                                 ...  \n",
       "1070                                    (food,okay,NEU)  \n",
       "1071  (food,solid,POS);(decor,nice,POS);(Baluchi 's,...  \n",
       "1072                 (all you can eat sushi,beaten,POS)  \n",
       "1073  (vibe,relaxed,POS);(vibe,cozy,POS);(service,gr...  \n",
       "1074                       (delivery guys,dramatic,NEG)  \n",
       "\n",
       "[1075 rows x 3 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aste data\n",
    "aste_df = pd.read_csv('D:/Kuliah/S2/Tesis/Code/Generative-ABSA-main/data/aste/rest15/all_data.csv')\n",
    "aste_df = aste_df.rename(columns={'label':'aste_label'})\n",
    "aste_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1075, 3)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aste_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>aste_label</th>\n",
       "      <th>triplet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>([10], [9], 'NEG')</td>\n",
       "      <td>(place,good,NEG)</td>\n",
       "      <td>('place', 'restaurant general', 'negative')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We , there were four of us , arrived at noon -...</td>\n",
       "      <td>([19], [31], 'NEG')</td>\n",
       "      <td>(staff,rude,NEG)</td>\n",
       "      <td>('staff', 'service general', 'negative')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>([1], [3], 'NEG'), ([1], [5, 6], 'NEG'), ([1],...</td>\n",
       "      <td>(food,lousy,NEG);(food,too sweet,NEG);(food,to...</td>\n",
       "      <td>('food', 'food quality', 'negative'), ('portio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avoid this place</td>\n",
       "      <td>([2], [0], 'NEG')</td>\n",
       "      <td>(place,Avoid,NEG)</td>\n",
       "      <td>('place', 'restaurant general', 'negative')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have eaten at Saul , many times , the food i...</td>\n",
       "      <td>([10], [16], 'POS')</td>\n",
       "      <td>(food,good,POS)</td>\n",
       "      <td>('food', 'food quality', 'positive')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>whoever the jazz duo was , they were on POINT</td>\n",
       "      <td>([2, 3], [8, 9], 'POS')</td>\n",
       "      <td>(jazz duo,on POINT,POS)</td>\n",
       "      <td>('jazz duo', 'ambience general', 'positive')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>even the wine by the glass was good</td>\n",
       "      <td>([2, 3, 4, 5], [7], 'POS')</td>\n",
       "      <td>(wine by the glass,good,POS)</td>\n",
       "      <td>('wine by the glass', 'drinks quality', 'posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>The food is okay and the prices here are medio...</td>\n",
       "      <td>([1], [3], 'NEU')</td>\n",
       "      <td>(food,okay,NEU)</td>\n",
       "      <td>('food', 'food quality', 'neutral'), ('NULL', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>Baluchi 's has solid food and a nice decor at ...</td>\n",
       "      <td>([4], [3], 'POS'), ([8], [7], 'POS'), ([0, 1],...</td>\n",
       "      <td>(food,solid,POS);(decor,nice,POS);(Baluchi 's,...</td>\n",
       "      <td>('food', 'food quality', 'positive'), ('decor'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>The vibe is very relaxed and cozy , service wa...</td>\n",
       "      <td>([1], [4], 'POS'), ([1], [6], 'POS'), ([8], [1...</td>\n",
       "      <td>(vibe,relaxed,POS);(vibe,cozy,POS);(service,gr...</td>\n",
       "      <td>('vibe', 'ambience general', 'positive'), ('se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>842 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  input  \\\n",
       "0     Judging from previous posts this used to be a ...   \n",
       "1     We , there were four of us , arrived at noon -...   \n",
       "2     The food was lousy - too sweet or too salty an...   \n",
       "3                                     Avoid this place    \n",
       "4     I have eaten at Saul , many times , the food i...   \n",
       "...                                                 ...   \n",
       "1068     whoever the jazz duo was , they were on POINT    \n",
       "1069               even the wine by the glass was good    \n",
       "1070  The food is okay and the prices here are medio...   \n",
       "1071  Baluchi 's has solid food and a nice decor at ...   \n",
       "1073  The vibe is very relaxed and cozy , service wa...   \n",
       "\n",
       "                                             aste_label  \\\n",
       "0                                    ([10], [9], 'NEG')   \n",
       "1                                   ([19], [31], 'NEG')   \n",
       "2     ([1], [3], 'NEG'), ([1], [5, 6], 'NEG'), ([1],...   \n",
       "3                                     ([2], [0], 'NEG')   \n",
       "4                                   ([10], [16], 'POS')   \n",
       "...                                                 ...   \n",
       "1068                            ([2, 3], [8, 9], 'POS')   \n",
       "1069                         ([2, 3, 4, 5], [7], 'POS')   \n",
       "1070                                  ([1], [3], 'NEU')   \n",
       "1071  ([4], [3], 'POS'), ([8], [7], 'POS'), ([0, 1],...   \n",
       "1073  ([1], [4], 'POS'), ([1], [6], 'POS'), ([8], [1...   \n",
       "\n",
       "                                                triplet  \\\n",
       "0                                      (place,good,NEG)   \n",
       "1                                      (staff,rude,NEG)   \n",
       "2     (food,lousy,NEG);(food,too sweet,NEG);(food,to...   \n",
       "3                                     (place,Avoid,NEG)   \n",
       "4                                       (food,good,POS)   \n",
       "...                                                 ...   \n",
       "1068                            (jazz duo,on POINT,POS)   \n",
       "1069                       (wine by the glass,good,POS)   \n",
       "1070                                    (food,okay,NEU)   \n",
       "1071  (food,solid,POS);(decor,nice,POS);(Baluchi 's,...   \n",
       "1073  (vibe,relaxed,POS);(vibe,cozy,POS);(service,gr...   \n",
       "\n",
       "                                                  label  \n",
       "0           ('place', 'restaurant general', 'negative')  \n",
       "1              ('staff', 'service general', 'negative')  \n",
       "2     ('food', 'food quality', 'negative'), ('portio...  \n",
       "3           ('place', 'restaurant general', 'negative')  \n",
       "4                  ('food', 'food quality', 'positive')  \n",
       "...                                                 ...  \n",
       "1068       ('jazz duo', 'ambience general', 'positive')  \n",
       "1069  ('wine by the glass', 'drinks quality', 'posit...  \n",
       "1070  ('food', 'food quality', 'neutral'), ('NULL', ...  \n",
       "1071  ('food', 'food quality', 'positive'), ('decor'...  \n",
       "1073  ('vibe', 'ambience general', 'positive'), ('se...  \n",
       "\n",
       "[842 rows x 4 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = aste_df.join(tasd_df.set_index('input'), on='input')\n",
    "merged_df = merged_df[~merged_df.index.duplicated(keep='first')]\n",
    "merged_df = merged_df.dropna()\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add to that great service and great food at a reasonable price and you have yourself the beginning of a great evening \n",
      "([4], [3], 'POS'), ([7], [6], 'POS')\n",
      "(service,great,POS);(food,great,POS)\n",
      "('service', 'service general', 'positive'), ('food', 'food quality', 'positive'), ('food', 'food prices', 'positive')\n"
     ]
    }
   ],
   "source": [
    "idx = random.randint(0, len(merged_df))\n",
    "row = merged_df.iloc[idx]\n",
    "inp = row['input']\n",
    "triplet = row['triplet']\n",
    "aste_label = row['aste_label']\n",
    "label = row['label']\n",
    "print(inp)\n",
    "print(aste_label)\n",
    "print(triplet)\n",
    "print(label)\n",
    "all_categories = label.split(')')\n",
    "#all_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pairs(label):\n",
    "    \"\"\"\n",
    "    get all pairs from TASD label, the pair is\n",
    "    (aspect, aspect category)\n",
    "    \"\"\"\n",
    "    all_tasd = re.findall('\\[(.*?)\\]', label.replace('(','[').replace(')',']').replace(\"'\",''))\n",
    "    all_tasd = [tasd.split(',') for tasd in all_tasd]\n",
    "    all_pair = [(tasd[0].strip(), tasd[1].strip()) for tasd in all_tasd]\n",
    "    return all_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_quadruplet(pairs, triplets):\n",
    "    triplets = triplets.split(';')\n",
    "    triplets = [triplet[1:-1].split(',') for triplet in triplets]\n",
    "    quadruplets = []\n",
    "    #triplet_list[0] is aspect\n",
    "    for triplet in triplets:\n",
    "        aspect = triplet[0]\n",
    "        quadruplet=[]\n",
    "        for pair in pairs:\n",
    "            #if aspect in pair from TASD is the same as \n",
    "            #aspect in triplet from ASTE then combine it\n",
    "            if pair[0]==aspect:\n",
    "                quadruplet = triplet+[pair[1]]\n",
    "        #if there are no same aspect from TASD in ASTE that means\n",
    "        #we will drop the triplet\n",
    "        if len(quadruplet)>=4:\n",
    "            quadruplets.append(quadruplet)\n",
    "    return quadruplets\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_quadruplet(quadruplets):\n",
    "    quadruplets_str = ''\n",
    "    for i,quadruplet in enumerate(quadruplets):\n",
    "        quadruplet_str = f'({str(quadruplet)})'\n",
    "        quadruplets_str+=quadruplet_str.replace('[','').replace(']','').replace(\"'\",'')\n",
    "        if i<(len(quadruplets)-1):\n",
    "            quadruplets_str+=';'\n",
    "    return quadruplets_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An excellent servic\n",
      "(servic,excellent,POS)\n",
      "('service', 'service general', 'positive')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#idx = random.randint(0, len(merged_df))\n",
    "idx=305\n",
    "row = merged_df.iloc[idx]\n",
    "inp = row['input']\n",
    "triplet = row['triplet']\n",
    "aste_label = row['aste_label']\n",
    "label = row['label']\n",
    "print(inp)\n",
    "print(triplet)\n",
    "print(label)\n",
    "#pair\n",
    "all_pair = extract_pairs(label)\n",
    "#quadruplet\n",
    "quadruplet = convert_to_quadruplet(all_pair, triplet)\n",
    "quadruplet = string_quadruplet(quadruplet)\n",
    "print(quadruplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_quadruplet(df, triplet_col, tasd_col):\n",
    "    quadruplets = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        triplet = row[triplet_col]\n",
    "        label = row[tasd_col]\n",
    "        #pair\n",
    "        all_pair = extract_pairs(label)\n",
    "        #quadruplet\n",
    "        quadruplet = convert_to_quadruplet(all_pair, triplet)\n",
    "        quadruplet = string_quadruplet(quadruplet)\n",
    "        quadruplets.append(quadruplet)\n",
    "    return quadruplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(place, good, NEG, restaurant general)',\n",
       " '(staff, rude, NEG, service general)',\n",
       " '(food, lousy, NEG, food quality);(food, too sweet, NEG, food quality);(food, too salty, NEG, food quality);(portions, tiny, NEG, food style_options)',\n",
       " '(place, Avoid, NEG, restaurant general)',\n",
       " '(food, good, POS, food quality)',\n",
       " '(Saul, best, POS, restaurant general)',\n",
       " '(foie gras terrine with figs, out of this world, POS, food quality);(duck confit, amazing, POS, food quality)',\n",
       " '(wine list, interesting, POS, drinks prices);(wine list, good values, POS, drinks prices)',\n",
       " '(restaurant, disappointed, NEG, restaurant general)',\n",
       " '(Food, okay, NEU, food quality);(Food, nothing great, NEU, food quality)',\n",
       " '(service, excellent, POS, service general);(decor, cool, POS, ambience general);(decor, understated, POS, ambience general)',\n",
       " '(duck breast special, incredible, POS, food quality)',\n",
       " '(Grilled Chicken special with Edamame Puree, enjoyed, POS, food quality)',\n",
       " '(food, decent, NEU, food quality)',\n",
       " '(place, best, POS, restaurant general)',\n",
       " '(Food, great, POS, food quality)',\n",
       " '(Service, top notch, POS, service general)',\n",
       " '(half price sushi deal, worth, POS, food quality)',\n",
       " '(crowd, attracted, POS, restaurant miscellaneous)',\n",
       " '(dishes, great, POS, food quality)',\n",
       " '(food, good, POS, food quality)',\n",
       " '(service, varys, NEG, service general)',\n",
       " '(ambience, pretty, POS, ambience general);(ambience, nice, POS, ambience general)',\n",
       " '(lava cake dessert, incredible, POS, food quality);(lava cake dessert, recommend, POS, food quality)',\n",
       " '(Cosette, off-the-beaten, POS, ambience general)',\n",
       " '(restaurant, tiny, POS, ambience general);(restaurant, cozy, POS, ambience general)',\n",
       " '(pizza, overpriced, NEG, food prices);(pizza, soggy, NEG, food prices)',\n",
       " '(meals, best, POS, food quality)',\n",
       " '(seafood, amazing, POS, food quality);(wine list, good, POS, drinks style_options);(menu, ever-changing, POS, food style_options);(menu, great surprises, POS, food style_options)',\n",
       " '(ingredients, super-fresh, POS, food quality);(ingredients, delicious, POS, food quality)',\n",
       " '(Pastrami, Best, POS, food quality);(portion, great, POS, food style_options)',\n",
       " '(fried shrimp, huge, POS, food quality);(fried shrimp, loved, POS, food quality)',\n",
       " '(place, amazed, POS, restaurant general)',\n",
       " '(signs, Japanese, POS, restaurant miscellaneous);(specials menus, Japanese, POS, food style_options);(food, Japanese, POS, food quality);(waitstaff, Japanese, POS, service general)',\n",
       " '(place, worth, POS, restaurant general)',\n",
       " '(staff, enjoy, POS, service general);(staff, young, POS, service general);(staff, not always well trained, POS, service general);(staff, friendly, POS, service general)',\n",
       " '(wine, Decent, POS, drinks prices)',\n",
       " '(place, favorite, POS, restaurant general)',\n",
       " '(service, excellent, POS, service general);(decor, great, POS, ambience general);(food, delicious, POS, food quality);(portions, large, POS, food style_options)',\n",
       " '(Gnocchi, partial, POS, restaurant general)',\n",
       " '(place, tiny, NEG, ambience general)',\n",
       " '(hostess, rude, NEG, service general);(hostess, offensive, NEG, service general)',\n",
       " '(food, great, POS, food quality);(wine, great, POS, drinks quality);(service, great, POS, service general)',\n",
       " '(wait, short, POS, service general)',\n",
       " '(glass of wine, great, POS, drinks quality)',\n",
       " '(service, great, POS, service general);(service, fast, POS, service general)',\n",
       " '(people, friendly, POS, service general)',\n",
       " '(place, try, POS, restaurant general)',\n",
       " '(restaurant, fun, POS, restaurant general)',\n",
       " '(pizza, yummy, POS, food quality);(atmoshpere, like, POS, ambience general)',\n",
       " '(pizza, expensive, NEG, food prices)',\n",
       " '(place, great, POS, restaurant general)',\n",
       " '(waitress, patient, POS, service general);(food, phenomenal, POS, food quality)',\n",
       " '(Service, prompt, POS, service general);(Service, friendly, POS, service general);(Service, great, POS, service general)',\n",
       " '(pizza, Great, POS, food quality);(service, fantastic, POS, service general)',\n",
       " '(wait, small, POS, service general);(wait, shorter, POS, service general)',\n",
       " '(sushi, best, POS, food quality)',\n",
       " '(crunchy tuna, Try, POS, food quality);(crunchy tuna, die for, POS, food quality)',\n",
       " '(garden terrace, enjoy, POS, ambience general)',\n",
       " '(food, amazing, POS, food quality);(service, prompt, POS, service general);(service, helpful, POS, service general);(service, not over-bearing or rushed, POS, service general)',\n",
       " '(Steak Tartare, great, POS, food style_options)',\n",
       " '(vibe, good, POS, ambience general);(French food, best, POS, food quality)',\n",
       " '(crust, best, POS, food quality)',\n",
       " '(neighborhood, great, POS, location general);(food, great, POS, food quality)',\n",
       " '(setting, intimate, POS, ambience general);(service, nice, POS, service general)',\n",
       " '(Moules, excellent, POS, food quality);(lobster ravioli, salty, NEG, food quality)',\n",
       " '',\n",
       " '(Downstairs lounge, good attractio, POS, ambience general)',\n",
       " '',\n",
       " '(exotic food, beautifully presented, POS, food quality);(exotic food, delight, POS, food quality)',\n",
       " '(staff, helpful, POS, service general);(staff, attentive, POS, service general)',\n",
       " '(bar, well stocked, POS, drinks style_options);(beers, interesting, POS, drinks style_options);(wines, well priced, POS, drinks prices)',\n",
       " '(shows, loved, POS, ambience general);(actors, loved, POS, ambience general)',\n",
       " '(server, helpful, POS, service general);(server, friendly, POS, service general)',\n",
       " '(food, good, POS, food quality)',\n",
       " '(outdoor atmosphere, wonderful, POS, location general)',\n",
       " '(service, Great, POS, service general);(food, great, POS, food quality)',\n",
       " '(Wait staff, unappreciative, NEG, service general);(pie, best, POS, food quality)',\n",
       " '(salad, best, POS, food quality)',\n",
       " '(dining, fine, POS, food quality)',\n",
       " '(restaurant, great, POS, restaurant general)',\n",
       " '(staff, no nonsense, POS, service general)',\n",
       " '(bagels, better, POS, food quality)',\n",
       " '(1st Ave spot, Worth visiting, POS, restaurant miscellaneous)',\n",
       " '(sake menu, overlooked, POS, drinks style_options)',\n",
       " '(Service, good, POS, service general);(Service, prompt, POS, service general);(Service, attentive, POS, service general);(Service, non-intrusive, POS, service general)',\n",
       " '(Traditional French decour, pleasant, POS, ambience general);(hall, noisy, NEG, ambience general)',\n",
       " '(Cafe Spice, best, POS, restaurant general)',\n",
       " '(Seating, prompt, POS, service general)',\n",
       " '(Food, good, POS, food quality);(raw vegatables in side orders, wondered about freshmess, NEG, food quality)',\n",
       " '(decor, vibrant, POS, ambience general);(decor, eye-pleasing, POS, ambience general);(semi-private boths, eye-pleasing, POS, ambience general);(semi-private boths, great, POS, ambience general)',\n",
       " '(meal, best, POS, food quality)',\n",
       " '(restaurant, miss, POS, restaurant general)',\n",
       " '(restaurant, cute, NEU, restaurant general);(restaurant, not upscale, NEU, restaurant general)',\n",
       " '(food, diamond, POS, food quality);(balance of herbs and tomatoes, perfect, POS, food quality)',\n",
       " '(Jekyll and hyde Pub, great time, POS, restaurant general)',\n",
       " '(bar, enjoying, POS, restaurant miscellaneous)',\n",
       " '(server, cool, POS, service general)',\n",
       " '(decor, good laugh, POS, ambience general);(hidden bathrooms, good laugh, POS, ambience general)',\n",
       " '(restaurant, recommend, POS, restaurant general)',\n",
       " '(place, great, POS, restaurant miscellaneous)',\n",
       " '(beers, happy, POS, drinks style_options);(food, delicious, POS, food quality);(pumkin tortelini, recommend, POS, food quality)',\n",
       " '(entertainment, great, POS, ambience general)',\n",
       " '(bagel, huge, POS, food style_options)',\n",
       " '(pizza, enjoyed, POS, food quality);(santa fe chopped salad, enjoyed, POS, food quality);(fish and chips, enjoyed, POS, food quality)',\n",
       " '(restaurant, overhyped, NEG, restaurant general)',\n",
       " '(chow fun and chow see, bland, NEG, food quality);(chow fun and chow see, oily, NEG, food quality)',\n",
       " '(service, good, POS, service general)',\n",
       " '(pad penang, delicious, POS, food quality)',\n",
       " '(service, poor, NEG, service general)',\n",
       " '(chef, Hats off, POS, food quality)',\n",
       " '(salads, delicious, POS, food quality);(salads, refreshing, POS, food quality);(salads, spicy, POS, food quality)',\n",
       " '',\n",
       " '(vibe, Great, POS, ambience general)',\n",
       " '(Ambience, cute, POS, ambience general);(Ambience, quaint, POS, ambience general);(Ambience, good, POS, ambience general)',\n",
       " '(salads, great, POS, food quality)',\n",
       " '(Ingredients, organic, POS, food quality);(Ingredients, plus, POS, food quality)',\n",
       " '(sushi, good, POS, food prices);(sushi, inexpensive, POS, food prices)',\n",
       " '(spicy Tuna roll, huge, POS, food prices);(spicy Tuna roll, best, POS, food prices)',\n",
       " '(Yellowtail, good, POS, food quality)',\n",
       " '(Big Wong, big Ups, POS, restaurant general);(Big Wong, fine, POS, restaurant general)',\n",
       " '(food, great, POS, food quality);(service, great, POS, service general)',\n",
       " '(atmosphere, noisy, NEG, ambience general);(waiters, fast, POS, service general)',\n",
       " '(place, crowded, POS, restaurant miscellaneous);(place, popular, POS, restaurant miscellaneous)',\n",
       " '(pasta dish, served timely, POS, food quality);(pasta dish, fresh, POS, food quality)',\n",
       " '(tiramisu chocolate cake, delicious, POS, food quality)',\n",
       " '(restaurant, amazing time, POS, restaurant general)',\n",
       " '(food, good, POS, food quality);(service, ok, NEU, service general)',\n",
       " '(food, bad, NEG, food quality);(service, bad, NEG, service general);(good, good, POS, food quality)',\n",
       " '(Pastis, wonderful, POS, restaurant general)',\n",
       " '(mushroom pizza, better, POS, food quality)',\n",
       " '(sangria, tasty, POS, drinks quality);(sangria, good, POS, drinks quality)',\n",
       " '(place, small, NEU, restaurant miscellaneous)',\n",
       " '(Bombay beer, big, POS, drinks style_options)',\n",
       " '(Service, slow, NEG, service general);(people, friendly, POS, service general)',\n",
       " '(food, authentic Italian, POS, food quality);(food, delicious, POS, food quality)',\n",
       " '(Pizza, terrific, POS, food quality);(homemade pasta, terrific, POS, food quality)',\n",
       " '(Ambience, delightful, POS, ambience general);(service, impeccable, POS, service general)',\n",
       " '(food, lousy, NEG, food quality)',\n",
       " '(hanger steak, rubber, NEG, food quality);(tuna, flavorless, NEG, food quality)',\n",
       " '(Service, horrible, NEG, service general);(ambience, not that great, NEG, ambience general)',\n",
       " '(restaurant, small cute, POS, restaurant general)',\n",
       " '(place, love, POS, restaurant general)',\n",
       " '(place, good, POS, ambience general)',\n",
       " '(tables, crammed, NEG, ambience general);(tables, too close, NEG, ambience general);(menu, typical, NEU, food style_options);(wine list, overpriced, NEG, drinks prices)',\n",
       " '(Service, not what one would expect, NEG, service general)',\n",
       " '(service, not constitute proper, NEG, service general)',\n",
       " '(Fish, overdone, NEG, food quality)',\n",
       " '(wait staff, nice, POS, service general);(place, Cute, NEG, restaurant general)',\n",
       " '(dessert, recommended, NEG, food quality)',\n",
       " '(restaurant, Skip, NEG, restaurant general);(restaurant, disappointment, NEG, restaurant general)',\n",
       " '(Myagi, favorite, POS, restaurant general)',\n",
       " '(service, never had bad, POS, service general);(fish, fresh, POS, food quality);(fish, delicious, POS, food quality)',\n",
       " '(tuna tartar appetizer, die for, POS, food quality)',\n",
       " '(pizza, ashamed, POS, food quality)',\n",
       " '(service, prompt, POS, service general);(service, curtious, POS, service general);(place, cool, POS, ambience general)',\n",
       " '(place, recommend, POS, restaurant general)',\n",
       " '(dining room, elegant, POS, ambience general);(dining room, refreshing, POS, ambience general)',\n",
       " '(service, impeccable, POS, service general);(service, unobtrusive, POS, service general)',\n",
       " '(meal, real, POS, food quality);(restaurant, real, POS, ambience general)',\n",
       " '(staff, impeccable, POS, service general)',\n",
       " '(New England Chowder, good, POS, food quality);(Lobster Bisque, award, POS, food quality)',\n",
       " '(chicken vindaloo, get, POS, food quality)',\n",
       " '(service, 1st class, POS, service general);(food, terrific, POS, food quality)',\n",
       " '(portions, large, POS, food style_options)',\n",
       " '(wine list, excellent, POS, drinks style_options)',\n",
       " '(service, excellent, POS, service general);(place, small, POS, restaurant miscellaneous);(place, intimate, POS, restaurant miscellaneous);(place, crowded, POS, restaurant miscellaneous)',\n",
       " '(food, decent, NEU, food quality);(food, not great, NEU, food quality);(lemon salad, exception, NEG, food quality)',\n",
       " '(menu, limited, NEG, food style_options)',\n",
       " '(grilled branzino, difficult to eat, NEG, food quality)',\n",
       " '(decor, diner-ish, NEU, ambience general)',\n",
       " '(place, fun, POS, ambience general)',\n",
       " '(entertainment, incredible, POS, ambience general)',\n",
       " '(staff, friendliest, POS, service general)',\n",
       " '(Jekyll and Hyde, different, POS, restaurant general)',\n",
       " '(food, tradional, POS, food quality);(portions, large, POS, food style_options)',\n",
       " '(place, fun, POS, ambience general)',\n",
       " '(characters, enjoyable, POS, ambience general)',\n",
       " '(Jeckll and Hydes, fun, POS, restaurant general)',\n",
       " '(Service, slow, NEG, service general)',\n",
       " '(Drinks, over priced, NEG, drinks prices)',\n",
       " '(Food, good not great not worth the wait or another visi, NEU, food quality)',\n",
       " '(pizza, Great, POS, food quality)',\n",
       " '(Service, quick, POS, service general)',\n",
       " '(pizza, great, POS, food quality)',\n",
       " '(fish, quality, POS, food quality);(service, great, POS, service general)',\n",
       " '(Delivery, fast, POS, service general)',\n",
       " '(service, Great friendly, POS, service general);(seating, Fast, POS, service general);(Delivery, Fast, POS, service general);(sushi, Excellent, POS, food quality)',\n",
       " '(bagels, warm, POS, food style_options);(bagels, soft, POS, food style_options);(bagels, crispy, POS, food style_options);(bagels, enormous, POS, food style_options)',\n",
       " '(salads, great, POS, food quality);(cream cheeses, huge, POS, food style_options);(cream cheeses, different, POS, food style_options)',\n",
       " '(lox, fresh, POS, food quality)',\n",
       " '(food, Not impressed, NEG, food quality)',\n",
       " '(ambiance, Zero, NEG, ambience general)',\n",
       " '(place, overrated, NEG, restaurant general)',\n",
       " '(Shabu-Shabu Restaurant, BEST, POS, restaurant general)',\n",
       " '(atmosphere, nothing special, POS, ambience general)',\n",
       " '(ambiance, adds, POS, ambience general)',\n",
       " '(Taxan, delicious, POS, food quality)',\n",
       " '(green curry with vegetables, Try, POS, food quality)',\n",
       " '(quantity, good, POS, food style_options);(quantity, satisfied, POS, food style_options)',\n",
       " '(ravioli, best, POS, food quality)',\n",
       " '(wine, good, POS, drinks quality);(service, good, POS, service general)',\n",
       " '(trattoria, quaint, POS, restaurant general);(trattoria, romantic, POS, restaurant general)',\n",
       " '(food, delicious, POS, food quality);(dishes, never a disappointment, POS, food quality);(specials, delicious, POS, food quality);(specials, never a disappointment, POS, food quality);(regular menu-fare, delicious, POS, food quality);(regular menu-fare, never a disappointment, POS, food quality)',\n",
       " '(back room, secret, POS, ambience general)',\n",
       " '(food, authentic, POS, food quality)',\n",
       " '(pizza, best, POS, food quality)',\n",
       " '(service, great, POS, service general)',\n",
       " '(hostess, rude, NEG, service general);(waitress, rude, NEG, service general)',\n",
       " '(Amma, nothing special, NEU, restaurant general)',\n",
       " '(dishes, average, NEG, food prices);(dishes, too expensive, NEG, food prices)',\n",
       " '(place, packed, NEU, ambience general)',\n",
       " '(food, excellent, POS, food quality)',\n",
       " '(kababs, good, POS, food quality);(Dal Bukhara, good, POS, food quality)',\n",
       " '(Haru on Park S, disgusting, NEG, restaurant general)',\n",
       " '(fish, not fresh, NEG, food quality);(rice, old, NEG, food quality);(rice, stale, NEG, food quality)',\n",
       " '(sushi, worst, NEG, food quality)',\n",
       " '(sushi, worst, NEG, food quality)',\n",
       " '(restaurant, highly, NEG, restaurant general)',\n",
       " '(all-u-can-eat sushi, poor quality, NEG, food quality)',\n",
       " '(waitstaffs, nice, POS, service general)',\n",
       " '',\n",
       " '(service, dissappointed, NEG, service general);(service, rude, NEG, service general)',\n",
       " '(dinner, ok, NEG, food quality)',\n",
       " '(eggs benedict, worst, NEG, food quality)',\n",
       " '(service, attentive, POS, service general)',\n",
       " '(Planet Thai, great, POS, restaurant general)',\n",
       " '(food, love, POS, food quality);(drinks, love, POS, drinks quality);(atmosphere, love, POS, ambience general)',\n",
       " '(svc, rude, NEG, service general);(restaurant, must, POS, restaurant general)',\n",
       " '(Pad Thai, Try, POS, food quality);(Pad Thai, fabulous, POS, food quality);(Pad Thai, cheap, POS, food quality)',\n",
       " '(portions, small, POS, food style_options);(food, nasty, POS, food quality)',\n",
       " '(atmosphere, saves, POS, ambience general)',\n",
       " '(Chennai Garden, favorite, POS, restaurant general)',\n",
       " '(Indian, authentic, POS, food prices)',\n",
       " '(restaurant, cramped, NEG, ambience general);(restaurant, busy, NEG, ambience general)',\n",
       " '(cigar bar, nice, POS, ambience general);(staff, great, POS, service general)',\n",
       " '(food, tasty, POS, food quality);(portion sizes, appropriate, POS, food style_options)',\n",
       " '(restaurant, nice, POS, restaurant miscellaneous)',\n",
       " '(place, Not a great, NEG, restaurant miscellaneous)',\n",
       " '(Food, excellent, POS, food quality)',\n",
       " '(Fish, fresh, POS, food quality)',\n",
       " '(YUKA, Love, POS, restaurant general)',\n",
       " '(seafood, good, POS, food quality);(Mermaid Inn, good, POS, restaurant general)',\n",
       " '(menu, limited, NEG, food style_options);(dishes, excellent, POS, food quality)',\n",
       " '(lobster sandwich, good, POS, food quality);(spaghetti with Scallops and Shrimp, great, POS, food quality)',\n",
       " '(service, good, POS, service general);(ambience, good, POS, ambience general)',\n",
       " '(restaurant, fallback, NEG, restaurant prices)',\n",
       " '(seafood, good, POS, food quality)',\n",
       " '(waiter, attentive, POS, service general)',\n",
       " '(restaurant, recommend, POS, restaurant general)',\n",
       " '(foods, unhappy, NEG, food quality)',\n",
       " '(jelly fish, recommend, POS, food quality);(drunken chicken, recommend, POS, food quality);(soupy dumplings, recommend, POS, food quality);(stir fry blue crab, recommend, POS, food quality)',\n",
       " '(food, cheap, POS, food prices);(waiters, nice, POS, service general)',\n",
       " '(Wine list, extensive without being over-priced, POS, drinks prices)',\n",
       " '(specials, try, POS, food quality);(specials, seasonal, POS, food quality);(specials, delicious, POS, food quality)',\n",
       " '(place, loved, POS, restaurant general)',\n",
       " '(food, good, POS, food prices);(place, great, POS, ambience general)',\n",
       " '(wait staff, freindly, POS, service general)',\n",
       " '(people, evil, NEG, service general);(people, incompetent, NEG, service general);(Cafe Noir, like, POS, restaurant general)',\n",
       " '(service, terrible, NEG, service general)',\n",
       " '(staff, good, NEG, service general);(Cafe Noir, great, POS, restaurant general)',\n",
       " '(Pizza, good, POS, food quality)',\n",
       " '(Salads, delicious, POS, food quality)',\n",
       " '(calamari, pass, NEG, food quality)',\n",
       " '(Decor, charming, POS, ambience general)',\n",
       " '(place, great, POS, restaurant general)',\n",
       " '(thai cuisine, like, POS, food quality)',\n",
       " '(customer service, worst, NEG, service general)',\n",
       " '(place, Loved, POS, restaurant general)',\n",
       " '(atmosphere, Excellent, POS, ambience general);(dishes, delicious, POS, food quality);(service, good, POS, service general);(service, friendly, POS, service general)',\n",
       " '(wine list, nice, POS, drinks style_options)',\n",
       " '(food, wonderful, POS, food quality);(drinks, wonderful, POS, drinks quality);(staff, wonderful, POS, service general);(mileau, wonderful, POS, ambience general)',\n",
       " '(Casimir, great time, POS, restaurant general)',\n",
       " '(food, great, POS, food prices);(food, reasonably priced, POS, food prices)',\n",
       " '(staff, nice, POS, service general);(staff, stressed, POS, service general);(unisex bathroom, stressed, NEG, ambience general)',\n",
       " '(caviar, spectacular, POS, food quality);(caviar, enjoyed, POS, food quality);(waitstaff, hospitable, POS, service general);(waitstaff, enjoyed, POS, service general)',\n",
       " '(waitstaff, comfortable, POS, service general);(waitstaff, relaxed, POS, service general)',\n",
       " '(caviar, delicious top grade, POS, food quality);(service, fantastic, POS, service general)',\n",
       " '(staff, Friendly, POS, service general)',\n",
       " '(food, outstanding, POS, food quality);(salmon dish, outstanding, POS, food quality)',\n",
       " '(Change Mojito, out of this world, POS, drinks quality)',\n",
       " '(back patio, worth, POS, ambience general);(back patio, cool, POS, ambience general);(music, well, POS, ambience general)',\n",
       " '(restaurant, excellent, POS, restaurant general)',\n",
       " '(food, good, POS, food quality)',\n",
       " '(place, nice, POS, ambience general);(place, calm, POS, ambience general)',\n",
       " '(service, slow, NEG, service general)',\n",
       " '(buffet, nice, POS, food style_options)',\n",
       " '(food, average or above, POS, food quality);(dishes, tasty, POS, food quality)',\n",
       " '(Service, good, POS, service general)',\n",
       " '(cheesecake, excellent, POS, food quality);(pastries, nice, POS, food quality)',\n",
       " '(cheeseburgers, huge, NEU, food style_options)',\n",
       " '(Tom Kha soup, pathetic, NEG, food quality)',\n",
       " '(Thai, good authentic, NEG, food quality)',\n",
       " '(pesto pizza, excellent, POS, food quality);(spicy Italian cheese, nice, POS, food quality)',\n",
       " '(back garden sitting area, pleasant, POS, ambience general)',\n",
       " '(lobster sandwich, FANTASTIC, POS, food quality)',\n",
       " '(portion, fine, POS, food style_options);(french fries, best, POS, food quality)',\n",
       " '(martinis, right, POS, drinks quality)',\n",
       " '(food, love, POS, food quality)',\n",
       " '(japanese comfort food, yummy authentic, POS, food quality)',\n",
       " '(food, Great, POS, food quality);(menu, good size, POS, food style_options);(service, great, POS, service general);(setting, unpretensious, POS, ambience general)',\n",
       " '(delivery, fastest, POS, service general)',\n",
       " '(spot, great, POS, restaurant miscellaneous)',\n",
       " '(Thai food, Average to good, POS, food quality);(delivery, terrible, NEG, service general)',\n",
       " '(place, wonderful, POS, restaurant general)',\n",
       " '',\n",
       " '(waiter, nice, POS, service general);(waiter, cordial, POS, service general)',\n",
       " '(dishes, good, POS, food quality)',\n",
       " '(restaurant, recommend, POS, restaurant general)',\n",
       " '(Service, great, POS, service general);(food, fantastic, POS, food quality)',\n",
       " '(food, outstanding, POS, food quality);(service, quick, POS, service general);(service, friendly, POS, service general);(service, professional, POS, service general)',\n",
       " '(crowd, nice, POS, restaurant miscellaneous);(crowd, never loud, POS, restaurant miscellaneous)',\n",
       " '(pizza place, overcrowded, POS, restaurant miscellaneous)',\n",
       " '(crust, thin, POS, food quality);(staff, friendly, POS, service general);(ingredients, fresh, POS, food quality)',\n",
       " '(mare, best, POS, restaurant general)',\n",
       " '(pizzeria, great, POS, restaurant general)',\n",
       " '(pizzas, terrific, POS, food quality)',\n",
       " '(Sophia pizza, recommend, POS, food quality)',\n",
       " '(food, great, NEG, food quality);(service, great, NEG, service general)',\n",
       " '(sushi, outstanding, NEG, food quality);(sushi, bland, NEG, food quality)',\n",
       " '(blond wood decor, soothing, POS, ambience general);(premium sake, soothing, POS, drinks quality);(service, great, POS, service general)',\n",
       " '(Mizu, difficult, POS, restaurant general)',\n",
       " '(smoked salmon and roe appetizer, off flavor, NEG, food quality)',\n",
       " '(menu, expensive, NEG, food quality)',\n",
       " '(view, spectacular, POS, location general);(food, great, POS, food quality)',\n",
       " '(food, delicious simple, POS, food style_options);(outdoor atmosphere, nice, POS, ambience general)',\n",
       " '(wait staff, Kind, POS, service general);(wait staff, attentive, POS, service general)',\n",
       " '(crab cakes, Delicious, POS, food quality)',\n",
       " '(calzones, horrific, NEG, food quality);(calzones, bad, NEG, food quality);(calzones, vomit-inducing, NEG, food quality);(calzones, YUCK, NEG, food quality)',\n",
       " '(counter service, bad, NEG, service general)',\n",
       " '(sandwiches, dry, NEG, food prices);(sandwiches, tasteless, NEG, food prices);(sandwiches, overpriced, NEG, food prices)',\n",
       " '(place, kicks ass, POS, restaurant general)',\n",
       " '(atmosphere, unheralded, POS, ambience general);(service, impecible, POS, service general);(food, magnificant, POS, food quality)',\n",
       " '(place, lovely, POS, ambience general);(place, peaceful, POS, ambience general)',\n",
       " '(place, great, POS, location general)',\n",
       " '(sushi, Great, POS, food quality)',\n",
       " '(apppetizers, Unique, POS, food quality)',\n",
       " '(sushimi cucumber roll, Try, POS, food quality)',\n",
       " '(service, awful, NEG, service general)',\n",
       " '(place, not worth the prices, NEG, restaurant prices)',\n",
       " '(Williamsburg spot, surprising, POS, restaurant general)',\n",
       " '(pizza, delicious, POS, food quality);(proprietor, nicest, POS, service general)',\n",
       " '(Bagels, ok, NEU, food quality)',\n",
       " '(turkey burgers, scary, NEG, food quality)',\n",
       " '(sushi, awful, NEG, food quality)',\n",
       " '(rice, poor quality, NEG, food quality);(rice, cooked so badly, NEG, food quality);(rice, hard, NEG, food quality)',\n",
       " '(sushi, bland, NEG, food quality);(sushi, disgusting, NEG, food quality)',\n",
       " '(service, Good, POS, service general);(service, fast, POS, service general)',\n",
       " '(Food, great, POS, food prices);(Food, inexpensive, POS, food prices)',\n",
       " '(location, perfect, POS, location general)',\n",
       " '(bottle, love, NEG, drinks prices);(music, like, NEG, ambience general)',\n",
       " '(atmoshere, Great, POS, ambience general)',\n",
       " '(staff, best, POS, service general);(Winnie, best, POS, service general)',\n",
       " '(food, reliable, POS, food quality)',\n",
       " '(Thai food, authentic, POS, food quality)',\n",
       " '(service, attentive, POS, service general);(service, discreet, POS, service general)',\n",
       " '(brioche and lollies, cute, POS, food quality);(brioche and lollies, sweet, POS, food quality)',\n",
       " '(place, quiet, POS, ambience general);(place, delightful, POS, ambience general)',\n",
       " '(Service, good, POS, service general);(food, wonderful, POS, food quality)',\n",
       " '(spot, good, POS, restaurant general)',\n",
       " '(Lucky Strike, best, POS, restaurant general)',\n",
       " '(food, yummy, POS, food quality);(mussels in spicy tomato sauce, yummy, POS, food quality);(mussels in spicy tomato sauce, cooked-to-perfection, POS, food quality);(fries, yummy, POS, food quality);(fries, crispy, POS, food quality)',\n",
       " '(late night atmosphere, best, POS, ambience general)',\n",
       " '(in-house lady DJ, good taste, POS, ambience general)',\n",
       " '(location, good, POS, location general);(Suan, reasonable, POS, restaurant prices)',\n",
       " '',\n",
       " '(noodles with shrimp and chicken and coconut juice, MUST, POS, food quality)',\n",
       " '(chef, changed, NEG, food quality);(staff, changed, NEG, service general)',\n",
       " '(food, inconsistent, NEG, food quality)',\n",
       " '(place, like, POS, restaurant miscellaneous)',\n",
       " '(setting, casual, POS, ambience general);(setting, romantic, POS, ambience general)',\n",
       " '(balsamic vinegar over icecream, try, POS, food quality);(balsamic vinegar over icecream, wonderful, POS, food quality)',\n",
       " '(dim sum, pricey, POS, food quality);(dim sum, worth, POS, food quality)',\n",
       " '(turnip cake, skip, NEG, food quality);(roast pork buns, skip, NEG, food quality);(egg custards, skip, NEG, food quality)',\n",
       " '(food, exceptional, POS, food quality)',\n",
       " '(braised lamb shank in red wine, excellent, POS, food quality)',\n",
       " '(service, friendly, POS, service general);(atmosphere, casual, NEU, ambience general)',\n",
       " '(pad se ew chicken, delicious, POS, food quality);(pad thai, oily, NEG, food quality)',\n",
       " '(Ginger House, good, POS, restaurant general)',\n",
       " '(fried dumplings, GREAT, POS, food quality)',\n",
       " '(Chinese restaurant, reliable, POS, restaurant general)',\n",
       " '(management, Terrible, NEG, service general);(management, terrible, NEG, service general)',\n",
       " '(Spreads, great, NEG, food prices);(Spreads, pricey, NEG, food prices);(toppings, great, NEG, food prices);(toppings, pricey, NEG, food prices)',\n",
       " '(food, decent, NEG, food quality);(ambience, annoying, NEG, ambience general)',\n",
       " '(shrimp appetizers, try, POS, food quality)',\n",
       " '(ambience, correct, POS, ambience general);(staff, excellent, POS, service general)',\n",
       " '(food, Great, POS, food quality);(service, great, POS, service general)',\n",
       " '(eats, good quality, POS, food prices);(eats, cheap, POS, food prices)',\n",
       " '(bagels, Great, POS, food style_options)',\n",
       " '(food, amazing, POS, food quality)',\n",
       " '(lamb, tender, POS, food quality);(dessert, divine, POS, food quality)',\n",
       " '(waiter, attentive, POS, service general)',\n",
       " '(place, beautiful, POS, ambience general)',\n",
       " '(restaurant, Family feel, POS, ambience general);(portions, enormous, POS, food style_options)',\n",
       " '(anti-pasta, excellent, POS, food quality);(calamari, excellent, POS, food quality);(pasta mains, excellent, POS, food style_options)',\n",
       " '(wine list, extensive, POS, drinks style_options);(meal, reasonably priced, POS, food prices)',\n",
       " '(place, Fantastic, POS, restaurant general)',\n",
       " '(food, Great, POS, food quality);(decor, great, POS, ambience general);(service, great, POS, service general)',\n",
       " '(spot, perfect, POS, restaurant miscellaneous)',\n",
       " '(Heartland Brewery, NEVER BEEN DISAPPOINTED, POS, restaurant general)',\n",
       " '(restaurant, Not the typical, POS, ambience general)',\n",
       " '(bar, cool, POS, ambience general);(food, great, POS, food quality);(beer, excellent, POS, drinks style_options)',\n",
       " '(shrimp scampi, excellent, POS, food quality);(antipasti, plentiful, POS, food style_options)',\n",
       " '(atomosphere, Cozy romantic, POS, ambience general)',\n",
       " '(Service, prompt, POS, service general);(Service, rushed, POS, service general)',\n",
       " '(Food, good, NEU, food quality)',\n",
       " '(porcini mushroom pasta special, tasteless, NEG, food quality);(seafood tagliatelle, tasteless, NEG, food quality)',\n",
       " '(place, liked, POS, restaurant general)',\n",
       " '(place, impress, NEG, restaurant miscellaneous)',\n",
       " '(food, wonderful, POS, food style_options);(food, tasty, POS, food style_options);(food, filling, POS, food style_options);(service, professional, POS, service general);(service, friendly, POS, service general)',\n",
       " '(Suan, great, POS, restaurant general)',\n",
       " '(service, fast, POS, service general);(service, friendly, POS, service general);(food, tasty, POS, food quality);(hot sauce, best, POS, food quality)',\n",
       " '(food, Good, POS, food quality)',\n",
       " '(drink, Good, POS, drinks quality)',\n",
       " '(spot, Great, POS, restaurant miscellaneous)',\n",
       " '(outdoor seating, terrific, POS, ambience general)',\n",
       " '(ambiance, great, POS, ambience general);(atmosphere, great, POS, ambience general);(food, could have been a lot better, NEG, food quality);(service, could have been a lot better, NEG, service general)',\n",
       " '(food, fine, POS, food quality)',\n",
       " '(chicken, stick, POS, food quality);(beef, stick, POS, food quality);(lamb dishes, stick, POS, food quality)',\n",
       " '(service, friendly, POS, service general)',\n",
       " '(dessert, skip, NEG, food quality)',\n",
       " '(Reuben sandwich, Best, POS, food quality)',\n",
       " '',\n",
       " '(food, not fresh, NEG, food quality);(sauces, bland, NEG, food quality);(sauces, oily, NEG, food quality)',\n",
       " '(Pizza, soggy, NEG, food quality)',\n",
       " '(wines by the glass, Not enough, NEG, drinks style_options)',\n",
       " '(place, great bargain, POS, restaurant prices)',\n",
       " '(Pakistani food, Authentic, POS, food quality)',\n",
       " '(food, cheap, POS, food prices);(food, good, POS, food prices)',\n",
       " '(Faan, good, POS, restaurant general)',\n",
       " '(pad thai, best, POS, food quality)',\n",
       " '(design, good, POS, ambience general);(atmosphere, good, POS, ambience general)',\n",
       " '(atmosphere, Nice, POS, ambience general);(service, pleasant, POS, service general);(desert, good, POS, food quality)',\n",
       " '(food, amazing, POS, food quality);(pastas, rich, POS, food style_options);(pizza, fresh doughy, POS, food quality)',\n",
       " '(vibe, warm, POS, ambience general);(owner, friendly, POS, service general);(service, fast, POS, service general)',\n",
       " '(Usha, nicest, POS, service general)',\n",
       " '(Toons, attractive, POS, ambience general)',\n",
       " '(food, good, POS, food quality)',\n",
       " '(Thai food, decent, POS, food quality)',\n",
       " '(decor, nice, POS, ambience general);(service, good, POS, service general);(food, excellent, POS, food quality)',\n",
       " '(service, good, POS, service general);(resturant, clean, POS, ambience general)',\n",
       " '(service, best, POS, service general);(atmosphere, best, POS, ambience general)',\n",
       " '(place, LOVE, POS, restaurant general)',\n",
       " '(outdoor seating, perfect, POS, ambience general)',\n",
       " '(Indoor, cozy, POS, ambience general);(Indoor, cute, POS, ambience general)',\n",
       " '(portion sizes, huge, POS, food style_options);(sushi, good, POS, food quality)',\n",
       " '(dumplings, Excellent, POS, food quality);(decor, clean, POS, ambience general);(decor, chic, POS, ambience general)',\n",
       " '(food, delicious, NEG, food style_options)',\n",
       " '(portions, small, NEG, food style_options);(food, good, POS, food quality)',\n",
       " '(staff, attentive, POS, service general);(staff, down to earth, POS, service general)',\n",
       " '(Indian food, Great, POS, food quality);(service, incredible, POS, service general)',\n",
       " '(food, Great, POS, food quality)',\n",
       " '(egg noodles in the beef broth with shrimp dumplings and slices of BBQ roast pork, love, POS, food quality)',\n",
       " '(dish, favorite, POS, food quality)',\n",
       " '(Ow Ley Soh, delicious, POS, food quality);(Ow Ley Soh, sweet, POS, food quality)',\n",
       " '(Big Wong, great, POS, restaurant general)',\n",
       " '(music, good, POS, ambience general);(food, great, POS, food quality);(service, speedy, POS, service general)',\n",
       " '(Japanese Tapas, good, POS, food quality)',\n",
       " '(drinks, good, POS, drinks quality);(service, good, POS, service general)',\n",
       " '(service, disappointed, NEG, service general);(food, overated, NEG, food quality);(food, pricey, NEG, food quality)',\n",
       " '(manager, incompetent, NEG, service general)',\n",
       " '(service, subpar, NEG, service general)',\n",
       " '(service, lousy, NEG, service general)',\n",
       " '(nigiri, good, NEU, food quality)',\n",
       " '(Areo, enjoyable, POS, restaurant general)',\n",
       " '(servers, attentive, POS, service general);(servers, friendly, POS, service general);(servers, attractive, POS, service general)',\n",
       " '(Food, good, POS, food quality);(view of the new york city skiline, terrific, POS, location general)',\n",
       " '(table by the window, recommand, POS, location general)',\n",
       " '(service, good, POS, service general);(place, relaxing, POS, ambience general)',\n",
       " '(food, great, POS, food quality)',\n",
       " '(Personal pans, perfect, POS, food style_options)',\n",
       " '(delivery guys, downside, NEG, service general)',\n",
       " '(pizza, good, POS, food style_options);(pizza, huge, POS, food style_options)',\n",
       " '(La Rosa, best, POS, food quality)',\n",
       " '(wines, good, POS, drinks quality);(service, fine, POS, service general);(decor, fun, POS, ambience general);(selection, Interesting, POS, food style_options)',\n",
       " '(spot, perfect, POS, restaurant miscellaneous)',\n",
       " '(service, prompt, POS, service general)',\n",
       " '(wine list, extensive, POS, drinks style_options);(wine list, impressive, POS, drinks style_options)',\n",
       " '(atmosphere, LOVE, POS, ambience general)',\n",
       " '(service, good, POS, service general);(staff, great, POS, service general)',\n",
       " '(PLACE, lOVE, POS, restaurant general)',\n",
       " '(meal, never had a disapointing, POS, food quality)',\n",
       " '(dumplings, yummy, POS, food quality)',\n",
       " '(BBQ Salmon, Luckily, POS, food quality);(Sea Bass, Luckily, POS, food quality);(Crispy Duck, Luckily, POS, food quality)',\n",
       " '',\n",
       " '(place, recommend, POS, restaurant general)',\n",
       " '(food, Great, POS, food quality)',\n",
       " '(Dog, Tasty, POS, food quality)',\n",
       " '(dog, organic, POS, food quality);(establishment, eco friendly, POS, restaurant miscellaneous)',\n",
       " '(pork souvlaki, best, POS, food quality)',\n",
       " '(Pizza, YUMMY, POS, food quality)',\n",
       " '(restaurant, inviting, POS, ambience general)',\n",
       " '(eggplant pizza, LOOOVE, POS, food quality);(pastas, LOOOVE, POS, food quality)',\n",
       " '(food, Excellent, POS, food quality);(interior, help, NEG, ambience general)',\n",
       " '(sake, Great, POS, drinks quality)',\n",
       " '',\n",
       " '(sashimi, fresh, POS, food quality);(rolls, innovative, POS, food quality);(rolls, delicious, POS, food quality)',\n",
       " '(service, problem, POS, service general)',\n",
       " '(Delivery, lacking, NEG, service general)',\n",
       " '(Sushi, Best, POS, food quality)',\n",
       " '(sushi, ruined, POS, food quality)',\n",
       " '(sashimi, Excellent, POS, food quality);(millennium roll, delicious, POS, food quality)',\n",
       " '(place, hidden away, POS, restaurant general);(place, worth, POS, restaurant general)',\n",
       " '(waiter, attentive, POS, service general);(food, delicious, POS, food quality);(views of the city, great, POS, location general)',\n",
       " '(place, Great, POS, ambience general)',\n",
       " '(food, Good, POS, food quality);(seafood spaghetti, favorite, POS, food quality)',\n",
       " '(food, Excellent, POS, food prices)',\n",
       " '(wait staff, courteous, POS, service general);(wait staff, accomodating, POS, service general)',\n",
       " '(space, limited, NEG, restaurant miscellaneous);(indo-chinese food, delicious, POS, food quality)',\n",
       " '(place, favorite, POS, restaurant general)',\n",
       " '(chicken pasta, love, POS, food quality)',\n",
       " '(place, fanatical, POS, restaurant prices)',\n",
       " '(lobster, good, NEU, food quality);(lobster, nothing spectacular, NEU, food quality)',\n",
       " '(restaraunt, five star, NEU, restaurant general)',\n",
       " '(pizza, overrated, NEG, food quality);(pizza, under cooked, NEG, food quality)',\n",
       " '(staff, rude, NEG, service general);(staff, not attentive, NEG, service general)',\n",
       " '',\n",
       " '(service, quick, POS, service general);(service, friendly, POS, service general)',\n",
       " '(restaurant, nice, POS, ambience general);(restaurant, clean, POS, ambience general)',\n",
       " '(vitello alla marsala, impressed, POS, food quality)',\n",
       " '(veal, perfectly, POS, food quality);(mushrooms, perfectly, POS, food quality)',\n",
       " '(PLACE, WORST, NEG, restaurant general)',\n",
       " '(bartender, immature, NEG, service general);(service, slowwwww, NEG, service general);(food, not fresh or warm, NEG, food quality);(waitresses, werent very attentive, NEG, service general)',\n",
       " '(place, never recommend, NEG, restaurant miscellaneous)',\n",
       " '(japanese food, overpriced, NEG, food prices)',\n",
       " '(food, luke warm, NEG, food quality)',\n",
       " '(waitress, not attentive, NEG, service general)',\n",
       " '(food, excellent, POS, food quality);(service, excellent, POS, service general);(The Four Seasons, dissappointed, NEG, restaurant general)',\n",
       " '(Red Dragon Roll, favorite, POS, food quality)',\n",
       " '(Seafood Dynamite, otherworldly, POS, food quality)',\n",
       " '(Sushi, Favorite, POS, food quality)',\n",
       " '(spot, unpretentious, POS, ambience general);(sushi, good, POS, food quality);(service, pleasant, POS, service general);(service, effective, POS, service general);(service, unassuming, POS, service general)',\n",
       " '(back garden area, nice, POS, ambience general)',\n",
       " '(rolls, creative, POS, food style_options);(japanese food, inventive, POS, food quality);(japanese food, delicious, POS, food quality)',\n",
       " '',\n",
       " '(food, Gross, NEG, food quality)',\n",
       " '(Indian Food, Great, POS, food quality)',\n",
       " '(food, good, POS, food quality);(place, clean, POS, restaurant prices);(place, affordable, POS, restaurant prices)',\n",
       " '(indian place, great, POS, restaurant miscellaneous)',\n",
       " '(staff, good, POS, service general)',\n",
       " '(drink menu, Love, POS, drinks style_options)',\n",
       " '(place, recommend, POS, restaurant general);(place, beautiful, POS, restaurant general)',\n",
       " '(view of river and NYC, Nice, POS, location general)',\n",
       " '',\n",
       " '(Egyptian restaurant, dreamy, POS, ambience general)',\n",
       " '(baba ganoush, enjoy delicious, POS, food quality);(belly dancers, talented, POS, ambience general)',\n",
       " '(Raymond, rocks, POS, service general)',\n",
       " '(Pacifico, great, POS, restaurant miscellaneous)',\n",
       " '(drinks, great, POS, drinks quality);(Raymond, great, POS, service general)',\n",
       " '(quacamole, yummy, POS, food quality);(wings with chimmichuri, yummy, POS, food quality)',\n",
       " '(chicken in the salads, weakness, NEG, food quality)',\n",
       " '(food, decent, POS, food prices);(people, friendly, POS, service general)',\n",
       " '(Indian Restaurant, Best, POS, restaurant general)',\n",
       " '(Decor, upgraded, NEG, ambience general);(food, amazing, POS, food quality)',\n",
       " '(gyros, best, POS, food quality)',\n",
       " '(restaurant, Best, POS, restaurant general)',\n",
       " '(food, Great, POS, food quality);(service, amazing, POS, service general);(place, class act, POS, restaurant general)',\n",
       " '(veal, incredible, POS, food quality)',\n",
       " '(place, must visit, POS, restaurant general)',\n",
       " '(food, shared, POS, food style_options)',\n",
       " '',\n",
       " '(Service, wonderful, POS, service general)',\n",
       " '(Paul, professional, POS, service general)',\n",
       " '(bar drinks, ok, NEG, drinks quality)',\n",
       " '(wine list, extensive, POS, drinks style_options);(staff, not seem knowledgeable, NEG, service general)',\n",
       " '(main course, wonderful, POS, food quality)',\n",
       " '(fish, exceeded our expectations, POS, food quality);(filet, exceeded our expectations, POS, food quality)',\n",
       " '(location, expect, NEU, restaurant miscellaneous)',\n",
       " '(restaurant, beautiful, POS, ambience general)',\n",
       " '(boths, not as small, POS, ambience general);(boths, perfect, POS, ambience general)',\n",
       " '(food, ok, NEU, food quality);(food, fair, NEU, food quality)',\n",
       " '(looks, exceeds, POS, ambience general)',\n",
       " '(food, Subtle, POS, food quality)',\n",
       " '(service, enjoy, POS, service general);(food, enjoy, POS, food quality)',\n",
       " '(Greg, favorite, POS, service general)',\n",
       " '(servers, patient, POS, service general)',\n",
       " '(dogs, amazing fresh, POS, food quality);(toppings, best, POS, food style_options);(toppings, endless, POS, food style_options)',\n",
       " '(hot dog, amazing fun, POS, food quality)',\n",
       " '(Casa La Femme, true, POS, restaurant general)',\n",
       " '(decor, impressed, POS, ambience general);(food, impressed, POS, food quality)',\n",
       " '(cocktail with Citrus Vodka and lemon and lime juice and mint leaves, great, POS, drinks quality)',\n",
       " '(Food, worth, POS, food quality)',\n",
       " '(belly dancing show, captivated, POS, ambience general)',\n",
       " '(restaurant, worth, POS, restaurant general)',\n",
       " '(waiter, nice, POS, service general);(food, average, NEU, food quality)',\n",
       " '(food, well prepared, NEG, food quality)',\n",
       " '(restaurant, good reputation, POS, restaurant miscellaneous);(customer service, intelligent, NEG, service general)',\n",
       " '(place, Great, POS, restaurant prices)',\n",
       " '(food, flavorful, POS, food prices);(food, plentiful, POS, food prices);(food, reasonably priced, POS, food prices)',\n",
       " '(atmosphere, relaxed, POS, ambience general);(atmosphere, casual, POS, ambience general)',\n",
       " '(place, great, POS, restaurant miscellaneous)',\n",
       " '(Sushi, unbelievable, POS, food quality)',\n",
       " '(rolls, Good creative, POS, food style_options)',\n",
       " '(Yamato, excellent, POS, restaurant miscellaneous)',\n",
       " '(rolls, great, POS, food quality);(triple color and norwegetan rolls, awesome, POS, food style_options);(triple color and norwegetan rolls, filling, POS, food style_options)',\n",
       " '(dessert, save room, POS, food quality);(special roll, enough, POS, food style_options);(regular roll, enough, POS, food style_options)',\n",
       " '(banana chocolate dessert, delicious, POS, food quality);(green tea tempura, great, POS, food quality)',\n",
       " '(appetizers, delicious, POS, food quality)',\n",
       " '(food, Amazing, POS, food quality)',\n",
       " '(interior, Mazing, NEG, ambience general)',\n",
       " '(food, Great, POS, food quality)',\n",
       " '(modern Japanese, delivers, POS, food quality)',\n",
       " '(atmosphere, nice, NEG, ambience general);(scheme of mirrors, crazy, NEG, ambience general)',\n",
       " '(modern Japanese food, go-to for, POS, food quality);(mirrors, confusing, NEG, ambience general)',\n",
       " '(place, fancy, NEU, ambience general);(Chinese style Indian food, good, POS, food quality)',\n",
       " '(food, speechless, NEG, food quality);(food, horrible, NEG, food quality)',\n",
       " '(food, disappointing, NEG, food quality)',\n",
       " '(pizza, best, POS, food quality)',\n",
       " '(hot dogs, juicy, POS, food quality)',\n",
       " '(toppings, great, POS, food quality)',\n",
       " '(dishes, oily, NEG, food quality)',\n",
       " '',\n",
       " '(indian chinese food, great, POS, food quality)',\n",
       " '(place, tiny, NEG, ambience general)',\n",
       " '(place, not beautiful, NEG, ambience general);(food, speaks for itself, POS, food quality)',\n",
       " '(Indian Chinese, Best, POS, food quality)',\n",
       " '(martinis, amazing, POS, drinks prices);(martinis, fairly priced, POS, drinks prices)',\n",
       " '(SERVICE, AMAZING, POS, service general);(waiters, nice, POS, service general)',\n",
       " '(DJ, awesome, POS, ambience general)',\n",
       " '(food, superb, POS, food quality)',\n",
       " '(appetizers, good, POS, food quality)',\n",
       " '(entree, good, POS, food quality)',\n",
       " '(place, classy, NEG, restaurant prices);(place, beautiful, NEG, restaurant prices)',\n",
       " '(Vanison, good, NEU, food quality);(Vanison, not amazing, NEU, food quality)',\n",
       " '(Bison, excellent, POS, food quality)',\n",
       " '(Dessert, disaster, NEG, food quality)',\n",
       " '(restaurant, expensive, NEG, restaurant general)',\n",
       " '(environment, upscale, NEU, ambience general)',\n",
       " '(food, worth, NEG, food quality)',\n",
       " '(service, sadly, NEG, service general)',\n",
       " '(Casa La Femme, offended, NEG, restaurant prices)',\n",
       " '(place, beautiful, POS, ambience general)',\n",
       " '(hostess, pleasant, POS, service general)',\n",
       " '(waiter, forgot, NEG, service general)',\n",
       " '(chicken, inedible, NEG, food quality)',\n",
       " '(food, good, NEG, food quality)',\n",
       " '(meal, inedible, NEG, food quality)',\n",
       " '(restaurant, abused, NEG, restaurant prices)',\n",
       " '',\n",
       " '(Food, amazing, POS, food quality)',\n",
       " '(lunch buffet, expensive, POS, food quality);(lunch buffet, worth, POS, food quality)',\n",
       " '(service, great, POS, service general);(dinner, great quality, POS, food quality)',\n",
       " '(Bukhara, top, POS, restaurant general)',\n",
       " '(food, disgusted, NEG, food quality);(service, disgusted, NEG, service general)',\n",
       " '(meal, disgusted, NEG, food quality)',\n",
       " '(place, Gorgeous, POS, restaurant miscellaneous);(place, ideal, POS, restaurant miscellaneous)',\n",
       " '(four course prix fix menu, enjoyed, POS, food quality);(white organza tent, gorgeous, POS, ambience general)',\n",
       " '(service, spectacular, POS, service general);(waiter, amazing, POS, service general)',\n",
       " '(Casa La Femme, recommend, POS, restaurant miscellaneous)',\n",
       " '(nakgi-bokum, horrible, NEG, food quality)',\n",
       " '(stir-fried squid, worst, NEG, food quality)',\n",
       " '(side dishes, passable, POS, food style_options)',\n",
       " '(service, lack of, NEG, service general)',\n",
       " '(dish, mess, NEG, food quality)',\n",
       " '(risotto, amazing, POS, food quality)',\n",
       " '(farro salad, tasty, POS, food quality);(mashed yukon potatoes, tasty, POS, food quality)',\n",
       " '(margherita pizza, looove, POS, food quality)',\n",
       " '(place, Love, POS, restaurant general)',\n",
       " '(slice of NYC pizza, quintessential, NEU, food quality)',\n",
       " '(crust, great, POS, food quality);(crust, good, POS, food quality);(sauce, light, POS, food quality);(cheese, great, POS, food quality)',\n",
       " '(margherita pizza, like, POS, food quality)',\n",
       " '(Restaurant, Romantic, POS, ambience general)',\n",
       " '(sashimi amuse bouche, delightful, POS, food quality)',\n",
       " '(Grilled Black Cod, devoured, POS, food quality);(Grilled Salmon dish, better, POS, food quality)',\n",
       " '(service, leaves much to be desired, NEG, service general)',\n",
       " '',\n",
       " '(meat, fresh, POS, food quality);(sauces, great, POS, food quality);(service, good, POS, service general);(kimchi, free, POS, food prices);(salad, free, POS, food prices)',\n",
       " '(Korean food, classic, POS, food quality);(fusion twists, classic, POS, food quality);(pork belly tacos, classic, POS, food quality)',\n",
       " '(hot dogs, good, POS, food quality);(pork croquette sandwich, fantastic, POS, food quality);(bun, perfect, POS, food quality)',\n",
       " '(food, good, POS, food quality)',\n",
       " '(family seafood entree, good, POS, food quality)',\n",
       " '(main entree, good, POS, food quality)',\n",
       " '(food, good, NEG, food prices)',\n",
       " '(place, not inviting, NEG, ambience general);(food, weird, NEG, food quality)',\n",
       " '(food, not comforting, NEG, food quality);(food, not appetizing, NEG, food quality);(food, uncooked, NEG, food quality)',\n",
       " '',\n",
       " '(Pacifico, loved, POS, restaurant general)',\n",
       " '(atmosphere, great, POS, ambience general)',\n",
       " '(restaurant, bad, POS, restaurant general)',\n",
       " '(servers, perfected, NEG, service general)',\n",
       " '(meals, good, NEG, food quality)',\n",
       " '(chicken, appalled, NEG, food style_options)',\n",
       " '(spinach, undercooked, NEG, food quality)',\n",
       " '(drinks, enjoy, POS, drinks quality);(appetizers, enjoy, POS, food quality)',\n",
       " '(STAFF, FIRED, NEG, service general)',\n",
       " '',\n",
       " '(pizza, good, POS, food quality)',\n",
       " '(crust, cooked well, POS, food quality);(pizza, fully loaded, POS, food style_options)',\n",
       " '(Restaurant, Worst, NEG, restaurant general)',\n",
       " '(decor, cool, POS, ambience general);(pita, good, POS, food quality);(hummus, good, POS, food quality);(grilled octopus, tasty, POS, food quality)',\n",
       " '(scene, spectacular, POS, ambience general)',\n",
       " '(Hot Dogs, Great, POS, food quality)',\n",
       " '(hot dogs, top notch, POS, food quality);(Slamwich, amazing, POS, food quality)',\n",
       " '(Bark, worth, POS, restaurant general)',\n",
       " '(staff, horrified, NEG, service general)',\n",
       " '(food, fine, POS, food quality);(service, fine, POS, service general);(maitre-D, unwelcoming, NEG, service general);(maitre-D, arrogant, NEG, service general)',\n",
       " '(bottle of wine, high-end, POS, drinks quality)',\n",
       " '(frontman, bad, NEG, service general)',\n",
       " '(meal, Best, POS, food quality)',\n",
       " '(Mussles, superb, POS, food quality);(calamari, superb, POS, food quality)',\n",
       " '(Lamb special, perfect, POS, food quality)',\n",
       " '(flank steak, good, POS, food quality)',\n",
       " '(The Four Seasons restaurant, great, POS, restaurant general)',\n",
       " '(food, great, POS, food quality);(environment, better, POS, ambience general)',\n",
       " '(hot dog, elevated, POS, food style_options)',\n",
       " '',\n",
       " '(fish tacos, recommend, POS, food quality)',\n",
       " '(atmosphere, Cool, POS, ambience general)',\n",
       " '(service, Poor, NEG, service general)',\n",
       " '(Casa la Femme, awful, NEG, restaurant general)',\n",
       " '(manager, rude, NEG, service general)',\n",
       " '(food, good, NEU, food quality);(food, not outstanding, NEU, food quality)',\n",
       " '(bread, stale, NEG, food quality);(salad, overpriced, NEG, food style_options);(salad, empty, NEG, food style_options)',\n",
       " '(hostess, rude, NEG, service general)',\n",
       " '(bartender, disappeared, NEG, service general)',\n",
       " '(staff, rude, NEG, service general);(customer service, non-existent, NEG, service general)',\n",
       " '',\n",
       " '(place, like, POS, restaurant general)',\n",
       " '(food, good, POS, food quality)',\n",
       " '(space, good, POS, ambience general)',\n",
       " '(service, HORRID, NEG, service general)',\n",
       " '(spicy tuna roll, good, POS, food quality);(rock shrimp tempura, awesome, POS, food quality)',\n",
       " '(pink pony, love, POS, restaurant general)',\n",
       " '(spot, perfect, POS, restaurant general)',\n",
       " '(service, bad taste, NEG, service general)',\n",
       " '(sea urchin, heavenly, POS, food quality)',\n",
       " '(sushi, fresh, POS, food style_options);(sushi, proportioned, POS, food style_options)',\n",
       " '(food, well prepared, POS, food quality);(service, impecable, POS, service general)',\n",
       " '(kitchen, slow, NEG, service general)',\n",
       " '(service, great, POS, service general);(food, great, POS, food prices)',\n",
       " '(food, average to above-average, POS, food quality);(French Onion soup, not overly impressive, POS, food style_options);(desserts, not brilliant, NEG, food quality)',\n",
       " '(place, Japanese, POS, restaurant miscellaneous)',\n",
       " '(Leon, casual, POS, ambience general);(Leon, hip, POS, ambience general);(specials, good, POS, food quality);(atmosphere, warm, POS, ambience general);(atmosphere, lively, POS, ambience general);(French bistro fare, well prepared, POS, food quality)',\n",
       " '(food, bland oily, NEG, food quality)',\n",
       " '(lunch, not as good as I expected, NEG, food quality)',\n",
       " '(place, small, NEG, ambience general);(place, cramped, NEG, ambience general);(food, fantastic, POS, food quality)',\n",
       " '(open kitchen, charm, POS, ambience general);(restaurant, warm, NEG, ambience general)',\n",
       " '(wine selection, Great, POS, drinks style_options);(Gigondas, worth the price, POS, drinks quality);(house champagne, great value, POS, drinks prices)',\n",
       " '(place, recommended, POS, restaurant miscellaneous)',\n",
       " '(Service, not exactly five star, NEU, service general)',\n",
       " '(tuna, excellent, POS, food quality);(wasabe potatoes, excellent, POS, food quality)',\n",
       " '(Service, prompt, POS, service general);(Service, courteous, POS, service general)',\n",
       " '(pizza, delicious, POS, food quality)',\n",
       " '(Wine list selection, good, POS, drinks style_options);(wine-by-the-glass, generously filled, POS, drinks style_options)',\n",
       " '(Red Eye, NEVER been disappointed, POS, restaurant general)',\n",
       " '(live jazz band, taken, POS, ambience general);(atmosphere, taken, POS, ambience general)',\n",
       " '(Jekyll and Hyde Pub, great, POS, restaurant general);(Jekyll and Hyde Pub, fantastic, POS, restaurant general)',\n",
       " '(lobster roll, recommend, POS, food quality);(lobster, fresh, POS, food quality)',\n",
       " '(scallion pancakes, ordinary, NEU, food quality);(fried dumplings, ordinary, NEU, food quality)',\n",
       " '(Salads, fantastic, POS, food quality)',\n",
       " '(takeout, great, POS, service general)',\n",
       " '(staff, accomodating, POS, service general);(food, delicious, POS, food quality);(place, lovely, POS, ambience general)',\n",
       " '(dishes, simple, POS, food style_options);(wine, served efficiently, POS, drinks style_options);(atmosphere, bustling, POS, ambience general)',\n",
       " '(pizza, good, POS, food quality);(place, nice cozy, POS, ambience general)',\n",
       " '(place, nice, POS, ambience general)',\n",
       " '(food, excellent, POS, food quality);(service, excellent, POS, service general)',\n",
       " '(filet mignon dish, superb, POS, food quality)',\n",
       " '(ambience, like, POS, ambience general);(ambience, dark, POS, ambience general);(ambience, original, POS, ambience general)',\n",
       " '(ambient, affordable, POS, ambience general);(ambient, excellent, POS, ambience general)',\n",
       " '(place, hopping, POS, restaurant general);(place, great time, POS, restaurant general)',\n",
       " '(expresso, liked, POS, drinks quality)',\n",
       " '(Prune, memorable, NEG, restaurant general)',\n",
       " '(food, great, POS, food quality)',\n",
       " '(portions, large, POS, food style_options)',\n",
       " '(food, expect, NEG, food quality)',\n",
       " '(resturant, cramped, NEG, ambience general);(resturant, unappealing, NEG, ambience general)',\n",
       " '(Shabu-Shabu, loves, POS, food quality)',\n",
       " '(menu, limited, NEG, food style_options)',\n",
       " '(location, Ok, NEU, location general);(ambience, Ok, NEU, ambience general)',\n",
       " '(food, exceptional, POS, food quality);(service, exceptional, POS, service general)',\n",
       " '(service, excellent, POS, service general);(service, friendly, POS, service general);(service, attentive, POS, service general)',\n",
       " '(wine choices, good, POS, drinks style_options)',\n",
       " '(staff, Great, POS, service general)',\n",
       " '(staff, horrible, NEG, service general)',\n",
       " '(place, pricey, NEG, restaurant prices);(food, worth, POS, food quality)',\n",
       " '(Decor, nice, POS, ambience general);(service, spotty, NEG, service general)',\n",
       " '(food, awsome, POS, food quality)',\n",
       " '(meal, delicious, POS, food quality);(room, beautiful, POS, ambience general)',\n",
       " '(seats, uncomfortable, NEG, ambience general)',\n",
       " '(Waitstaff, friendly, POS, service general)',\n",
       " '(atmosphere, great, POS, ambience general)',\n",
       " '(Service, average, NEU, service general)',\n",
       " '(ambience, fun, POS, ambience general);(food, tasty, POS, food quality)',\n",
       " '(place, recommend, POS, restaurant general)',\n",
       " '(restaurant, traditional, POS, restaurant general)',\n",
       " '(ingredients, Fresh, POS, food quality)',\n",
       " '(food, recommend, NEG, food quality)',\n",
       " '(pastrami sandwich on a roll, huge, NEU, food style_options)',\n",
       " '(food, impressed, POS, food quality)',\n",
       " '(scallops, delicious, POS, food quality);(sauce, wonderful, POS, food quality)',\n",
       " '(place, glad, POS, restaurant general)',\n",
       " '(service, excellent, POS, service general);(food, delicious, POS, food quality)',\n",
       " '(food, cold, NEG, food quality);(food, soggy, NEG, food quality)',\n",
       " '(food, appetizing, POS, food style_options);(food, delicious, POS, food style_options)',\n",
       " '(pizza, best, POS, food quality)',\n",
       " '(food, mediocre, NEG, food quality);(service, horrible, NEG, service general)',\n",
       " '(kitchen food, delicious, POS, food quality);(Sushi, out of this world, POS, food quality)',\n",
       " '(rolls, unique, POS, food style_options)',\n",
       " '(cuisine, best, POS, food quality);(service, attentive, POS, service general);(service, charming, POS, service general)',\n",
       " '(entree, bland, NEG, food style_options);(entree, small, NEG, food style_options);(dessert, not inspired, NEG, food quality)',\n",
       " '(strawberry daiquiries, Wonderful, POS, drinks quality)',\n",
       " '(chicken and mashed potatos, devoured, POS, food quality)',\n",
       " '(joint, Great, POS, restaurant general)',\n",
       " '(selection of thin crust pizza, good, POS, food quality);(pizza place, nice, POS, restaurant general);(Basil slice, good, POS, food quality)',\n",
       " '(dosas, skimpy, NEG, food quality);(dosas, unattractive, NEG, food quality)',\n",
       " '(restaurant, beautiful, POS, location general)',\n",
       " '(food, good, POS, food quality);(basic dishes, good, POS, food quality);(drinks, delicious, POS, drinks quality)',\n",
       " '(spreads, Good, POS, food quality);(beverage selections, great, POS, drinks style_options);(bagels, tasty, POS, food quality)',\n",
       " '(cream cheeses, out of this world, POS, food quality);(coffee, love, POS, drinks quality)',\n",
       " '(fish, adequate, NEG, food style_options);(fish, inexpertly sliced, NEG, food style_options)',\n",
       " '(place, Ghetto, NEG, ambience general);(place, not even funny, NEG, ambience general)',\n",
       " '(Pizza, Awsome, POS, food quality);(Margheritta slice, Awsome, POS, food quality)',\n",
       " '(restaurant, special, POS, restaurant general)',\n",
       " '(restaurant, noisy, NEG, ambience general)',\n",
       " '(interior decor, cute, POS, ambience general);(place, little, POS, restaurant prices)',\n",
       " '(bagels, delicious, POS, food quality)',\n",
       " '(Service, fast, POS, service general);(Service, friendly, POS, service general)',\n",
       " '(Rao, good, NEU, restaurant general)',\n",
       " '(cheff, loved, POS, food style_options);(cheff, inovated, POS, food style_options)',\n",
       " '(Lucky Strike, great casual, POS, restaurant general)',\n",
       " '(place, great, POS, restaurant general)',\n",
       " '(BBQ ribs, best, POS, food style_options)',\n",
       " '(service, Quick, POS, service general);(service, friendly, POS, service general)',\n",
       " '(food, lot, POS, food prices);(place, exceeded my expectations, POS, restaurant general)',\n",
       " '(People, friendly, POS, service general)',\n",
       " '(bottles of wine, cheap, POS, drinks quality);(bottles of wine, good, POS, drinks quality)',\n",
       " '(food, aweful, NEG, food quality)',\n",
       " '(drinks, amazing, POS, drinks prices)',\n",
       " '(roti rolls, try, POS, food quality)',\n",
       " '(spices, Delicate, POS, food quality);(onions, Delicate, POS, food quality);(eggs, Delicate, POS, food quality);(roti, kick-ass, POS, food quality)',\n",
       " '(drumsticks over rice, Best, POS, food quality);(sour spicy soup, Best, POS, food quality)',\n",
       " '(Beef noodle soup, good, POS, food quality)',\n",
       " '(Taiwanese food, Best, POS, food quality)',\n",
       " '',\n",
       " '(Staff, accomodating, POS, service general)',\n",
       " '(decor, simple, POS, ambience general);(decor, comfortable, POS, ambience general)',\n",
       " '(crabmeat lasagna, out of this world, POS, food quality)',\n",
       " '(jazz duo, on POINT, POS, ambience general)',\n",
       " '(wine by the glass, good, POS, drinks quality)',\n",
       " '(food, okay, NEU, food quality)',\n",
       " '(food, solid, POS, food quality);(decor, nice, POS, ambience general)',\n",
       " '(vibe, relaxed, POS, ambience general);(vibe, cozy, POS, ambience general);(service, great, POS, service general);(food, excellent, POS, food quality)']"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = transform_to_quadruplet(merged_df, 'triplet', 'label')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadruplet_df = merged_df.drop(columns=['aste_label'])\n",
    "quadruplet_df['quadruplet_label'] = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadruplet_df[quadruplet_df['quadruplet_label']!=''].to_csv('D:/Kuliah/S2/Tesis/Code/Generative-ABSA-main/data/quadruplet/rest15/all_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>triplet</th>\n",
       "      <th>label</th>\n",
       "      <th>quadruplet_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>(place,good,NEG)</td>\n",
       "      <td>('place', 'restaurant general', 'negative')</td>\n",
       "      <td>(place, good, NEG, restaurant general)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We , there were four of us , arrived at noon -...</td>\n",
       "      <td>(staff,rude,NEG)</td>\n",
       "      <td>('staff', 'service general', 'negative')</td>\n",
       "      <td>(staff, rude, NEG, service general)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>(food,lousy,NEG);(food,too sweet,NEG);(food,to...</td>\n",
       "      <td>('food', 'food quality', 'negative'), ('portio...</td>\n",
       "      <td>(food, lousy, NEG, food quality);(food, too sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avoid this place</td>\n",
       "      <td>(place,Avoid,NEG)</td>\n",
       "      <td>('place', 'restaurant general', 'negative')</td>\n",
       "      <td>(place, Avoid, NEG, restaurant general)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have eaten at Saul , many times , the food i...</td>\n",
       "      <td>(food,good,POS)</td>\n",
       "      <td>('food', 'food quality', 'positive')</td>\n",
       "      <td>(food, good, POS, food quality)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>whoever the jazz duo was , they were on POINT</td>\n",
       "      <td>(jazz duo,on POINT,POS)</td>\n",
       "      <td>('jazz duo', 'ambience general', 'positive')</td>\n",
       "      <td>(jazz duo, on POINT, POS, ambience general)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>even the wine by the glass was good</td>\n",
       "      <td>(wine by the glass,good,POS)</td>\n",
       "      <td>('wine by the glass', 'drinks quality', 'posit...</td>\n",
       "      <td>(wine by the glass, good, POS, drinks quality)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>The food is okay and the prices here are medio...</td>\n",
       "      <td>(food,okay,NEU)</td>\n",
       "      <td>('food', 'food quality', 'neutral'), ('NULL', ...</td>\n",
       "      <td>(food, okay, NEU, food quality)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>Baluchi 's has solid food and a nice decor at ...</td>\n",
       "      <td>(food,solid,POS);(decor,nice,POS);(Baluchi 's,...</td>\n",
       "      <td>('food', 'food quality', 'positive'), ('decor'...</td>\n",
       "      <td>(food, solid, POS, food quality);(decor, nice,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>The vibe is very relaxed and cozy , service wa...</td>\n",
       "      <td>(vibe,relaxed,POS);(vibe,cozy,POS);(service,gr...</td>\n",
       "      <td>('vibe', 'ambience general', 'positive'), ('se...</td>\n",
       "      <td>(vibe, relaxed, POS, ambience general);(vibe, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>842 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  input  \\\n",
       "0     Judging from previous posts this used to be a ...   \n",
       "1     We , there were four of us , arrived at noon -...   \n",
       "2     The food was lousy - too sweet or too salty an...   \n",
       "3                                     Avoid this place    \n",
       "4     I have eaten at Saul , many times , the food i...   \n",
       "...                                                 ...   \n",
       "1068     whoever the jazz duo was , they were on POINT    \n",
       "1069               even the wine by the glass was good    \n",
       "1070  The food is okay and the prices here are medio...   \n",
       "1071  Baluchi 's has solid food and a nice decor at ...   \n",
       "1073  The vibe is very relaxed and cozy , service wa...   \n",
       "\n",
       "                                                triplet  \\\n",
       "0                                      (place,good,NEG)   \n",
       "1                                      (staff,rude,NEG)   \n",
       "2     (food,lousy,NEG);(food,too sweet,NEG);(food,to...   \n",
       "3                                     (place,Avoid,NEG)   \n",
       "4                                       (food,good,POS)   \n",
       "...                                                 ...   \n",
       "1068                            (jazz duo,on POINT,POS)   \n",
       "1069                       (wine by the glass,good,POS)   \n",
       "1070                                    (food,okay,NEU)   \n",
       "1071  (food,solid,POS);(decor,nice,POS);(Baluchi 's,...   \n",
       "1073  (vibe,relaxed,POS);(vibe,cozy,POS);(service,gr...   \n",
       "\n",
       "                                                  label  \\\n",
       "0           ('place', 'restaurant general', 'negative')   \n",
       "1              ('staff', 'service general', 'negative')   \n",
       "2     ('food', 'food quality', 'negative'), ('portio...   \n",
       "3           ('place', 'restaurant general', 'negative')   \n",
       "4                  ('food', 'food quality', 'positive')   \n",
       "...                                                 ...   \n",
       "1068       ('jazz duo', 'ambience general', 'positive')   \n",
       "1069  ('wine by the glass', 'drinks quality', 'posit...   \n",
       "1070  ('food', 'food quality', 'neutral'), ('NULL', ...   \n",
       "1071  ('food', 'food quality', 'positive'), ('decor'...   \n",
       "1073  ('vibe', 'ambience general', 'positive'), ('se...   \n",
       "\n",
       "                                       quadruplet_label  \n",
       "0                (place, good, NEG, restaurant general)  \n",
       "1                   (staff, rude, NEG, service general)  \n",
       "2     (food, lousy, NEG, food quality);(food, too sw...  \n",
       "3               (place, Avoid, NEG, restaurant general)  \n",
       "4                       (food, good, POS, food quality)  \n",
       "...                                                 ...  \n",
       "1068        (jazz duo, on POINT, POS, ambience general)  \n",
       "1069     (wine by the glass, good, POS, drinks quality)  \n",
       "1070                    (food, okay, NEU, food quality)  \n",
       "1071  (food, solid, POS, food quality);(decor, nice,...  \n",
       "1073  (vibe, relaxed, POS, ambience general);(vibe, ...  \n",
       "\n",
       "[842 rows x 4 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadruplet_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadruplet Manual Anotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_id</th>\n",
       "      <th>original_tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>nolimit_sentiment</th>\n",
       "      <th>nolimit_aspect_categories</th>\n",
       "      <th>quadruplet</th>\n",
       "      <th>annotated_spam</th>\n",
       "      <th>model_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.640000e+18</td>\n",
       "      <td>@loseratlover @TokopediaCare @gojekindonesia @...</td>\n",
       "      <td>Sering di toko ini dibawa kabur kurir, temen s...</td>\n",
       "      <td>negative</td>\n",
       "      <td>delivery; produk;</td>\n",
       "      <td>(toko, sering dibawa kabur kurir, negative, de...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.640000e+18</td>\n",
       "      <td>@bukugpu @fiksigpu @sastragpu @bincang_buku @K...</td>\n",
       "      <td>Min Funicula di Tokped belum diskon %. Tolong ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>price; produk;</td>\n",
       "      <td>(Funicula, belum diskon, neutral, price);</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.640000e+18</td>\n",
       "      <td>admin blibli kocak juga</td>\n",
       "      <td>admin blibli kocak juga</td>\n",
       "      <td>neutral</td>\n",
       "      <td>customerservice; produk;</td>\n",
       "      <td>(admin blibli, kocak, positive, customerservice);</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.640000e+18</td>\n",
       "      <td>@tokopedia upload video untuk komplain lama se...</td>\n",
       "      <td>upload video untuk komplain lama sekali, mana ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>website&amp;apps; produk;</td>\n",
       "      <td>(upload video, lama sekali, negative, website&amp;...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.640000e+18</td>\n",
       "      <td>Kalo barang ga sesuai bisa diajukan pengembali...</td>\n",
       "      <td>Kalo barang ga sesuai bisa diajukan pengembali...</td>\n",
       "      <td>negative</td>\n",
       "      <td>payment; produk;</td>\n",
       "      <td>(barang, ga sesuai, neutral, payment);</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    original_id                                     original_tweet  \\\n",
       "0  1.640000e+18  @loseratlover @TokopediaCare @gojekindonesia @...   \n",
       "1  1.640000e+18  @bukugpu @fiksigpu @sastragpu @bincang_buku @K...   \n",
       "2  1.640000e+18                            admin blibli kocak juga   \n",
       "3  1.640000e+18  @tokopedia upload video untuk komplain lama se...   \n",
       "4  1.640000e+18  Kalo barang ga sesuai bisa diajukan pengembali...   \n",
       "\n",
       "                                         clean_tweet nolimit_sentiment  \\\n",
       "0  Sering di toko ini dibawa kabur kurir, temen s...          negative   \n",
       "1  Min Funicula di Tokped belum diskon %. Tolong ...          negative   \n",
       "2                            admin blibli kocak juga           neutral   \n",
       "3  upload video untuk komplain lama sekali, mana ...          negative   \n",
       "4  Kalo barang ga sesuai bisa diajukan pengembali...          negative   \n",
       "\n",
       "  nolimit_aspect_categories  \\\n",
       "0         delivery; produk;   \n",
       "1            price; produk;   \n",
       "2  customerservice; produk;   \n",
       "3     website&apps; produk;   \n",
       "4          payment; produk;   \n",
       "\n",
       "                                          quadruplet  annotated_spam  \\\n",
       "0  (toko, sering dibawa kabur kurir, negative, de...               2   \n",
       "1          (Funicula, belum diskon, neutral, price);               2   \n",
       "2  (admin blibli, kocak, positive, customerservice);               2   \n",
       "3  (upload video, lama sekali, negative, website&...               2   \n",
       "4             (barang, ga sesuai, neutral, payment);               2   \n",
       "\n",
       "   model_spam  \n",
       "0           2  \n",
       "1           2  \n",
       "2           2  \n",
       "3           2  \n",
       "4           2  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/quadruplet_test_pred.csv')\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        'content' : 'original_tweet',\n",
    "        'final_sentiment' : 'nolimit_sentiment',\n",
    "        'labels' : 'nolimit_aspect_categories',\n",
    "        'sentiment_label' : 'annotated_spam',\n",
    "        'preds' : 'model_spam'\n",
    "    }\n",
    ")\n",
    "df['quadruplet'] = df['quadruplet'].apply(lambda x:x[1:-1])\n",
    "df = df.drop(columns=['pred_quadruplet_pt_t5', 'pred_quadruplet_tf_t5', 'spam'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/quadruplet_only.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import BertForSequenceClassification\n",
    "import preprocessor as p\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from tqdm.auto import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('indolem/indobert-base-uncased')\n",
    "id2label = {0: \"SPAM\", 1: \"OBJECTIVE\", 2:\"SUBJECTIVE\"}\n",
    "label2id = {\"SPAM\": 0, \"OBJECTIVE\": 1, \"SUBJECTIVE\":2}\n",
    "model = BertForSequenceClassification.from_pretrained('D:/Kuliah/S2/Tesis/Code/spam_detection/test-trainer/checkpoint-1770'\n",
    "                                                      , num_labels=3, id2label=id2label, label2id=label2id).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ecommerce_Indonesia_01-Dec-2022_31-Dec-2022_TIJA1y16tr_0.csv',\n",
       " 'Ecommerce_Indonesia_01-Dec-2022_31-Dec-2022_TIJA1y16tr_1.csv',\n",
       " 'Ecommerce_Indonesia_01-Dec-2022_31-Dec-2022_TIJA1y16tr_2.csv',\n",
       " 'Ecommerce_Indonesia_01-Dec-2022_31-Dec-2022_TIJA1y16tr_3.csv',\n",
       " 'Ecommerce_Indonesia_01-Dec-2022_31-Dec-2022_TIJA1y16tr_4.csv',\n",
       " 'Ecommerce_Indonesia_01-Jan-2023_31-Jan-2023_gtJEUiS9JH_0.csv',\n",
       " 'Ecommerce_Indonesia_01-Jan-2023_31-Jan-2023_gtJEUiS9JH_1.csv',\n",
       " 'Ecommerce_Indonesia_01-Jan-2023_31-Jan-2023_gtJEUiS9JH_2.csv',\n",
       " 'Ecommerce_Indonesia_01-Jan-2023_31-Jan-2023_gtJEUiS9JH_3.csv',\n",
       " 'Ecommerce_Indonesia_01-Jan-2023_31-Jan-2023_gtJEUiS9JH_4.csv',\n",
       " 'Ecommerce_Indonesia_01-Nov-2022_30-Nov-2022_wjV3n9Ppve_0.csv',\n",
       " 'Ecommerce_Indonesia_01-Nov-2022_30-Nov-2022_wjV3n9Ppve_1.csv',\n",
       " 'Ecommerce_Indonesia_01-Nov-2022_30-Nov-2022_wjV3n9Ppve_2.csv',\n",
       " 'Ecommerce_Indonesia_01-Nov-2022_30-Nov-2022_wjV3n9Ppve_3.csv',\n",
       " 'Ecommerce_Indonesia_01-Nov-2022_30-Nov-2022_wjV3n9Ppve_4.csv',\n",
       " 'Ecommerce_Indonesia_01-Nov-2022_30-Nov-2022_wjV3n9Ppve_5.csv']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\1798584822.py:2: DtypeWarning: Columns (52,58,65,68,70,71,72,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,130,131,132,133,134,135,136,137,138,139,140,141,142,143,145,147,148,149,150,151,152,153,154,155,156,157,158,159,160,162,163,164,167,168,169,170,171,172,173,174,175,177,178,179,180,181,182,183,184,185,187,188,191,192,194,195,196,197,198,199,200,201,202,203,204,206,207,208,209,210,212,213,214,216,217,218,219,220,221,223,224,225,229,232,233,234,237,238,239,243,244,245,247,248,251,252,254,256,257,261,262,263,264,266,267,268,270,271,273,274,275,277,278,279,280,282,284,286,287,289,291,292,293,295,296,298,299,301,303,304,305,306,307,308,309,310,311,312,313,315,321,322,327,328,329,330,331,333,334,338,342,345,347,350,351,352,353,355,357,358,359,365,366,367,368,369,371,372,373,375,376,377,379,380,381,382,383,385,386,387,388,389,391,392,393,395,396,397,398,399,400,401,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,428,429,430,432,433,434,436,438,441,442,443,444,446,447,448,449,451,452,454,455,456,457,458,459,460,461,462,463,464,465,466,467,469,470,471,472,473,474,476,477,478,479,480,481,482,485,486,488,489,490,492,494,495,496,498,499,501,502,503,504,506,508,509,510,511,513,514,516,517,519,520,521,522,525,526,527,530,532,535,536,538,540,542,543,545,549,550,553,554,555,556,557,558,559,560,561,565,566,567,569,570,572,573,574,576,577,578,580,581,585,591,593,594,596,597,598,599,600,604,605,606,607,608,610,621,626,627,628,629,631,634,635,638,639,641,644,645,706,709,710,713) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\1798584822.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n"
     ]
    }
   ],
   "source": [
    "file_path = f'{post_train_folder}/{csv_files[0]}'\n",
    "df = pd.read_csv(file_path, sep=';')\n",
    "clean_df = df[(df['post_type']==\"'talk\")& #karena yg post\n",
    "                (df['lang']==\"'in\")&\n",
    "                (df['content_type']==\"'text\")\n",
    "            ]\n",
    "clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
    "clean_df = clean_df.drop_duplicates(subset=['clean_tweet'])\n",
    "clean_df = clean_df.reset_index(drop=True)\n",
    "clean_df = clean_df['clean_tweet'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26690, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:6: DtypeWarning: Columns (52,58,65,68,70,71,72,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,130,131,132,133,134,135,136,137,138,139,140,141,142,143,145,147,148,149,150,151,152,153,154,155,156,157,158,159,160,162,163,164,167,168,169,170,171,172,173,174,175,177,178,179,180,181,182,183,184,185,187,188,191,192,194,195,196,197,198,199,200,201,202,203,204,206,207,208,209,210,212,213,214,216,217,218,219,220,221,223,224,225,229,232,233,234,237,238,239,243,244,245,247,248,251,252,254,256,257,261,262,263,264,266,267,268,270,271,273,274,275,277,278,279,280,282,284,286,287,289,291,292,293,295,296,298,299,301,303,304,305,306,307,308,309,310,311,312,313,315,321,322,327,328,329,330,331,333,334,338,342,345,347,350,351,352,353,355,357,358,359,365,366,367,368,369,371,372,373,375,376,377,379,380,381,382,383,385,386,387,388,389,391,392,393,395,396,397,398,399,400,401,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,428,429,430,432,433,434,436,438,441,442,443,444,446,447,448,449,451,452,454,455,456,457,458,459,460,461,462,463,464,465,466,467,469,470,471,472,473,474,476,477,478,479,480,481,482,485,486,488,489,490,492,494,495,496,498,499,501,502,503,504,506,508,509,510,511,513,514,516,517,519,520,521,522,525,526,527,530,532,535,536,538,540,542,543,545,549,550,553,554,555,556,557,558,559,560,561,565,566,567,569,570,572,573,574,576,577,578,580,581,585,591,593,594,596,597,598,599,600,604,605,606,607,608,610,621,626,627,628,629,631,634,635,638,639,641,644,645,706,709,710,713) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
      "100%|██████████| 26690/26690 [03:35<00:00, 123.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:6: DtypeWarning: Columns (52,54,58,65,68,70,71,72,75,76,77,78,79,80,81,82,83,84,85,87,88,89,90,91,92,93,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,130,131,132,133,134,135,136,137,138,139,140,142,143,145,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,185,186,187,188,190,191,192,194,195,196,197,198,200,202,203,204,206,207,208,209,210,211,212,213,214,216,217,218,219,223,224,225,229,232,233,234,238,239,241,243,245,247,248,249,251,252,253,254,255,257,258,261,262,263,266,267,269,270,274,275,277,278,279,280,281,282,284,286,288,289,291,292,293,296,298,299,300,301,302,303,304,305,306,307,309,310,311,312,313,319,321,322,325,327,328,329,330,333,334,335,338,339,342,343,345,346,347,348,350,351,352,353,355,357,358,359,365,366,367,368,371,372,373,376,377,379,380,382,383,384,385,386,387,388,389,390,392,393,395,396,397,398,400,401,404,405,406,407,408,409,411,412,413,414,415,416,417,418,419,420,421,422,423,424,426,428,429,430,431,432,433,434,436,438,439,441,442,443,444,445,446,447,448,450,451,452,453,455,456,458,459,460,461,462,463,464,465,466,467,469,470,471,472,473,474,475,476,477,478,479,480,481,482,484,486,488,489,490,491,494,495,496,498,499,501,502,503,504,506,508,509,510,511,513,516,517,519,521,522,525,526,527,528,529,530,532,535,536,538,540,542,543,546,549,550,554,556,557,558,561,564,567,568,569,570,572,573,574,576,577,578,580,581,586,589,591,593,594,596,597,598,599,600,604,606,607,608,626,627,628,629,630,631,632,633,634,635,636,639,641,642,643,644,645,706,709,710,713) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
      "100%|██████████| 28740/28740 [03:53<00:00, 122.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18710, 2)\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:6: DtypeWarning: Columns (52,58,65,68,69,70,71,72,75,76,77,78,79,80,81,82,83,84,85,87,88,89,90,91,92,93,94,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,130,131,132,133,134,135,136,137,138,139,140,142,143,145,147,148,149,150,151,152,153,154,155,156,157,158,159,160,162,163,164,167,168,169,170,171,172,173,174,175,177,178,179,180,181,182,183,184,185,186,187,188,190,191,192,194,195,196,197,198,199,200,201,202,203,204,206,207,208,209,210,211,212,213,214,216,217,218,219,220,223,224,225,227,228,229,232,233,234,237,238,241,242,243,244,245,247,248,249,251,252,253,254,255,256,257,258,261,262,263,264,265,266,267,268,270,271,273,274,275,277,278,279,280,281,282,284,286,290,291,292,293,295,296,298,299,300,301,303,304,305,306,307,308,309,310,311,312,313,315,319,321,322,323,324,325,327,328,329,330,333,334,341,342,343,345,346,347,349,350,351,352,353,354,355,357,358,359,365,366,367,368,371,372,373,375,377,379,380,381,382,383,384,385,386,387,389,390,391,392,393,395,396,397,398,399,400,401,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,426,427,428,429,430,431,432,433,434,436,437,438,439,441,442,443,444,445,446,447,448,449,451,452,453,455,456,457,458,459,460,461,462,463,464,465,466,467,469,470,471,472,473,474,475,476,478,479,480,481,482,484,485,486,488,489,490,492,494,495,496,498,499,501,502,503,504,505,506,508,509,510,511,512,513,514,516,519,520,521,522,523,524,525,526,527,528,530,532,533,534,535,536,538,539,540,542,543,545,546,547,549,550,551,552,553,554,556,557,559,560,561,567,569,570,572,573,574,576,577,578,580,581,582,583,584,585,587,588,589,590,591,592,593,594,596,597,598,599,600,602,604,605,606,607,608,612,613,621,626,627,628,629,630,631,632,633,634,635,637,638,639,641,643,644,645,706,709,710,713,714) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
      "100%|██████████| 25077/25077 [03:23<00:00, 123.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26006, 2)\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:6: DtypeWarning: Columns (15,51,52,53,58,62,65,67,68,70,71,72,74,75,76,77,78,79,80,81,83,84,85,87,89,90,91,92,93,94,97,98,99,101,102,103,104,106,108,109,110,111,112,113,114,115,116,119,120,121,122,123,124,125,127,130,131,132,133,134,135,136,137,138,139,140,142,145,147,148,149,150,151,152,153,158,159,161,163,165,168,169,170,173,178,179,180,182,183,185,187,188,190,191,192,194,195,198,202,204,206,209,212,213,214,218,219,224,225,232,234,243,244,245,254,257,263,265,266,267,270,275,278,280,281,284,286,287,291,293,296,298,299,301,303,304,306,310,312,315,322,328,329,333,334,335,338,342,347,350,351,353,358,359,368,371,377,380,382,383,385,386,387,392,393,395,396,401,405,406,407,408,409,410,413,414,415,417,419,420,421,422,423,424,426,428,430,432,433,440,442,444,446,450,451,455,456,459,460,463,464,465,467,470,472,473,475,476,480,482,488,495,496,498,499,501,502,503,504,505,506,508,509,510,511,514,516,519,520,521,522,525,527,530,532,536,538,542,543,550,556,570,571,572,573,574,575,577,578,580,589,590,592,593,594,597,598,600,604,606,607,608,621,626,627,628,629,634,635,639,640,641,642,643,645,706,708,709,710,711,712,713) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
      "100%|██████████| 12569/12569 [01:38<00:00, 127.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28990, 2)\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:6: DtypeWarning: Columns (51,53,62,67,74,75,89,161,165,167,178,180,190,219,266,406,419,440,476,506,519,525,571,626,634,635,640,642,675,706,708,713) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
      "100%|██████████| 969/969 [00:07<00:00, 125.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29177, 2)\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:6: DtypeWarning: Columns (51,52,58,65,68,69,70,71,72,75,76,77,78,79,80,81,82,83,84,85,87,88,89,90,91,92,93,94,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,130,131,132,133,134,135,136,137,138,139,140,141,142,143,145,146,147,148,149,150,151,152,153,154,155,157,158,159,160,162,163,164,167,168,169,170,171,172,173,174,175,177,178,179,180,182,183,184,185,186,187,188,191,192,194,195,196,197,198,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,216,217,218,219,223,224,225,229,232,234,237,238,239,241,243,244,245,248,249,251,252,254,255,256,257,258,261,262,263,264,266,267,268,270,271,274,277,278,279,280,282,284,286,289,290,291,292,293,296,297,298,299,300,301,302,303,304,305,306,307,309,310,311,312,313,314,315,319,321,322,323,325,328,329,330,331,333,334,335,338,339,342,343,345,347,349,350,351,352,353,354,357,358,359,360,366,367,368,369,371,372,373,374,375,376,377,378,379,380,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,432,433,434,436,437,438,439,440,442,443,444,445,446,447,448,449,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,485,486,487,488,489,490,492,494,495,496,497,498,499,500,501,502,503,504,506,508,509,510,511,513,516,517,519,520,521,522,524,525,526,527,528,529,530,531,532,536,538,540,542,543,545,549,550,552,553,554,555,556,557,560,561,566,567,568,569,570,571,572,573,574,575,576,577,578,580,581,582,583,584,585,586,589,590,591,592,593,594,596,597,598,599,600,603,604,605,606,607,608,610,611,612,614,622,626,627,628,629,630,631,632,633,634,635,639,641,643,644,645,706,708,709,711,713,714) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
      "100%|██████████| 28371/28371 [03:50<00:00, 123.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37197, 2)\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:6: DtypeWarning: Columns (15,31,37,38,51,52,53,54,58,62,65,67,68,69,70,71,72,74,75,76,77,78,79,80,81,82,83,84,85,87,88,89,90,91,92,93,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,119,120,121,122,123,124,125,126,127,128,130,131,132,133,134,135,136,137,138,139,140,141,142,145,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,167,168,169,170,172,173,175,177,178,179,180,182,183,184,185,186,187,188,191,192,194,195,196,197,198,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,216,217,218,219,220,223,224,225,229,232,234,237,243,244,245,251,252,254,257,261,262,263,264,266,267,268,270,274,277,278,279,280,281,282,284,286,291,292,293,296,297,298,299,301,302,303,304,305,306,307,309,310,312,313,319,322,324,328,329,330,333,334,335,337,338,342,343,345,347,349,350,351,352,353,355,357,358,359,366,367,368,371,372,373,375,377,380,382,383,384,385,386,387,388,389,390,392,393,396,397,398,399,400,401,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,424,425,426,427,428,429,430,431,432,433,434,436,437,438,439,440,441,442,443,444,446,447,448,449,450,451,452,454,455,456,457,458,459,460,461,462,463,464,465,466,467,469,470,471,472,473,474,475,476,478,479,480,481,482,485,486,487,488,490,492,494,495,496,498,499,501,503,504,506,508,509,510,511,513,514,519,520,521,522,524,525,526,527,530,532,533,535,536,538,540,542,543,545,549,550,553,554,556,560,566,567,568,570,571,572,573,574,575,576,577,578,580,581,583,584,589,590,591,593,597,599,600,604,605,607,608,611,612,613,626,627,628,629,631,634,635,638,639,640,641,642,643,644,645,706,708,709,711,712,713,714) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
      "100%|██████████| 17680/17680 [02:23<00:00, 123.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44186, 2)\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:6: DtypeWarning: Columns (15,51,52,53,54,58,62,65,67,68,70,71,72,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,96,97,98,99,100,102,103,104,105,106,108,109,110,111,112,113,114,116,117,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,138,139,140,142,143,145,147,148,149,150,152,153,154,155,156,158,159,160,163,164,167,168,169,170,171,172,173,174,175,177,178,179,180,181,182,183,184,185,186,187,188,190,191,192,194,195,196,197,198,199,200,202,203,204,206,207,208,209,210,211,212,213,214,216,217,218,219,220,223,224,225,227,229,232,234,243,244,245,248,249,251,252,254,255,256,257,258,261,262,263,264,266,267,268,270,272,273,274,277,278,279,280,281,282,284,286,288,291,292,293,297,298,299,300,301,302,303,304,305,307,309,310,311,312,313,315,319,321,322,328,329,330,333,334,335,342,345,347,348,350,351,352,353,355,357,358,359,365,366,367,368,371,372,373,377,380,382,383,384,385,386,387,389,390,391,392,393,395,396,397,398,400,401,404,405,406,407,409,410,411,412,413,414,415,417,419,420,421,422,424,426,428,429,430,431,432,433,436,437,438,440,442,443,444,446,448,451,452,453,455,456,457,458,459,460,461,462,463,464,465,466,467,469,470,471,472,474,475,476,479,480,481,482,484,485,486,488,494,495,496,498,499,500,501,502,503,504,505,506,508,509,510,511,512,513,516,519,520,521,522,524,525,526,527,530,531,532,533,534,535,536,538,540,542,543,545,549,550,553,554,556,561,563,564,567,568,569,570,571,572,573,574,575,577,578,580,581,583,584,585,586,587,589,591,593,594,596,597,598,599,600,604,605,606,607,608,622,626,627,628,629,630,631,632,634,635,636,637,639,640,641,642,643,644,645,675,706,708,709,711,712,713,714) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
      "100%|██████████| 14075/14075 [01:52<00:00, 125.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47123, 2)\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:6: DtypeWarning: Columns (15,16,17,19,22,33,34,35,37,38,39,51,52,53,54,58,62,65,67,68,69,70,71,72,73,74,75,76,77,80,82,83,84,87,88,89,90,91,92,93,94,96,97,98,99,102,103,104,106,108,109,110,111,112,113,114,120,121,122,123,124,127,128,130,131,132,134,135,138,140,142,143,145,147,148,149,150,153,154,155,158,159,160,161,163,164,165,167,168,169,172,173,175,177,178,179,180,182,184,185,187,188,191,192,197,198,202,203,204,208,209,210,212,213,214,218,219,223,224,225,229,232,234,243,244,245,252,254,255,257,263,264,266,267,268,270,273,274,278,279,280,281,284,286,291,292,293,298,299,303,304,305,306,307,312,313,322,328,329,331,333,334,335,345,350,352,353,357,358,359,360,366,367,368,372,373,382,385,387,390,392,393,396,398,399,404,405,406,407,409,413,415,419,420,422,423,426,429,432,438,440,442,444,446,448,451,455,458,459,460,461,462,463,464,465,467,470,472,474,475,476,481,482,485,486,488,489,490,491,492,495,496,499,501,503,504,505,506,508,509,510,511,512,513,514,516,519,520,521,522,525,526,527,530,532,533,534,536,538,543,549,550,556,567,568,569,570,571,572,573,574,575,576,577,578,580,581,585,586,590,592,593,597,604,605,607,608,610,626,627,628,629,633,634,638,639,640,641,642,643,644,645,675,706,708,709,711,712,713,714) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
      "100%|██████████| 5933/5933 [00:48<00:00, 122.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49437, 2)\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:6: DtypeWarning: Columns (15,51,52,53,58,62,65,67,68,70,72,74,75,77,79,83,84,87,89,90,92,93,97,98,99,102,103,104,106,109,111,112,113,119,121,124,125,126,131,134,135,136,138,140,145,148,153,156,158,160,161,163,165,167,168,169,171,173,175,177,178,179,180,182,183,185,187,188,192,195,198,204,212,213,218,219,229,238,243,245,251,254,257,266,267,279,280,291,293,294,298,299,313,329,333,334,335,347,350,351,353,355,366,367,368,373,385,386,387,392,393,396,397,406,415,416,420,422,426,432,440,444,450,455,458,459,460,461,463,471,472,474,476,482,488,496,498,499,502,503,504,508,509,510,516,519,520,521,522,525,527,529,532,536,538,542,546,556,567,570,571,573,575,589,594,597,607,608,626,627,628,629,633,634,635,640,641,642,643,645,675,706,708,709,710,711,712,713,714) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
      "100%|██████████| 6298/6298 [00:49<00:00, 126.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51576, 2)\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:6: DtypeWarning: Columns (15,51,52,53,54,58,62,65,67,68,69,70,71,72,74,75,76,77,78,79,80,81,82,83,84,85,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,130,131,132,133,134,135,136,137,138,139,140,142,143,145,147,148,149,150,151,152,153,154,155,158,159,160,161,162,163,164,165,167,168,169,170,172,173,175,177,178,179,180,182,183,185,187,188,189,191,192,194,195,196,197,198,200,201,202,203,204,206,207,208,209,210,211,212,213,214,216,217,218,219,220,223,224,225,229,232,234,237,238,243,244,245,251,252,254,256,257,261,262,263,266,267,270,273,274,277,278,279,280,282,284,286,291,292,293,295,296,297,298,299,300,301,302,303,304,305,307,309,310,311,312,313,319,321,322,323,325,327,328,329,330,331,333,334,335,339,342,345,347,350,351,352,353,357,358,359,366,367,368,371,372,373,375,377,380,381,382,383,384,385,386,387,389,390,391,392,393,395,396,397,398,399,400,401,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,436,437,438,439,440,441,442,443,444,446,447,448,451,452,453,455,456,458,459,460,461,462,463,464,465,466,469,470,471,472,473,474,475,476,478,479,480,481,482,484,486,488,489,490,492,494,495,496,498,499,500,501,502,503,504,505,506,508,509,510,511,513,514,516,517,519,521,522,524,525,526,527,529,530,532,535,536,538,540,542,543,549,550,554,556,557,558,559,567,569,570,571,572,573,574,575,577,578,580,584,585,587,589,592,593,594,596,597,598,599,600,604,607,608,610,613,626,627,628,629,630,631,632,633,634,635,638,639,640,641,642,643,644,645,675,711,712,713) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
      "100%|██████████| 16519/16519 [02:12<00:00, 124.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58322, 2)\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:6: DtypeWarning: Columns (51,52,53,54,58,62,65,67,68,70,71,72,74,75,76,77,78,79,80,81,82,83,84,85,87,88,89,90,91,92,93,94,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,119,120,121,122,123,124,125,126,127,128,130,131,132,133,134,135,136,138,139,140,142,143,145,146,147,148,149,150,151,152,153,154,156,158,159,160,162,163,164,167,168,169,170,171,172,173,174,175,177,178,179,182,183,184,185,187,188,189,191,192,194,195,196,197,198,200,202,203,204,206,207,208,209,210,211,212,213,214,216,217,218,219,220,223,224,225,227,229,232,234,237,238,239,243,244,245,248,251,252,254,256,257,258,261,263,266,267,268,270,273,274,277,278,279,280,282,286,291,292,293,295,296,298,299,301,302,303,304,305,306,307,309,310,311,312,313,319,321,322,323,325,328,329,330,332,333,334,335,342,343,345,347,349,350,351,352,353,358,359,365,366,367,368,371,372,373,374,377,382,383,384,385,386,387,389,390,392,393,395,396,397,398,399,400,404,405,406,407,408,409,410,411,412,413,414,415,416,417,419,420,421,422,423,424,426,427,428,429,430,432,433,434,436,438,440,441,442,443,444,446,447,448,449,451,452,453,455,456,457,458,459,460,461,462,463,464,465,466,467,469,470,471,472,473,474,475,476,478,479,480,481,482,483,486,488,489,492,494,495,496,498,499,500,502,503,504,505,506,508,509,510,511,513,514,516,517,519,520,521,522,525,527,528,530,532,535,536,538,540,542,543,545,549,550,554,556,557,560,561,567,569,570,571,572,573,574,575,577,578,579,580,581,591,594,597,598,599,600,602,604,605,606,607,608,610,613,614,616,619,626,627,628,629,630,631,632,634,635,638,639,640,641,642,643,644,645,711,713) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
      "100%|██████████| 31090/31090 [04:11<00:00, 123.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66659, 2)\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:6: DtypeWarning: Columns (51,52,53,54,58,62,65,67,68,69,70,71,72,74,75,76,77,78,79,80,81,82,83,84,85,87,88,89,90,91,92,93,94,96,97,98,99,100,101,102,103,104,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,133,134,135,136,137,138,139,140,142,143,145,147,148,149,150,151,152,153,154,155,158,159,160,162,163,164,167,168,169,170,171,172,173,174,175,177,178,179,181,182,183,184,185,186,187,188,189,191,192,194,195,196,197,198,200,202,203,204,205,206,207,208,209,210,211,212,213,214,216,217,218,219,220,223,224,225,229,232,234,238,243,244,245,248,251,254,256,257,258,261,262,263,264,265,266,267,268,270,272,273,274,277,278,279,280,281,282,284,286,289,291,292,293,294,295,296,298,299,300,301,303,304,305,306,307,309,310,311,312,313,318,319,321,322,323,328,329,330,331,332,333,334,335,337,342,345,346,347,350,351,352,353,355,357,358,359,360,365,366,367,368,371,372,373,375,377,379,380,381,382,383,385,386,387,389,390,391,392,393,394,395,396,397,398,399,400,401,404,405,406,407,408,409,410,411,412,413,414,415,416,417,419,420,421,422,424,426,428,429,430,431,432,433,434,436,437,440,441,442,443,444,446,447,448,451,452,454,455,456,457,458,459,460,461,462,463,464,465,466,469,470,471,472,474,475,476,478,479,480,481,482,484,485,486,488,489,490,492,494,495,496,498,499,500,501,502,503,504,505,506,508,509,510,511,512,513,514,516,519,520,521,522,523,525,526,527,529,530,532,533,534,535,536,538,540,541,542,543,546,549,550,553,556,557,560,564,567,568,570,571,572,573,574,575,576,577,578,580,581,582,583,584,585,587,588,589,590,591,594,596,597,598,599,600,604,606,607,608,623,626,627,628,629,630,632,634,635,637,638,639,640,641,642,643,644,645,713) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
      "100%|██████████| 18014/18014 [02:23<00:00, 125.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72478, 2)\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:6: DtypeWarning: Columns (15,51,52,53,58,62,65,67,68,70,71,72,74,75,76,77,80,81,83,84,85,87,88,89,90,91,92,93,94,96,98,99,100,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,119,120,121,123,124,125,127,128,130,131,133,134,135,138,139,140,141,142,143,145,147,148,149,150,152,153,154,155,156,157,158,159,160,162,163,164,167,168,169,170,171,173,174,175,177,178,179,181,182,183,184,185,187,188,191,192,195,196,197,198,202,203,204,206,207,208,209,210,211,212,213,214,216,217,218,219,223,224,225,229,232,234,239,243,244,245,247,248,249,251,254,256,257,261,262,263,264,265,266,267,268,269,270,273,274,277,278,279,280,281,282,284,286,291,292,293,296,298,299,302,303,304,306,307,309,310,311,313,322,327,328,329,330,331,333,334,335,338,342,346,347,348,350,351,352,353,358,359,361,366,367,368,371,372,373,377,379,380,382,383,384,385,386,387,388,389,390,391,392,393,395,396,397,398,399,400,401,404,405,406,407,408,409,411,412,413,414,415,417,419,420,422,424,426,428,429,430,432,433,434,436,437,440,442,443,444,446,447,451,452,454,455,456,457,458,459,460,461,462,463,464,465,466,467,469,470,471,472,474,475,476,477,478,480,481,482,483,486,488,490,491,492,494,496,498,499,501,502,503,504,505,506,508,509,510,511,512,513,514,516,519,520,521,522,524,525,526,527,530,532,533,534,536,538,540,542,543,549,550,551,554,556,557,558,560,561,563,567,569,570,571,572,573,574,575,576,577,578,580,581,584,585,586,587,589,591,592,593,594,596,597,599,602,604,606,607,608,610,611,613,614,620,626,627,628,629,630,631,633,634,635,636,637,638,639,641,642,643,644,645,675,711) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
      "100%|██████████| 29620/29620 [03:56<00:00, 125.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78044, 2)\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:6: DtypeWarning: Columns (15,51,52,53,58,62,65,67,68,70,71,72,74,75,77,79,80,83,84,85,87,89,90,93,94,97,98,99,102,103,104,106,111,112,113,115,116,119,121,123,124,125,127,128,131,134,135,138,140,142,143,147,148,149,152,154,158,159,160,163,167,168,169,173,174,175,177,178,181,182,183,184,185,187,188,191,192,195,198,202,203,204,208,209,212,213,214,218,219,223,232,234,238,243,254,257,264,266,267,270,278,279,280,281,282,286,291,292,293,298,299,304,306,312,322,328,329,330,331,333,334,335,342,347,350,352,353,358,359,367,368,372,373,385,387,389,391,396,397,404,405,406,407,409,413,414,415,417,419,420,422,424,426,428,430,432,440,442,444,446,448,451,455,456,457,458,459,460,461,462,463,464,465,469,470,471,472,475,476,479,480,481,482,486,488,489,490,492,495,496,498,499,501,503,504,505,506,508,509,510,511,512,513,516,519,520,521,522,523,525,526,527,530,532,533,534,535,536,538,540,543,545,550,556,560,567,571,572,573,574,575,577,578,581,589,597,604,607,608,613,626,627,628,629,630,631,634,635,637,638,640,641,642,643,644,645,675,711,713) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
      "100%|██████████| 19227/19227 [02:33<00:00, 125.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83184, 2)\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:6: DtypeWarning: Columns (51,53,65,67,147,163,168,169,178,182,185,195,219,243,266,291,322,335,350,406,440,459,476,483,503,504,510,571,578,597,640,641,642,643,675,711,713) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';')\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_30504\\96602400.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
      "100%|██████████| 713/713 [00:05<00:00, 121.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83415, 2)\n"
     ]
    }
   ],
   "source": [
    "post_train_folder = 'Data/post-train/'\n",
    "csv_files = [file for file in os.listdir(post_train_folder) if file.endswith('.csv')]\n",
    "for file_idx, file in enumerate(csv_files):\n",
    "    print(file_idx)\n",
    "    file_path = f'{post_train_folder}/{file}'\n",
    "    df = pd.read_csv(file_path, sep=';')\n",
    "    clean_df = df[(df['post_type']==\"'talk\")& #karena yg post\n",
    "                    (df['lang']==\"'in\")&\n",
    "                    (df['content_type']==\"'text\")\n",
    "                ]\n",
    "    clean_df['clean_tweet'] = clean_df['content'].apply(p.clean)\n",
    "    clean_df = clean_df.drop_duplicates(subset=['clean_tweet'])\n",
    "    clean_df = clean_df.reset_index(drop=True)\n",
    "    clean_df = clean_df['clean_tweet'].to_frame()\n",
    "    clean_dataset = Dataset.from_pandas(clean_df)\n",
    "    #prediction\n",
    "    classifier = pipeline(task='text-classification',\n",
    "                        tokenizer=tokenizer, \n",
    "                        model=model, device='cuda:0')\n",
    "    labels = []\n",
    "    for out in tqdm(classifier(KeyDataset(clean_dataset, \"clean_tweet\"))):\n",
    "        labels.append(out['label'])\n",
    "    clean_df['tweet_type'] = labels\n",
    "    clean_df = clean_df[clean_df['tweet_type']!=\"SPAM\"]\n",
    "    clean_df = clean_df.reset_index(drop=True)\n",
    "    #save to file\n",
    "    clean_file_path = f'{post_train_folder}/clean_tweet.csv'\n",
    "    #klo ada buat kita append\n",
    "    if os.path.isfile(clean_file_path):\n",
    "        text_df = pd.read_csv(clean_file_path)\n",
    "        text_df = pd.concat([text_df, clean_df])\n",
    "        print(text_df.shape)\n",
    "        text_df.to_csv(clean_file_path, index=False)\n",
    "    #kalau gk ada maka buat baru\n",
    "    else:\n",
    "        clean_df.to_csv(clean_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83415, 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(clean_file_path)\n",
    "test_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadruplet 4k data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danendra\\anaconda3\\envs\\tesis\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import BertForSequenceClassification\n",
    "import preprocessor as p\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_detail = [\n",
    "    'original_id',\n",
    "    'date_created',\n",
    "    'specific_type',\n",
    "    'post_type',\n",
    "    'object_name',\n",
    "    'content',\n",
    "    'final_sentiment',\n",
    "    'lang',\n",
    "    'content_type'\n",
    "] \n",
    "post_stats = [\n",
    "    'followers',\n",
    "    'share',\n",
    "    'like',\n",
    "    'comment',\n",
    "    'engagement',\n",
    "    'reach',\n",
    "    'impression',\n",
    "    'engagement_rate'\n",
    "]\n",
    "labels = [\n",
    "    'delivery',\n",
    "    'customerservice',\n",
    "    'website&apps',\n",
    "    'payment',\n",
    "    'price',\n",
    "    'produk'\n",
    "]\n",
    "used_col = post_detail+post_stats+labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_12632\\3437453336.py:3: DtypeWarning: Columns (52,58,65,68,70,71,72,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,130,131,132,133,134,135,136,137,138,139,140,141,142,143,145,147,148,149,150,151,152,153,154,155,156,157,158,159,160,162,163,164,167,168,169,170,171,172,173,174,175,177,178,179,180,181,182,183,184,185,187,188,191,192,194,195,196,197,198,199,200,201,202,203,204,206,207,208,209,210,212,213,214,216,217,218,219,220,221,223,224,225,229,232,233,234,237,238,239,243,244,245,247,248,251,252,254,256,257,261,262,263,264,266,267,268,270,271,273,274,275,277,278,279,280,282,284,286,287,289,291,292,293,295,296,298,299,301,303,304,305,306,307,308,309,310,311,312,313,315,321,322,327,328,329,330,331,333,334,338,342,345,347,350,351,352,353,355,357,358,359,365,366,367,368,369,371,372,373,375,376,377,379,380,381,382,383,385,386,387,388,389,391,392,393,395,396,397,398,399,400,401,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,428,429,430,432,433,434,436,438,441,442,443,444,446,447,448,449,451,452,454,455,456,457,458,459,460,461,462,463,464,465,466,467,469,470,471,472,473,474,476,477,478,479,480,481,482,485,486,488,489,490,492,494,495,496,498,499,501,502,503,504,506,508,509,510,511,513,514,516,517,519,520,521,522,525,526,527,530,532,535,536,538,540,542,543,545,549,550,553,554,555,556,557,558,559,560,561,565,566,567,569,570,572,573,574,576,577,578,580,581,585,591,593,594,596,597,598,599,600,604,605,606,607,608,610,621,626,627,628,629,631,634,635,638,639,641,644,645,706,709,710,713) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Data/post-train/MLM/Ecommerce_Indonesia_01-Dec-2022_31-Dec-2022_TIJA1y16tr_0.csv\", sep=';')\n"
     ]
    }
   ],
   "source": [
    "#df1 = pd.read_csv('data/Ecommerce_Indonesia_20-Mar-2023_20-Apr-2023_GB4eugwhcl/Ecommerce_Indonesia_20-Mar-2023_20-Apr-2023_GB4eugwhcl_0.csv', sep=';')\n",
    "#df2 = pd.read_csv('data/quadruplet/Ecommerce_Indonesia_20-Mar-2023_20-Apr-2023_GB4eugwhcl/Ecommerce_Indonesia_20-Mar-2023_20-Apr-2023_GB4eugwhcl_1.csv', sep=';')\n",
    "df = pd.read_csv(\"Data/post-train/MLM/Ecommerce_Indonesia_01-Dec-2022_31-Dec-2022_TIJA1y16tr_0.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[used_col]\n",
    "clean_df = df[(df['post_type']==\"'talk\")& #karena yg post\n",
    "                    (df['lang']==\"'in\")&\n",
    "                    (df['content_type']==\"'text\")\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('indolem/indobert-base-uncased')\n",
    "id2label = {0: \"SPAM\", 1: \"OBJECTIVE\", 2:\"SUBJECTIVE\"}\n",
    "label2id = {\"SPAM\": 0, \"OBJECTIVE\": 1, \"SUBJECTIVE\":2}\n",
    "model = BertForSequenceClassification.from_pretrained('D:/Kuliah/S2/Tesis/Code/spam_detection/test-trainer/checkpoint-1770'\n",
    "                                                      , num_labels=3, id2label=id2label, label2id=label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(examples):\n",
    "    clean_tweets = [p.clean(text) for text in examples['content']]\n",
    "    examples['clean_tweet'] = clean_tweets\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(clean_df)\n",
    "clean_dataset = dataset.map(clean_data, batched=True, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(task='text-classification',\n",
    "                      tokenizer=tokenizer, \n",
    "                      model=model, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78447/78447 [09:58<00:00, 131.16it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for out in tqdm(classifier(KeyDataset(clean_dataset, \"clean_tweet\"))):\n",
    "    labels.append(out['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_12632\\872735425.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['tweet_type'] = labels\n",
      "C:\\Users\\danendra\\AppData\\Local\\Temp\\ipykernel_12632\\872735425.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_tweet'] = clean_dataset['clean_tweet']\n"
     ]
    }
   ],
   "source": [
    "clean_df['tweet_type'] = labels\n",
    "clean_df['clean_tweet'] = clean_dataset['clean_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.drop_duplicates(subset=['clean_tweet'])\n",
    "clean_df = clean_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26690/26690 [00:01<00:00, 14064.03it/s]\n"
     ]
    }
   ],
   "source": [
    "#nyatuin label\n",
    "aspect_categories = [\n",
    "    'delivery',\n",
    "    'customerservice',\n",
    "    'website&apps',\n",
    "    'payment',\n",
    "    'price',\n",
    "    'produk'\n",
    "]\n",
    "clean_df['baseline_aspect_category'] = ''\n",
    "for i in tqdm(range(len(clean_df))):\n",
    "    category_concat = ''\n",
    "    row = clean_df.iloc[i]\n",
    "    for cat in aspect_categories:\n",
    "        if type(row[cat])==str:\n",
    "            category_concat+=f'{cat}; '\n",
    "    clean_df.at[i, 'baseline_aspect_category'] = category_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_df[['original_id', 'content', 'final_sentiment', 'baseline_aspect_category', 'tweet_type', 'clean_tweet']].to_csv('Data/Ecommerce_01-Dec-2022_31-Dec-2022_spam_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_only = clean_df[clean_df['tweet_type']=='SUBJECTIVE']\n",
    "sentiment_only = sentiment_only.drop_duplicates(subset=['clean_tweet'])\n",
    "sentiment_only = sentiment_only.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5172/5172 [00:00<00:00, 13925.85it/s]\n"
     ]
    }
   ],
   "source": [
    "#nyatuin label\n",
    "aspect_categories = [\n",
    "    'delivery',\n",
    "    'customerservice',\n",
    "    'website&apps',\n",
    "    'payment',\n",
    "    'price',\n",
    "    'produk'\n",
    "]\n",
    "sentiment_only['baseline_aspect_category'] = ''\n",
    "for i in tqdm(range(len(sentiment_only))):\n",
    "    category_concat = ''\n",
    "    row = sentiment_only.iloc[i]\n",
    "    for cat in aspect_categories:\n",
    "        if type(row[cat])==str:\n",
    "            category_concat+=f'{cat}; '\n",
    "    sentiment_only.at[i, 'baseline_aspect_category'] = category_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_id</th>\n",
       "      <th>date_created</th>\n",
       "      <th>specific_type</th>\n",
       "      <th>post_type</th>\n",
       "      <th>object_name</th>\n",
       "      <th>content</th>\n",
       "      <th>final_sentiment</th>\n",
       "      <th>lang</th>\n",
       "      <th>content_type</th>\n",
       "      <th>followers</th>\n",
       "      <th>...</th>\n",
       "      <th>engagement_rate</th>\n",
       "      <th>delivery</th>\n",
       "      <th>customerservice</th>\n",
       "      <th>website&amp;apps</th>\n",
       "      <th>payment</th>\n",
       "      <th>price</th>\n",
       "      <th>produk</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>baseline_aspect_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'1609093028043710464</td>\n",
       "      <td>31/12/2022 14.44</td>\n",
       "      <td>'status</td>\n",
       "      <td>'talk</td>\n",
       "      <td>'olx</td>\n",
       "      <td>'@worksfess Coba olx nder</td>\n",
       "      <td>'neutral</td>\n",
       "      <td>'in</td>\n",
       "      <td>'text</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>' Coba olx nder</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'1609024284567166978</td>\n",
       "      <td>31/12/2022 10.10</td>\n",
       "      <td>'status</td>\n",
       "      <td>'talk</td>\n",
       "      <td>'olx</td>\n",
       "      <td>'Iki olx keneng opo kok eror ki.  Mata pencaha...</td>\n",
       "      <td>'negative</td>\n",
       "      <td>'in</td>\n",
       "      <td>'text</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>'Iki olx keneng opo kok eror ki. Mata pencahar...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'1608428182386135041</td>\n",
       "      <td>29/12/2022 18.42</td>\n",
       "      <td>'status</td>\n",
       "      <td>'talk</td>\n",
       "      <td>'olx</td>\n",
       "      <td>'@winrte Kok bisa sih kamu punya?! Aku mau sat...</td>\n",
       "      <td>'negative</td>\n",
       "      <td>'in</td>\n",
       "      <td>'text</td>\n",
       "      <td>510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>' Kok bisa sih kamu punya?! Aku mau satu juga ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'1608394553438142465</td>\n",
       "      <td>29/12/2022 16.28</td>\n",
       "      <td>'status</td>\n",
       "      <td>'talk</td>\n",
       "      <td>'olx</td>\n",
       "      <td>'@kegblgnunfaedh Pacar kayak gitu dijual aja d...</td>\n",
       "      <td>'negative</td>\n",
       "      <td>'in</td>\n",
       "      <td>'text</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>' Pacar kayak gitu dijual aja di OLX, gaakan l...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'1608393834664427520</td>\n",
       "      <td>29/12/2022 16.25</td>\n",
       "      <td>'status</td>\n",
       "      <td>'talk</td>\n",
       "      <td>'olx</td>\n",
       "      <td>'kalo gua lagi gedeg bgt kerja disini, gua sel...</td>\n",
       "      <td>'neutral</td>\n",
       "      <td>'in</td>\n",
       "      <td>'text</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>'kalo gua lagi gedeg bgt kerja disini, gua sel...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>'1606590558595878913</td>\n",
       "      <td>24/12/2022 17.00</td>\n",
       "      <td>'status</td>\n",
       "      <td>'talk</td>\n",
       "      <td>'shopee</td>\n",
       "      <td>'Apesi shopee halaman bermasalah mulu kesel gue</td>\n",
       "      <td>'neutral</td>\n",
       "      <td>'in</td>\n",
       "      <td>'text</td>\n",
       "      <td>1118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>'Apesi shopee halaman bermasalah mulu kesel gue</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>'1606590472562315264</td>\n",
       "      <td>24/12/2022 16.59</td>\n",
       "      <td>'status</td>\n",
       "      <td>'talk</td>\n",
       "      <td>'shopee</td>\n",
       "      <td>'@Askrlfess Ga pernah hhh ngomong sama aku pal...</td>\n",
       "      <td>'negative</td>\n",
       "      <td>'in</td>\n",
       "      <td>'text</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>'Delivery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>' Ga pernah hhh ngomong sama aku paling cuma n...</td>\n",
       "      <td>delivery;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>'1608489841892954114</td>\n",
       "      <td>29/12/2022 22.47</td>\n",
       "      <td>'status</td>\n",
       "      <td>'talk</td>\n",
       "      <td>'blibli</td>\n",
       "      <td>'@bliblidotcom Kwetiau ngliat aja udah eneg</td>\n",
       "      <td>'neutral</td>\n",
       "      <td>'in</td>\n",
       "      <td>'text</td>\n",
       "      <td>644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>' Kwetiau ngliat aja udah eneg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>'1608488137587830784</td>\n",
       "      <td>29/12/2022 22.40</td>\n",
       "      <td>'status</td>\n",
       "      <td>'talk</td>\n",
       "      <td>'blibli</td>\n",
       "      <td>'@bliblidotcom ES POTONG AJDIQBDJQJQ</td>\n",
       "      <td>'neutral</td>\n",
       "      <td>'in</td>\n",
       "      <td>'text</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>' ES POTONG AJDIQBDJQJQ</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5171</th>\n",
       "      <td>'1608486603974148098</td>\n",
       "      <td>29/12/2022 22.34</td>\n",
       "      <td>'status</td>\n",
       "      <td>'talk</td>\n",
       "      <td>'blibli</td>\n",
       "      <td>'Eh gua deg2an bgt ngambil objek blibli smoga ...</td>\n",
       "      <td>'neutral</td>\n",
       "      <td>'in</td>\n",
       "      <td>'text</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>'Eh gua deg2an bgt ngambil objek blibli smoga ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5172 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               original_id      date_created specific_type post_type  \\\n",
       "0     '1609093028043710464  31/12/2022 14.44       'status     'talk   \n",
       "1     '1609024284567166978  31/12/2022 10.10       'status     'talk   \n",
       "2     '1608428182386135041  29/12/2022 18.42       'status     'talk   \n",
       "3     '1608394553438142465  29/12/2022 16.28       'status     'talk   \n",
       "4     '1608393834664427520  29/12/2022 16.25       'status     'talk   \n",
       "...                    ...               ...           ...       ...   \n",
       "5167  '1606590558595878913  24/12/2022 17.00       'status     'talk   \n",
       "5168  '1606590472562315264  24/12/2022 16.59       'status     'talk   \n",
       "5169  '1608489841892954114  29/12/2022 22.47       'status     'talk   \n",
       "5170  '1608488137587830784  29/12/2022 22.40       'status     'talk   \n",
       "5171  '1608486603974148098  29/12/2022 22.34       'status     'talk   \n",
       "\n",
       "     object_name                                            content  \\\n",
       "0           'olx                          '@worksfess Coba olx nder   \n",
       "1           'olx  'Iki olx keneng opo kok eror ki.  Mata pencaha...   \n",
       "2           'olx  '@winrte Kok bisa sih kamu punya?! Aku mau sat...   \n",
       "3           'olx  '@kegblgnunfaedh Pacar kayak gitu dijual aja d...   \n",
       "4           'olx  'kalo gua lagi gedeg bgt kerja disini, gua sel...   \n",
       "...          ...                                                ...   \n",
       "5167     'shopee    'Apesi shopee halaman bermasalah mulu kesel gue   \n",
       "5168     'shopee  '@Askrlfess Ga pernah hhh ngomong sama aku pal...   \n",
       "5169     'blibli        '@bliblidotcom Kwetiau ngliat aja udah eneg   \n",
       "5170     'blibli               '@bliblidotcom ES POTONG AJDIQBDJQJQ   \n",
       "5171     'blibli  'Eh gua deg2an bgt ngambil objek blibli smoga ...   \n",
       "\n",
       "     final_sentiment lang content_type  followers  ...  engagement_rate  \\\n",
       "0           'neutral  'in        'text         94  ...              0.0   \n",
       "1          'negative  'in        'text          2  ...              0.0   \n",
       "2          'negative  'in        'text        510  ...              0.0   \n",
       "3          'negative  'in        'text          3  ...              0.0   \n",
       "4           'neutral  'in        'text          2  ...              0.0   \n",
       "...              ...  ...          ...        ...  ...              ...   \n",
       "5167        'neutral  'in        'text       1118  ...              0.0   \n",
       "5168       'negative  'in        'text         71  ...              0.0   \n",
       "5169        'neutral  'in        'text        644  ...              0.0   \n",
       "5170        'neutral  'in        'text          2  ...              0.0   \n",
       "5171        'neutral  'in        'text         51  ...              0.0   \n",
       "\n",
       "       delivery  customerservice  website&apps  payment  price  produk  \\\n",
       "0           NaN              NaN           NaN      NaN    NaN     NaN   \n",
       "1           NaN              NaN           NaN      NaN    NaN     NaN   \n",
       "2           NaN              NaN           NaN      NaN    NaN     NaN   \n",
       "3           NaN              NaN           NaN      NaN    NaN     NaN   \n",
       "4           NaN              NaN           NaN      NaN    NaN     NaN   \n",
       "...         ...              ...           ...      ...    ...     ...   \n",
       "5167        NaN              NaN           NaN      NaN    NaN     NaN   \n",
       "5168  'Delivery              NaN           NaN      NaN    NaN     NaN   \n",
       "5169        NaN              NaN           NaN      NaN    NaN     NaN   \n",
       "5170        NaN              NaN           NaN      NaN    NaN     NaN   \n",
       "5171        NaN              NaN           NaN      NaN    NaN     NaN   \n",
       "\n",
       "      tweet_type                                        clean_tweet  \\\n",
       "0     SUBJECTIVE                                    ' Coba olx nder   \n",
       "1     SUBJECTIVE  'Iki olx keneng opo kok eror ki. Mata pencahar...   \n",
       "2     SUBJECTIVE  ' Kok bisa sih kamu punya?! Aku mau satu juga ...   \n",
       "3     SUBJECTIVE  ' Pacar kayak gitu dijual aja di OLX, gaakan l...   \n",
       "4     SUBJECTIVE  'kalo gua lagi gedeg bgt kerja disini, gua sel...   \n",
       "...          ...                                                ...   \n",
       "5167  SUBJECTIVE    'Apesi shopee halaman bermasalah mulu kesel gue   \n",
       "5168  SUBJECTIVE  ' Ga pernah hhh ngomong sama aku paling cuma n...   \n",
       "5169  SUBJECTIVE                     ' Kwetiau ngliat aja udah eneg   \n",
       "5170  SUBJECTIVE                            ' ES POTONG AJDIQBDJQJQ   \n",
       "5171  SUBJECTIVE  'Eh gua deg2an bgt ngambil objek blibli smoga ...   \n",
       "\n",
       "     baseline_aspect_category  \n",
       "0                              \n",
       "1                              \n",
       "2                              \n",
       "3                              \n",
       "4                              \n",
       "...                       ...  \n",
       "5167                           \n",
       "5168               delivery;   \n",
       "5169                           \n",
       "5170                           \n",
       "5171                           \n",
       "\n",
       "[5172 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_only[['original_id', 'content', 'final_sentiment', 'baseline_aspect_category', 'tweet_type', 'clean_tweet']].to_csv('Data/Ecommerce_01-Dec-2022_31-Dec-2022_sentiment_only_2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadruplet Zili anotation\n",
    "yang dianotasi zili "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from experiments.src.utils import extract_quadruplet\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1000 = 'Data/quadruplet/quadruplet_annottated_sample_dataset.csv'\n",
    "data_2000 = 'Data/quadruplet/quadruplet_2200_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_2000)\n",
    "clean_df = df.dropna(subset=['quadruplet'])\n",
    "clean_df = clean_df.drop(columns=['Total', 'original_id'])\n",
    "clean_df['quadruplet'] = clean_df['quadruplet'].apply(lambda x:x[:-1] if x[-1]==';' else x)\n",
    "clean_df = clean_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2337, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_quad = []\n",
    "for i in range(len(clean_df)):\n",
    "    extractions = extract_quadruplet(clean_df.iloc[i]['quadruplet'])\n",
    "    for quad in extractions:\n",
    "        if \"\" in quad:\n",
    "            error_quad.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.drop(index=error_quad).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2313, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet(quadruplets):\n",
    "    triplets = []\n",
    "    for quad in quadruplets:\n",
    "        aspect_term, opinion_term, sentiment, aspect_categories = quad\n",
    "        triplets.append((aspect_term, opinion_term, sentiment))\n",
    "    triplet_str = ''\n",
    "    for i, triplet in enumerate(triplets):\n",
    "        triplet_str+=str(triplet)\n",
    "        if i<len(triplets)-1:\n",
    "            triplet_str+=';'\n",
    "    return triplet_str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_triplets = []\n",
    "errors_idx = []\n",
    "for i in range(len(clean_df)):\n",
    "    row = clean_df.iloc[i]\n",
    "    quadruplets = extract_quadruplet(row['quadruplet'])\n",
    "    triplets = get_triplet(quadruplets)\n",
    "    if triplets!='':\n",
    "        all_triplets.append(triplets)\n",
    "    else:\n",
    "        errors_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.drop(index=errors_idx).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2298, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['triplet_label'] = all_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quadruplet</th>\n",
       "      <th>triplet_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(hp, harga terlalu tinggi, negative, produk)</td>\n",
       "      <td>(hp, harga terlalu tinggi, negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(motor bekas, pertama kali, positive, produk)</td>\n",
       "      <td>(motor bekas, pertama kali, positive)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(beli second, biar lebih aman, negative, produ...</td>\n",
       "      <td>(beli second, biar lebih aman, negative);(olx,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(nasi goreng, enak, positive, produk)</td>\n",
       "      <td>(nasi goreng, enak, positive)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(olx, reseller, negative, customerservice)</td>\n",
       "      <td>(olx, reseller, negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(olx, ditawar gila kali, negative, produk)</td>\n",
       "      <td>(olx, ditawar gila kali, negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(olx, ada manusiawinya, positive, produk); (fb...</td>\n",
       "      <td>(olx, ada manusiawinya, positive);(fb, kebanya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(kostan, kafe dsana banyak, positive, produk);...</td>\n",
       "      <td>(kostan, kafe dsana banyak, positive);(google ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(seller kandang kucing, nyebelin, negative, pr...</td>\n",
       "      <td>(seller kandang kucing, nyebelin, negative);(o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(jual hp, harga murah, positive, produk); (cpt...</td>\n",
       "      <td>(jual hp, harga murah, positive);(cpt banget l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          quadruplet  \\\n",
       "0       (hp, harga terlalu tinggi, negative, produk)   \n",
       "1      (motor bekas, pertama kali, positive, produk)   \n",
       "2  (beli second, biar lebih aman, negative, produ...   \n",
       "3              (nasi goreng, enak, positive, produk)   \n",
       "4         (olx, reseller, negative, customerservice)   \n",
       "5         (olx, ditawar gila kali, negative, produk)   \n",
       "6  (olx, ada manusiawinya, positive, produk); (fb...   \n",
       "7  (kostan, kafe dsana banyak, positive, produk);...   \n",
       "8  (seller kandang kucing, nyebelin, negative, pr...   \n",
       "9  (jual hp, harga murah, positive, produk); (cpt...   \n",
       "\n",
       "                                       triplet_label  \n",
       "0               (hp, harga terlalu tinggi, negative)  \n",
       "1              (motor bekas, pertama kali, positive)  \n",
       "2  (beli second, biar lebih aman, negative);(olx,...  \n",
       "3                      (nasi goreng, enak, positive)  \n",
       "4                          (olx, reseller, negative)  \n",
       "5                 (olx, ditawar gila kali, negative)  \n",
       "6  (olx, ada manusiawinya, positive);(fb, kebanya...  \n",
       "7  (kostan, kafe dsana banyak, positive);(google ...  \n",
       "8  (seller kandang kucing, nyebelin, negative);(o...  \n",
       "9  (jual hp, harga murah, positive);(cpt banget l...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[['quadruplet', 'triplet_label']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('Data/quadruplet/quadruplet_2200-data_annottated_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>final_sentiment</th>\n",
       "      <th>baseline_aspect_category</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>quadruplet</th>\n",
       "      <th>triplet_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@JUALAN_BASE @fleurlovincs Nder hpnya kamu pak...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>delivery; produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>Nder hpnya kamu pake brp lama? Kayaknya jt ms...</td>\n",
       "      <td>(hp, harga terlalu tinggi, negative, produk)</td>\n",
       "      <td>(hp, harga terlalu tinggi, negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@teh_manis__ @ezash coba cari di olx mba kalo ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>coba cari di olx mba kalo baru pertama kali m...</td>\n",
       "      <td>(motor bekas, pertama kali, positive, produk)</td>\n",
       "      <td>(motor bekas, pertama kali, positive)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@tanyakanrl Kalo mau beli second jangan di tok...</td>\n",
       "      <td>positive</td>\n",
       "      <td>delivery; produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>Kalo mau beli second jangan di toko oren atau...</td>\n",
       "      <td>(beli second, biar lebih aman, negative, produ...</td>\n",
       "      <td>(beli second, biar lebih aman, negative);(olx,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kalo jam 1 malem gabisa tidur pengen makan nas...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>customerservice; produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>kalo jam malem gabisa tidur pengen makan nasi ...</td>\n",
       "      <td>(nasi goreng, enak, positive, produk)</td>\n",
       "      <td>(nasi goreng, enak, positive)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@tirta_cipeng Di luar dunia fashion, saya seri...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>Di luar dunia fashion, saya sering banget nem...</td>\n",
       "      <td>(olx, reseller, negative, customerservice)</td>\n",
       "      <td>(olx, reseller, negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>@indomilkyourway @alfamart @alfamidi_ku @Indom...</td>\n",
       "      <td>positive</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>PINK BLOSSOM ENAK BGTIIII</td>\n",
       "      <td>(pink blossom, enak bgt, positive, produk)</td>\n",
       "      <td>(pink blossom, enak bgt, positive)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>shopee gw doang apa emang lagi error sih. tiap...</td>\n",
       "      <td>negative</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>shopee gw doang apa emang lagi error sih. tiap...</td>\n",
       "      <td>(shopee, lagi error, negative, website&amp;apps)</td>\n",
       "      <td>(shopee, lagi error, negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>@indomilkyourway @alfamart @alfamidi_ku @Indom...</td>\n",
       "      <td>positive</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>Yang black latte enak banget sumpilll, plis j...</td>\n",
       "      <td>(black latte, enak banget sumpilll, positive, ...</td>\n",
       "      <td>(black latte, enak banget sumpilll, positive)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>@sbtcon Di deskripsi link Shopee sllu tulis ka...</td>\n",
       "      <td>negative</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>Di deskripsi link Shopee sllu tulis kalo rusa...</td>\n",
       "      <td>(packing, diluar tanggung jawab seller, negati...</td>\n",
       "      <td>(packing, diluar tanggung jawab seller, negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>@modaraimusu @myXLCare Ga cuma lu doang nder, ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>Ga cuma lu doang nder, gue juga gitu. Dulu sb...</td>\n",
       "      <td>(XL, padahal csnya enak, positive, costumerser...</td>\n",
       "      <td>(xl, padahal csnya enak, positive)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2298 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content final_sentiment  \\\n",
       "0     @JUALAN_BASE @fleurlovincs Nder hpnya kamu pak...         neutral   \n",
       "1     @teh_manis__ @ezash coba cari di olx mba kalo ...         neutral   \n",
       "2     @tanyakanrl Kalo mau beli second jangan di tok...        positive   \n",
       "3     kalo jam 1 malem gabisa tidur pengen makan nas...         neutral   \n",
       "4     @tirta_cipeng Di luar dunia fashion, saya seri...         neutral   \n",
       "...                                                 ...             ...   \n",
       "2293  @indomilkyourway @alfamart @alfamidi_ku @Indom...        positive   \n",
       "2294  shopee gw doang apa emang lagi error sih. tiap...        negative   \n",
       "2295  @indomilkyourway @alfamart @alfamidi_ku @Indom...        positive   \n",
       "2296  @sbtcon Di deskripsi link Shopee sllu tulis ka...        negative   \n",
       "2297  @modaraimusu @myXLCare Ga cuma lu doang nder, ...        negative   \n",
       "\n",
       "      baseline_aspect_category  tweet_type  \\\n",
       "0            delivery; produk;  SUBJECTIVE   \n",
       "1                      produk;  SUBJECTIVE   \n",
       "2            delivery; produk;  SUBJECTIVE   \n",
       "3     customerservice; produk;  SUBJECTIVE   \n",
       "4                      produk;  SUBJECTIVE   \n",
       "...                        ...         ...   \n",
       "2293                   produk;  SUBJECTIVE   \n",
       "2294                   produk;  SUBJECTIVE   \n",
       "2295                   produk;  SUBJECTIVE   \n",
       "2296                   produk;  SUBJECTIVE   \n",
       "2297                   produk;  SUBJECTIVE   \n",
       "\n",
       "                                            clean_tweet  \\\n",
       "0      Nder hpnya kamu pake brp lama? Kayaknya jt ms...   \n",
       "1      coba cari di olx mba kalo baru pertama kali m...   \n",
       "2      Kalo mau beli second jangan di toko oren atau...   \n",
       "3     kalo jam malem gabisa tidur pengen makan nasi ...   \n",
       "4      Di luar dunia fashion, saya sering banget nem...   \n",
       "...                                                 ...   \n",
       "2293                          PINK BLOSSOM ENAK BGTIIII   \n",
       "2294  shopee gw doang apa emang lagi error sih. tiap...   \n",
       "2295   Yang black latte enak banget sumpilll, plis j...   \n",
       "2296   Di deskripsi link Shopee sllu tulis kalo rusa...   \n",
       "2297   Ga cuma lu doang nder, gue juga gitu. Dulu sb...   \n",
       "\n",
       "                                             quadruplet  \\\n",
       "0          (hp, harga terlalu tinggi, negative, produk)   \n",
       "1         (motor bekas, pertama kali, positive, produk)   \n",
       "2     (beli second, biar lebih aman, negative, produ...   \n",
       "3                 (nasi goreng, enak, positive, produk)   \n",
       "4            (olx, reseller, negative, customerservice)   \n",
       "...                                                 ...   \n",
       "2293         (pink blossom, enak bgt, positive, produk)   \n",
       "2294       (shopee, lagi error, negative, website&apps)   \n",
       "2295  (black latte, enak banget sumpilll, positive, ...   \n",
       "2296  (packing, diluar tanggung jawab seller, negati...   \n",
       "2297  (XL, padahal csnya enak, positive, costumerser...   \n",
       "\n",
       "                                          triplet_label  \n",
       "0                  (hp, harga terlalu tinggi, negative)  \n",
       "1                 (motor bekas, pertama kali, positive)  \n",
       "2     (beli second, biar lebih aman, negative);(olx,...  \n",
       "3                         (nasi goreng, enak, positive)  \n",
       "4                             (olx, reseller, negative)  \n",
       "...                                                 ...  \n",
       "2293                 (pink blossom, enak bgt, positive)  \n",
       "2294                     (shopee, lagi error, negative)  \n",
       "2295      (black latte, enak banget sumpilll, positive)  \n",
       "2296  (packing, diluar tanggung jawab seller, negative)  \n",
       "2297                 (xl, padahal csnya enak, positive)  \n",
       "\n",
       "[2298 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1k Data quadruplet relabeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import preprocessor as p\n",
    "from experiments.src.postprocessor import PostProcessor\n",
    "from experiments.src.utils import extract_quintuplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/quintuplet/quintuple_data_clean.csv')\n",
    "df = df.dropna(subset=['content'])\n",
    "df['clean_tweet'] = df['content'].apply(p.clean)\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2013 entries, 0 to 2012\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   aoriginal_id              2013 non-null   int64 \n",
      " 1   content                   2013 non-null   object\n",
      " 2   final_sentiment           2013 non-null   object\n",
      " 3   baseline_aspect_category  1985 non-null   object\n",
      " 4   tweet_type                2013 non-null   object\n",
      " 5   clean_tweet               2013 non-null   object\n",
      " 6   label                     2003 non-null   object\n",
      " 7   Unnamed: 7                182 non-null    object\n",
      " 8   Unnamed: 8                53 non-null     object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 141.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bersih2 aspect category dan sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_quad = []\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    quintuplets = extract_quintuplet(row['label'])\n",
    "    for quintuplet in quintuplets:\n",
    "        entity, aspect_term, opinion_term, sentiment, aspect_category = quintuplet\n",
    "        if entity=='' or aspect_term=='' or opinion_term=='' or sentiment=='' or aspect_category=='':\n",
    "            print(i, quintuplet)\n",
    "            errors_quad.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessor = PostProcessor(use_postprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['postprocess_quintuplet']=''\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    orig_sentence = row['clean_tweet']\n",
    "    clean_quintuplets = []\n",
    "    quintuplets = extract_quintuplet(row['label'])\n",
    "    for quintuplet in quintuplets:\n",
    "        entity, aspect_term, opinion_term, sentiment, aspect_category = quintuplet\n",
    "        entity, aspect_term, opinion_term, sentiment, aspect_category = postprocessor.post_process(entity, aspect_term, opinion_term, sentiment, aspect_category, orig_sentence)\n",
    "        aspect_term = aspect_term.replace(',','')\n",
    "        opinion_term = opinion_term.replace(',','')\n",
    "        clean_quintuplets.append(f'({entity},{aspect_term},{opinion_term},{sentiment},{aspect_category})')\n",
    "    df.at[i, 'postprocess_quintuplet'] = ';'.join(clean_quintuplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_quad = []\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    quintuplets = extract_quintuplet(row['postprocess_quintuplet'])\n",
    "    for quintuplet in quintuplets:\n",
    "        entity, aspect_term, opinion_term, sentiment, aspect_category = quintuplet\n",
    "        if entity=='' or aspect_term=='' or opinion_term=='' or sentiment=='' or aspect_category=='':\n",
    "            print(i, quintuplet)\n",
    "            errors_quad.append(i)\n",
    "errors_quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   aoriginal_id              100 non-null    int64 \n",
      " 1   content                   100 non-null    object\n",
      " 2   final_sentiment           100 non-null    object\n",
      " 3   baseline_aspect_category  100 non-null    object\n",
      " 4   tweet_type                100 non-null    object\n",
      " 5   clean_tweet               100 non-null    object\n",
      " 6   label                     100 non-null    object\n",
      " 7   Unnamed: 7                1 non-null      object\n",
      " 8   postprocess_quintuplet    100 non-null    object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 7.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aoriginal_id</th>\n",
       "      <th>content</th>\n",
       "      <th>final_sentiment</th>\n",
       "      <th>baseline_aspect_category</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>postprocess_quintuplet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1648753333681917954</td>\n",
       "      <td>@JUALAN_BASE @fleurlovincs Nder hpnya kamu pak...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>delivery; produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>nder hpnya kamu pake brp lama? kayaknya jt msh...</td>\n",
       "      <td>(olx, _, banyak yg jual dibawah 4jt, positive,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(olx,_,banyak yg jual dibawah jt,positive,price)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1647741896079589377</td>\n",
       "      <td>@tanyakanrl Kalo mau beli second jangan di tok...</td>\n",
       "      <td>positive</td>\n",
       "      <td>delivery; produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>kalo mau beli second jangan di toko oren atau ...</td>\n",
       "      <td>(olx, _, lebih aman, positive, website&amp;apps);(...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(olx,_,lebih aman,positive,website&amp;apps);(fb,m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1647638497573085184</td>\n",
       "      <td>@tirta_cipeng Di luar dunia fashion, saya seri...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>di luar dunia fashion, saya sering banget nemu...</td>\n",
       "      <td>(olx, reseller, ga jujur, negative, other);(ol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(olx,reseller,ga jujur,negative,price);(olx,ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          aoriginal_id                                            content  \\\n",
       "0  1648753333681917954  @JUALAN_BASE @fleurlovincs Nder hpnya kamu pak...   \n",
       "1  1647741896079589377  @tanyakanrl Kalo mau beli second jangan di tok...   \n",
       "2  1647638497573085184  @tirta_cipeng Di luar dunia fashion, saya seri...   \n",
       "\n",
       "  final_sentiment baseline_aspect_category  tweet_type  \\\n",
       "0         neutral        delivery; produk;  SUBJECTIVE   \n",
       "1        positive        delivery; produk;  SUBJECTIVE   \n",
       "2         neutral                  produk;  SUBJECTIVE   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  nder hpnya kamu pake brp lama? kayaknya jt msh...   \n",
       "1  kalo mau beli second jangan di toko oren atau ...   \n",
       "2  di luar dunia fashion, saya sering banget nemu...   \n",
       "\n",
       "                                               label Unnamed: 7  \\\n",
       "0  (olx, _, banyak yg jual dibawah 4jt, positive,...        NaN   \n",
       "1  (olx, _, lebih aman, positive, website&apps);(...        NaN   \n",
       "2  (olx, reseller, ga jujur, negative, other);(ol...        NaN   \n",
       "\n",
       "                              postprocess_quintuplet  \n",
       "0   (olx,_,banyak yg jual dibawah jt,positive,price)  \n",
       "1  (olx,_,lebih aman,positive,website&apps);(fb,m...  \n",
       "2  (olx,reseller,ga jujur,negative,price);(olx,ma...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Data/quadruplet/quintuplet_100_data_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   aoriginal_id              1000 non-null   float64\n",
      " 1   content                   1000 non-null   object \n",
      " 2   final_sentiment           1000 non-null   object \n",
      " 3   baseline_aspect_category  1000 non-null   object \n",
      " 4   tweet_type                1000 non-null   object \n",
      " 5   clean_tweet               1000 non-null   object \n",
      " 6   quadruplet                998 non-null    object \n",
      " 7   corrected_quadruplet      1000 non-null   object \n",
      " 8   review MLK                8 non-null      object \n",
      " 9   is_comparative            1000 non-null   bool   \n",
      " 10  postprocess_quad          1000 non-null   object \n",
      "dtypes: bool(1), float64(1), object(9)\n",
      "memory usage: 119.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aoriginal_id</th>\n",
       "      <th>content</th>\n",
       "      <th>final_sentiment</th>\n",
       "      <th>baseline_aspect_category</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>quadruplet</th>\n",
       "      <th>corrected_quadruplet</th>\n",
       "      <th>postprocess_quad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1.647931e+18</td>\n",
       "      <td>Selama ngurus barang retur. Dari semua platfor...</td>\n",
       "      <td>positive</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>selama ngurus barang retur. dari semua platfor...</td>\n",
       "      <td>(barang, cuman yang paling cepet dah, positive...</td>\n",
       "      <td>barang retur, yang paling cepet dah, positive,...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1.647237e+18</td>\n",
       "      <td>verifikasi qr nya shopee nyusahin banget</td>\n",
       "      <td>negative</td>\n",
       "      <td>produk;</td>\n",
       "      <td>SUBJECTIVE</td>\n",
       "      <td>verifikasi qr nya shopee nyusahin banget</td>\n",
       "      <td>verifikasi qr shopee, nyusahin banget, negativ...</td>\n",
       "      <td>verifikasi qr shopee, nyusahin banget, negativ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     aoriginal_id                                            content  \\\n",
       "403  1.647931e+18  Selama ngurus barang retur. Dari semua platfor...   \n",
       "703  1.647237e+18           verifikasi qr nya shopee nyusahin banget   \n",
       "\n",
       "    final_sentiment baseline_aspect_category  tweet_type  \\\n",
       "403        positive                  produk;  SUBJECTIVE   \n",
       "703        negative                  produk;  SUBJECTIVE   \n",
       "\n",
       "                                           clean_tweet  \\\n",
       "403  selama ngurus barang retur. dari semua platfor...   \n",
       "703           verifikasi qr nya shopee nyusahin banget   \n",
       "\n",
       "                                            quadruplet  \\\n",
       "403  (barang, cuman yang paling cepet dah, positive...   \n",
       "703  verifikasi qr shopee, nyusahin banget, negativ...   \n",
       "\n",
       "                                  corrected_quadruplet postprocess_quad  \n",
       "403  barang retur, yang paling cepet dah, positive,...                   \n",
       "703  verifikasi qr shopee, nyusahin banget, negativ...                   "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[403, 703]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quintuplet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from experiments.src.postprocessor import PostProcessor\n",
    "from experiments.src.utils import extract_quintuplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/quintuplet/quintuple_data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quintuplet_label'] = df.apply(lambda x: x.corrected_label if str(x.corrected_label)!='nan' else x.label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['quintuplet_label'])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessor = PostProcessor(use_postprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['postprocess_quintuplet']=''\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    orig_sentence = row['clean_tweet']\n",
    "    clean_quintuplets = []\n",
    "    quintuplets = extract_quintuplet(row['quintuplet_label'])\n",
    "    for quintuplet in quintuplets:\n",
    "        entity, aspect_term, opinion_term, sentiment, aspect_category = quintuplet\n",
    "        _, _, _, sentiment, aspect_category = postprocessor.post_process(entity, aspect_term, opinion_term, sentiment, aspect_category, orig_sentence)\n",
    "        clean_quintuplets.append(f'({entity},{aspect_term},{opinion_term},{sentiment},{aspect_category})')\n",
    "    df.at[i, 'postprocess_quintuplet'] = ';'.join(clean_quintuplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_quad = []\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    quintuplets = extract_quintuplet(row['postprocess_quintuplet'])\n",
    "    for quintuplet in quintuplets:\n",
    "        entity, aspect_term, opinion_term, sentiment, aspect_category = quintuplet\n",
    "        if entity=='' or aspect_term=='' or opinion_term=='' or sentiment=='' or aspect_category=='':\n",
    "            print(i, quintuplet)\n",
    "            errors_quad.append(i)\n",
    "errors_quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tokopedia min top up tapcash @BNICustomerCare lagi bermasalah ya? dari tadi pending gabisa update saldo\n",
      "(_ top up tapcash, pending gabisa update saldo, negative, website&apps)\n",
      "[('', '', '', '', '')]\n",
      "[('', '', '', 'neutral', 'price')]\n"
     ]
    }
   ],
   "source": [
    "i = 1643\n",
    "print(df.iloc[i]['content'])\n",
    "print(df.iloc[i]['quintuplet_label'])\n",
    "print(extract_quintuplet(df.iloc[i]['quintuplet_label']))\n",
    "print(extract_quintuplet(df.iloc[i]['postprocess_quintuplet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Data/quintuplet/quintuplet_postprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2001 entries, 0 to 2000\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   aoriginal_id              2001 non-null   int64 \n",
      " 1   content                   2001 non-null   object\n",
      " 2   final_sentiment           2001 non-null   object\n",
      " 3   baseline_aspect_category  1973 non-null   object\n",
      " 4   tweet_type                2001 non-null   object\n",
      " 5   clean_tweet               2001 non-null   object\n",
      " 6   label                     2001 non-null   object\n",
      " 7   corrected_label           182 non-null    object\n",
      " 8   keterangan                53 non-null     object\n",
      " 9   quintuplet_label          2001 non-null   object\n",
      " 10  postprocess_quintuplet    2001 non-null   object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 172.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "930.6"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9*len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv('Data/quintuplet/quintuplet_postprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.iloc[120]['postprocess_quintuplet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 120 argument of type 'float' is not iterable\n",
      "error 135 argument of type 'float' is not iterable\n",
      "error 146 argument of type 'float' is not iterable\n",
      "error 162 argument of type 'float' is not iterable\n",
      "error 174 argument of type 'float' is not iterable\n",
      "error 175 argument of type 'float' is not iterable\n",
      "error 183 argument of type 'float' is not iterable\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df2)):\n",
    "    try:\n",
    "        if 'costumerservice' in df2.iloc[i]['postprocess_quintuplet']:\n",
    "            print(i)\n",
    "    except Exception as e:\n",
    "        print('error', i, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aoriginal_id                                              1648075525968248832\n",
       "content                     @banjarbase Mahal😭 aku tim shopee krinkle soal...\n",
       "final_sentiment                                                      negative\n",
       "baseline_aspect_category                                              produk;\n",
       "tweet_type                                                         SUBJECTIVE\n",
       "clean_tweet                              Mahal aku tim shopee krinkle soalnya\n",
       "label                        (shopee, shopee krinkle, mahal, negative, price)\n",
       "corrected_label             kayanya ini gk usah dimasukin zil, gk jelas gi...\n",
       "keterangan                                                                NaN\n",
       "quintuplet_label            kayanya ini gk usah dimasukin zil, gk jelas gi...\n",
       "postprocess_quintuplet                                                    NaN\n",
       "Name: 120, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.iloc[120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "quintuplets = extract_quintuplet(df2.iloc[120]['quintuplet_label'])\n",
    "for quintuplet in quintuplets:\n",
    "    entity, aspect_term, opinion_term, sentiment, aspect_category = quintuplet\n",
    "    print(aspect_category)\n",
    "    _, _, _, sentiment, aspect_category = postprocessor.post_process(entity, aspect_term, opinion_term, sentiment, aspect_category, orig_sentence)\n",
    "    print(aspect_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4179a95aa5b49abc81a1f9774c9389b2d4eba524b70fc2f22d886502bea2eb9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

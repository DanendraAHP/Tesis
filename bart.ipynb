{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, TFBartForConditionalGeneration\n",
    "from transformers.models.bart.modeling_bart import shift_tokens_right\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Set up the T5 tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "model = TFBartForConditionalGeneration.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/Kuliah/S2/Tesis/Code/Generative-ABSA-main/data/quadruplet/rest15/all_data.csv')\n",
    "X = df['input'].values.tolist()\n",
    "y = df['quadruplet_label'].values.tolist()\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(x, y, pad_id):\n",
    "    input_encodings = dict(tokenizer(x, padding=True, truncation=True, return_tensors=\"pt\"))\n",
    "    target_encodings = dict(tokenizer(y, padding=True, truncation=True, return_tensors=\"pt\"))\n",
    "    labels = target_encodings['input_ids']\n",
    "    #decoder_start_token_id=0 biar <s> yang nandain start dari tokenisasi\n",
    "    decoder_input_ids = shift_tokens_right(labels, pad_id, 0)\n",
    "    labels = labels.masked_fill_(labels == pad_id, -100)\n",
    "    encodings = {\n",
    "        'input_ids': tf.convert_to_tensor(input_encodings['input_ids'].numpy()),\n",
    "        'attention_mask': tf.convert_to_tensor(input_encodings['attention_mask'].numpy()),\n",
    "        'decoder_input_ids': tf.convert_to_tensor(decoder_input_ids.numpy()),\n",
    "        'labels': tf.convert_to_tensor(labels.numpy()),\n",
    "    }\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_id = model.config.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = make_data(x_train, y_train, pad_id)\n",
    "test_encodings = make_data(x_test, y_test, pad_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(656, 56), dtype=int64, numpy=\n",
       " array([[    0,   133,  5765, ...,     1,     1,     1],\n",
       "        [    0,   133, 28287, ...,     1,     1,     1],\n",
       "        [    0,   133,  3202, ...,     1,     1,     1],\n",
       "        ...,\n",
       "        [    0,   133,   813, ...,     1,     1,     1],\n",
       "        [    0,  2387, 25537, ...,     1,     1,     1],\n",
       "        [    0, 24989,  3958, ...,     1,     1,     1]], dtype=int64)>,\n",
       " 'attention_mask': <tf.Tensor: shape=(656, 56), dtype=int64, numpy=\n",
       " array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]], dtype=int64)>,\n",
       " 'decoder_input_ids': <tf.Tensor: shape=(656, 77), dtype=int64, numpy=\n",
       " array([[   0,    0, 1640, ...,    1,    1,    1],\n",
       "        [   0,    0, 1640, ...,    1,    1,    1],\n",
       "        [   0,    0, 1640, ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [   0,    0, 1640, ...,    1,    1,    1],\n",
       "        [   0,    0, 1640, ...,    1,    1,    1],\n",
       "        [   0,    0, 1640, ...,    1,    1,    1]], dtype=int64)>,\n",
       " 'labels': <tf.Tensor: shape=(656, 77), dtype=int64, numpy=\n",
       " array([[    0,  1640, 45801, ...,  -100,  -100,  -100],\n",
       "        [    0,  1640,    29, ...,  -100,  -100,  -100],\n",
       "        [    0,  1640,  1090, ...,  -100,  -100,  -100],\n",
       "        ...,\n",
       "        [    0,  1640, 17360, ...,  -100,  -100,  -100],\n",
       "        [    0,  1640,  6406, ...,  -100,  -100,  -100],\n",
       "        [    0,  1640,   642, ...,  -100,  -100,  -100]], dtype=int64)>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'tf-bart-base-quadruplet'\n",
    "checkpoint_filepath = save_path + \"/\" + \"T5-{epoch:04d}.ckpt\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "callbacks = [model_checkpoint_callback] \n",
    "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "# Define the fine-tuning parameters\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "model.compile(optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.5777 - accuracy: 0.0428"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model.shared_layer_call_fn, model.shared_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn while saving (showing 5 of 414). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0001-0.4267.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0001-0.4267.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 132s 1s/step - loss: 1.5777 - accuracy: 0.0428 - val_loss: 0.4267 - val_accuracy: 0.0724\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4787 - accuracy: 0.0333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model.shared_layer_call_fn, model.shared_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn while saving (showing 5 of 414). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0002-0.3185.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0002-0.3185.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 112s 1s/step - loss: 0.4787 - accuracy: 0.0333 - val_loss: 0.3185 - val_accuracy: 0.0833\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3456 - accuracy: 0.0348"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model.shared_layer_call_fn, model.shared_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn while saving (showing 5 of 414). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0003-0.2978.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0003-0.2978.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 112s 1s/step - loss: 0.3456 - accuracy: 0.0348 - val_loss: 0.2978 - val_accuracy: 0.0726\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.0320"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model.shared_layer_call_fn, model.shared_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn while saving (showing 5 of 414). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0004-0.2746.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0004-0.2746.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 113s 1s/step - loss: 0.2579 - accuracy: 0.0320 - val_loss: 0.2746 - val_accuracy: 0.0749\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2193 - accuracy: 0.0308"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model.shared_layer_call_fn, model.shared_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn while saving (showing 5 of 414). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0005-0.2690.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0005-0.2690.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 108s 1s/step - loss: 0.2193 - accuracy: 0.0308 - val_loss: 0.2690 - val_accuracy: 0.0771\n",
      "Epoch 6/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.1731 - accuracy: 0.0371 - val_loss: 0.2719 - val_accuracy: 0.0748\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.1475 - accuracy: 0.0356"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model.shared_layer_call_fn, model.shared_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn while saving (showing 5 of 414). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0007-0.2626.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0007-0.2626.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 107s 1s/step - loss: 0.1475 - accuracy: 0.0356 - val_loss: 0.2626 - val_accuracy: 0.0727\n",
      "Epoch 8/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.0373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model.shared_layer_call_fn, model.shared_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn while saving (showing 5 of 414). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0008-0.2584.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0008-0.2584.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 104s 1s/step - loss: 0.1277 - accuracy: 0.0373 - val_loss: 0.2584 - val_accuracy: 0.0835\n",
      "Epoch 9/50\n",
      "82/82 [==============================] - 11s 125ms/step - loss: 0.1095 - accuracy: 0.0341 - val_loss: 0.2672 - val_accuracy: 0.0726\n",
      "Epoch 10/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0896 - accuracy: 0.0355 - val_loss: 0.2597 - val_accuracy: 0.0726\n",
      "Epoch 11/50\n",
      "82/82 [==============================] - 11s 129ms/step - loss: 0.0802 - accuracy: 0.0364 - val_loss: 0.2859 - val_accuracy: 0.0817\n",
      "Epoch 12/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.0333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model.shared_layer_call_fn, model.shared_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn while saving (showing 5 of 414). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0012-0.2538.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0012-0.2538.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 109s 1s/step - loss: 0.0885 - accuracy: 0.0333 - val_loss: 0.2538 - val_accuracy: 0.0774\n",
      "Epoch 13/50\n",
      "82/82 [==============================] - 11s 125ms/step - loss: 0.1015 - accuracy: 0.0375 - val_loss: 0.2749 - val_accuracy: 0.0725\n",
      "Epoch 14/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0707 - accuracy: 0.0358 - val_loss: 0.2834 - val_accuracy: 0.0725\n",
      "Epoch 15/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0764 - accuracy: 0.0375 - val_loss: 0.2733 - val_accuracy: 0.0725\n",
      "Epoch 16/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0471 - accuracy: 0.0357 - val_loss: 0.2817 - val_accuracy: 0.0725\n",
      "Epoch 17/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0504 - accuracy: 0.0331 - val_loss: 0.2975 - val_accuracy: 0.0876\n",
      "Epoch 18/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0621 - accuracy: 0.0353 - val_loss: 0.3188 - val_accuracy: 0.0725\n",
      "Epoch 19/50\n",
      "82/82 [==============================] - 10s 126ms/step - loss: 0.0504 - accuracy: 0.0310 - val_loss: 0.2839 - val_accuracy: 0.0725\n",
      "Epoch 20/50\n",
      "82/82 [==============================] - 10s 126ms/step - loss: 0.0389 - accuracy: 0.0315 - val_loss: 0.2984 - val_accuracy: 0.0725\n",
      "Epoch 21/50\n",
      "82/82 [==============================] - 10s 124ms/step - loss: 0.0451 - accuracy: 0.0339 - val_loss: 0.3007 - val_accuracy: 0.0728\n",
      "Epoch 22/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0279 - accuracy: 0.0346 - val_loss: 0.2991 - val_accuracy: 0.0727\n",
      "Epoch 23/50\n",
      "82/82 [==============================] - 10s 126ms/step - loss: 0.0285 - accuracy: 0.0366 - val_loss: 0.3085 - val_accuracy: 0.0728\n",
      "Epoch 24/50\n",
      "82/82 [==============================] - 10s 126ms/step - loss: 0.0221 - accuracy: 0.0368 - val_loss: 0.2998 - val_accuracy: 0.0727\n",
      "Epoch 25/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0229 - accuracy: 0.0347 - val_loss: 0.3380 - val_accuracy: 0.0727\n",
      "Epoch 26/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0182 - accuracy: 0.0351 - val_loss: 0.3152 - val_accuracy: 0.0726\n",
      "Epoch 27/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0163 - accuracy: 0.0348 - val_loss: 0.3215 - val_accuracy: 0.0890\n",
      "Epoch 28/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0157 - accuracy: 0.0392 - val_loss: 0.3477 - val_accuracy: 0.0727\n",
      "Epoch 29/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0193 - accuracy: 0.0347 - val_loss: 0.3510 - val_accuracy: 0.0726\n",
      "Epoch 30/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0171 - accuracy: 0.0345 - val_loss: 0.3511 - val_accuracy: 0.0750\n",
      "Epoch 31/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0151 - accuracy: 0.0340 - val_loss: 0.3139 - val_accuracy: 0.0728\n",
      "Epoch 32/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0147 - accuracy: 0.0333 - val_loss: 0.3425 - val_accuracy: 0.0727\n",
      "Epoch 33/50\n",
      "82/82 [==============================] - 10s 126ms/step - loss: 0.0160 - accuracy: 0.0352 - val_loss: 0.3174 - val_accuracy: 0.0834\n",
      "Epoch 34/50\n",
      "82/82 [==============================] - 10s 126ms/step - loss: 0.0139 - accuracy: 0.0328 - val_loss: 0.3254 - val_accuracy: 0.0726\n",
      "Epoch 35/50\n",
      "82/82 [==============================] - 10s 126ms/step - loss: 0.0157 - accuracy: 0.0336 - val_loss: 0.3260 - val_accuracy: 0.0725\n",
      "Epoch 36/50\n",
      "82/82 [==============================] - 10s 126ms/step - loss: 0.0148 - accuracy: 0.0351 - val_loss: 0.3468 - val_accuracy: 0.0726\n",
      "Epoch 37/50\n",
      "82/82 [==============================] - 10s 126ms/step - loss: 0.0162 - accuracy: 0.0321 - val_loss: 0.3368 - val_accuracy: 0.0725\n",
      "Epoch 38/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0120 - accuracy: 0.0337 - val_loss: 0.3568 - val_accuracy: 0.0725\n",
      "Epoch 39/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0133 - accuracy: 0.0364 - val_loss: 0.3428 - val_accuracy: 0.0725\n",
      "Epoch 40/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0128 - accuracy: 0.0309 - val_loss: 0.3439 - val_accuracy: 0.0723\n",
      "Epoch 41/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0072 - accuracy: 0.0348 - val_loss: 0.3318 - val_accuracy: 0.0768\n",
      "Epoch 42/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0176 - accuracy: 0.0333 - val_loss: 0.3380 - val_accuracy: 0.0726\n",
      "Epoch 43/50\n",
      "82/82 [==============================] - 10s 128ms/step - loss: 0.0166 - accuracy: 0.0337 - val_loss: 0.3727 - val_accuracy: 0.0721\n",
      "Epoch 44/50\n",
      "82/82 [==============================] - 11s 133ms/step - loss: 0.0275 - accuracy: 0.0379 - val_loss: 0.3607 - val_accuracy: 0.0722\n",
      "Epoch 45/50\n",
      "82/82 [==============================] - 11s 131ms/step - loss: 0.0166 - accuracy: 0.0318 - val_loss: 0.3827 - val_accuracy: 0.0724\n",
      "Epoch 46/50\n",
      "82/82 [==============================] - 10s 126ms/step - loss: 0.0108 - accuracy: 0.0353 - val_loss: 0.3914 - val_accuracy: 0.0724\n",
      "Epoch 47/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0158 - accuracy: 0.0341 - val_loss: 0.3870 - val_accuracy: 0.0724\n",
      "Epoch 48/50\n",
      "82/82 [==============================] - 10s 126ms/step - loss: 0.0153 - accuracy: 0.0312 - val_loss: 0.3541 - val_accuracy: 0.0724\n",
      "Epoch 49/50\n",
      "82/82 [==============================] - 10s 125ms/step - loss: 0.0142 - accuracy: 0.0339 - val_loss: 0.3872 - val_accuracy: 0.0724\n",
      "Epoch 50/50\n",
      "82/82 [==============================] - 10s 126ms/step - loss: 0.0149 - accuracy: 0.0342 - val_loss: 0.3765 - val_accuracy: 0.0724\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "history = model.fit(train_encodings, epochs=50, batch_size=8, validation_data=test_encodings, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at tf-bart-base-quadruplet.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "save_path = 'tf-bart-base-quadruplet'\n",
    "loaded_model = TFBartForConditionalGeneration.from_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masukkan:  In the summer months , the back garden area is really nice \n",
      "Label sebenarnya:  (back garden area, nice, POS, ambience general)\n",
      "Hasil prediksi model:  </s><s>(back garden area, nice, POS, ambience general)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "------------------------------------------------------------\n",
      "Masukkan:  Add to that great service and great food at a reasonable price and you have yourself the beginning of a great evening \n",
      "Label sebenarnya:  (service, great, POS, service general);(food, great, POS, food prices)\n",
      "Hasil prediksi model:  </s><s>(service, great, POS, service general);(food, great at POS, food quality)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "------------------------------------------------------------\n",
      "Masukkan:  This place is not worth the prices \n",
      "Label sebenarnya:  (place, not worth the prices, NEG, restaurant prices)\n",
      "Hasil prediksi model:  </s><s>(place, not worth the prices, NEG, restaurant general)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "------------------------------------------------------------\n",
      "Masukkan:  The service is awful \n",
      "Label sebenarnya:  (service, awful, NEG, service general)\n",
      "Hasil prediksi model:  </s><s>(service, awful, NEG, service general)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "------------------------------------------------------------\n",
      "Masukkan:  The service was fast and friendly and the food was very tasty and they had the best hot sauce to add to your meals \n",
      "Label sebenarnya:  (service, fast, POS, service general);(service, friendly, POS, service general);(food, tasty, POS, food quality);(hot sauce, best, POS, food quality)\n",
      "Hasil prediksi model:  </s><s>(service, fast, POS, service general);(food, tasty, NEG, food quality)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    idx = random.randint(0, len(x_test))\n",
    "    input_text =  x_test[idx]\n",
    "    encoded_query = dict(tokenizer(input_text, padding=True, truncation=True, return_tensors=\"tf\"))\n",
    "    input_ids = encoded_query[\"input_ids\"]\n",
    "    attention_mask = encoded_query[\"attention_mask\"]\n",
    "    generated_answer = loaded_model.generate(input_ids, attention_mask=attention_mask, max_length=150)\n",
    "    decoded_answer = tokenizer.decode(generated_answer.numpy()[0])\n",
    "\n",
    "    print('Masukkan: ',x_test[idx])\n",
    "    print('Label sebenarnya: ',y_test[idx])\n",
    "    print('Hasil prediksi model: ',decoded_answer)\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

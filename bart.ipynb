{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, TFBartForConditionalGeneration\n",
    "from transformers.models.bart.modeling_bart import shift_tokens_right\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the T5 tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "#model = TFBartForConditionalGeneration.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/Kuliah/S2/Tesis/Code/Generative-ABSA-main/data/quadruplet/rest15/all_data.csv')\n",
    "X = df['input'].values.tolist()\n",
    "y = df['quadruplet_label'].values.tolist()\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(x, y, pad_id):\n",
    "    input_encodings = dict(tokenizer(x, padding=True, truncation=True, return_tensors=\"pt\"))\n",
    "    target_encodings = dict(tokenizer(y, padding=True, truncation=True, return_tensors=\"pt\"))\n",
    "    labels = target_encodings['input_ids']\n",
    "    #decoder_start_token_id=0 biar <s> yang nandain start dari tokenisasi\n",
    "    decoder_input_ids = shift_tokens_right(labels, pad_id, 0)\n",
    "    labels = labels.masked_fill_(labels == pad_id, -100)\n",
    "    encodings = {\n",
    "        'input_ids': tf.convert_to_tensor(input_encodings['input_ids'].numpy()),\n",
    "        'attention_mask': tf.convert_to_tensor(input_encodings['attention_mask'].numpy()),\n",
    "        'decoder_input_ids': tf.convert_to_tensor(decoder_input_ids.numpy()),\n",
    "        'labels': tf.convert_to_tensor(labels.numpy()),\n",
    "    }\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18524/2841323910.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpad_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "pad_id = model.config.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = make_data(x_train, y_train, pad_id)\n",
    "test_encodings = make_data(x_test, y_test, pad_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(656, 56), dtype=int64, numpy=\n",
       " array([[    0,   133,  5765, ...,     1,     1,     1],\n",
       "        [    0,   133, 28287, ...,     1,     1,     1],\n",
       "        [    0,   133,  3202, ...,     1,     1,     1],\n",
       "        ...,\n",
       "        [    0,   133,   813, ...,     1,     1,     1],\n",
       "        [    0,  2387, 25537, ...,     1,     1,     1],\n",
       "        [    0, 24989,  3958, ...,     1,     1,     1]], dtype=int64)>,\n",
       " 'attention_mask': <tf.Tensor: shape=(656, 56), dtype=int64, numpy=\n",
       " array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]], dtype=int64)>,\n",
       " 'decoder_input_ids': <tf.Tensor: shape=(656, 77), dtype=int64, numpy=\n",
       " array([[   0,    0, 1640, ...,    1,    1,    1],\n",
       "        [   0,    0, 1640, ...,    1,    1,    1],\n",
       "        [   0,    0, 1640, ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [   0,    0, 1640, ...,    1,    1,    1],\n",
       "        [   0,    0, 1640, ...,    1,    1,    1],\n",
       "        [   0,    0, 1640, ...,    1,    1,    1]], dtype=int64)>,\n",
       " 'labels': <tf.Tensor: shape=(656, 77), dtype=int64, numpy=\n",
       " array([[    0,  1640, 45801, ...,  -100,  -100,  -100],\n",
       "        [    0,  1640,    29, ...,  -100,  -100,  -100],\n",
       "        [    0,  1640,  1090, ...,  -100,  -100,  -100],\n",
       "        ...,\n",
       "        [    0,  1640, 17360, ...,  -100,  -100,  -100],\n",
       "        [    0,  1640,  6406, ...,  -100,  -100,  -100],\n",
       "        [    0,  1640,   642, ...,  -100,  -100,  -100]], dtype=int64)>}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'tf-bart-base-quadruplet'\n",
    "checkpoint_filepath = save_path + \"/\" + \"T5-{epoch:04d}-{val_loss:.4f}.ckpt\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "callbacks = [model_checkpoint_callback] \n",
    "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "# Define the fine-tuning parameters\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "model.compile(optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4945 - accuracy: 0.0309"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model.shared_layer_call_fn, model.shared_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn while saving (showing 5 of 414). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0001-0.2956.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0001-0.2956.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 68s 836ms/step - loss: 0.4945 - accuracy: 0.0309 - val_loss: 0.2956 - val_accuracy: 0.0491\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3639 - accuracy: 0.0361"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model.shared_layer_call_fn, model.shared_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn while saving (showing 5 of 414). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0002-0.2814.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0002-0.2814.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 65s 795ms/step - loss: 0.3639 - accuracy: 0.0361 - val_loss: 0.2814 - val_accuracy: 0.0856\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2833 - accuracy: 0.0323"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model.shared_layer_call_fn, model.shared_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn while saving (showing 5 of 414). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0003-0.2623.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0003-0.2623.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 62s 763ms/step - loss: 0.2833 - accuracy: 0.0323 - val_loss: 0.2623 - val_accuracy: 0.0534\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.0319"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model.shared_layer_call_fn, model.shared_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn while saving (showing 5 of 414). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0004-0.2467.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0004-0.2467.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 63s 771ms/step - loss: 0.2147 - accuracy: 0.0319 - val_loss: 0.2467 - val_accuracy: 0.0749\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - 14s 170ms/step - loss: 0.1792 - accuracy: 0.0341 - val_loss: 0.2530 - val_accuracy: 0.0724\n",
      "Epoch 6/50\n",
      "82/82 [==============================] - 14s 168ms/step - loss: 0.1473 - accuracy: 0.0310 - val_loss: 0.2522 - val_accuracy: 0.0724\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - 14s 169ms/step - loss: 0.1225 - accuracy: 0.0325 - val_loss: 0.2493 - val_accuracy: 0.0727\n",
      "Epoch 8/50\n",
      "82/82 [==============================] - 14s 170ms/step - loss: 0.1079 - accuracy: 0.0382 - val_loss: 0.2556 - val_accuracy: 0.0492\n",
      "Epoch 9/50\n",
      "82/82 [==============================] - 14s 171ms/step - loss: 0.0899 - accuracy: 0.0349 - val_loss: 0.2692 - val_accuracy: 0.0726\n",
      "Epoch 10/50\n",
      "82/82 [==============================] - 14s 171ms/step - loss: 0.0744 - accuracy: 0.0342 - val_loss: 0.2640 - val_accuracy: 0.0492\n",
      "Epoch 11/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.0334"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model.shared_layer_call_fn, model.shared_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn while saving (showing 5 of 414). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0011-0.2421.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-bart-base-quadruplet\\T5-0011-0.2421.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 66s 816ms/step - loss: 0.0667 - accuracy: 0.0334 - val_loss: 0.2421 - val_accuracy: 0.0492\n",
      "Epoch 12/50\n",
      "82/82 [==============================] - 14s 169ms/step - loss: 0.0651 - accuracy: 0.0359 - val_loss: 0.2682 - val_accuracy: 0.0792\n",
      "Epoch 13/50\n",
      "82/82 [==============================] - 14s 167ms/step - loss: 0.0529 - accuracy: 0.0341 - val_loss: 0.2822 - val_accuracy: 0.0513\n",
      "Epoch 14/50\n",
      "82/82 [==============================] - 14s 168ms/step - loss: 0.0474 - accuracy: 0.0366 - val_loss: 0.3022 - val_accuracy: 0.0726\n",
      "Epoch 15/50\n",
      "82/82 [==============================] - 14s 168ms/step - loss: 0.0496 - accuracy: 0.0333 - val_loss: 0.2973 - val_accuracy: 0.0726\n",
      "Epoch 16/50\n",
      "82/82 [==============================] - 14s 167ms/step - loss: 0.0454 - accuracy: 0.0350 - val_loss: 0.2898 - val_accuracy: 0.0725\n",
      "Epoch 17/50\n",
      "82/82 [==============================] - 14s 168ms/step - loss: 0.0322 - accuracy: 0.0348 - val_loss: 0.2981 - val_accuracy: 0.0724\n",
      "Epoch 18/50\n",
      "82/82 [==============================] - 15s 187ms/step - loss: 0.0410 - accuracy: 0.0315 - val_loss: 0.3078 - val_accuracy: 0.0490\n",
      "Epoch 19/50\n",
      "82/82 [==============================] - 16s 190ms/step - loss: 0.0356 - accuracy: 0.0350 - val_loss: 0.3181 - val_accuracy: 0.0726\n",
      "Epoch 20/50\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 0.0331 - accuracy: 0.0347 - val_loss: 0.3021 - val_accuracy: 0.0727\n",
      "Epoch 21/50\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 0.0315 - accuracy: 0.0386 - val_loss: 0.3252 - val_accuracy: 0.0490\n",
      "Epoch 22/50\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 0.0495 - accuracy: 0.0359 - val_loss: 0.3060 - val_accuracy: 0.0492\n",
      "Epoch 23/50\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 0.0395 - accuracy: 0.0334 - val_loss: 0.3033 - val_accuracy: 0.0723\n",
      "Epoch 24/50\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 0.0308 - accuracy: 0.0342 - val_loss: 0.3202 - val_accuracy: 0.0725\n",
      "Epoch 25/50\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 0.0252 - accuracy: 0.0316 - val_loss: 0.3113 - val_accuracy: 0.0734\n",
      "Epoch 26/50\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 0.0261 - accuracy: 0.0319 - val_loss: 0.3187 - val_accuracy: 0.0723\n",
      "Epoch 27/50\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 0.0180 - accuracy: 0.0347 - val_loss: 0.3328 - val_accuracy: 0.0724\n",
      "Epoch 28/50\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 0.0229 - accuracy: 0.0343 - val_loss: 0.3526 - val_accuracy: 0.0724\n",
      "Epoch 29/50\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 0.0172 - accuracy: 0.0329 - val_loss: 0.3098 - val_accuracy: 0.0488\n",
      "Epoch 30/50\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 0.0144 - accuracy: 0.0316 - val_loss: 0.3162 - val_accuracy: 0.0491\n",
      "Epoch 31/50\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 0.0130 - accuracy: 0.0341 - val_loss: 0.3239 - val_accuracy: 0.0834\n",
      "Epoch 32/50\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 0.0152 - accuracy: 0.0318 - val_loss: 0.3296 - val_accuracy: 0.0726\n",
      "Epoch 33/50\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 0.0152 - accuracy: 0.0381 - val_loss: 0.3373 - val_accuracy: 0.0490\n",
      "Epoch 34/50\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 0.0167 - accuracy: 0.0364 - val_loss: 0.3468 - val_accuracy: 0.0489\n",
      "Epoch 35/50\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 0.0174 - accuracy: 0.0351 - val_loss: 0.3584 - val_accuracy: 0.0724\n",
      "Epoch 36/50\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 0.0111 - accuracy: 0.0328 - val_loss: 0.3434 - val_accuracy: 0.0726\n",
      "Epoch 37/50\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 0.0137 - accuracy: 0.0335 - val_loss: 0.3296 - val_accuracy: 0.0490\n",
      "Epoch 38/50\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 0.0102 - accuracy: 0.0390 - val_loss: 0.3671 - val_accuracy: 0.0724\n",
      "Epoch 39/50\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 0.0122 - accuracy: 0.0354 - val_loss: 0.3589 - val_accuracy: 0.0727\n",
      "Epoch 40/50\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 0.0170 - accuracy: 0.0334 - val_loss: 0.3455 - val_accuracy: 0.0727\n",
      "Epoch 41/50\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 0.0189 - accuracy: 0.0342 - val_loss: 0.3439 - val_accuracy: 0.0727\n",
      "Epoch 42/50\n",
      "82/82 [==============================] - 16s 194ms/step - loss: 0.0221 - accuracy: 0.0319 - val_loss: 0.4053 - val_accuracy: 0.0724\n",
      "Epoch 43/50\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 0.0228 - accuracy: 0.0363 - val_loss: 0.3633 - val_accuracy: 0.0725\n",
      "Epoch 44/50\n",
      "82/82 [==============================] - 14s 172ms/step - loss: 0.0094 - accuracy: 0.0350 - val_loss: 0.3332 - val_accuracy: 0.0726\n",
      "Epoch 45/50\n",
      "82/82 [==============================] - 14s 168ms/step - loss: 0.0105 - accuracy: 0.0339 - val_loss: 0.3657 - val_accuracy: 0.0513\n",
      "Epoch 46/50\n",
      "82/82 [==============================] - 14s 168ms/step - loss: 0.0093 - accuracy: 0.0362 - val_loss: 0.3482 - val_accuracy: 0.0491\n",
      "Epoch 47/50\n",
      "82/82 [==============================] - 14s 168ms/step - loss: 0.0073 - accuracy: 0.0315 - val_loss: 0.3887 - val_accuracy: 0.0620\n",
      "Epoch 48/50\n",
      "82/82 [==============================] - 14s 168ms/step - loss: 0.0088 - accuracy: 0.0368 - val_loss: 0.3661 - val_accuracy: 0.0532\n",
      "Epoch 49/50\n",
      "82/82 [==============================] - 14s 167ms/step - loss: 0.0094 - accuracy: 0.0317 - val_loss: 0.3651 - val_accuracy: 0.0488\n",
      "Epoch 50/50\n",
      "82/82 [==============================] - 14s 168ms/step - loss: 0.0118 - accuracy: 0.0336 - val_loss: 0.3879 - val_accuracy: 0.0808\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "history = model.fit(train_encodings, epochs=50, batch_size=8, validation_data=test_encodings, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall , decent food at a good price , with friendly people \n",
      "(food, decent, POS, food prices);(people, friendly, POS, service general)\n",
      "</s><s>(food, decent, NEU, food prices);(people, friendly, POS</s>\n"
     ]
    }
   ],
   "source": [
    "idx = random.randint(0, len(x_test))\n",
    "input_text =  x_test[idx]\n",
    "encoded_query = dict(tokenizer(input_text, padding=True, truncation=True, return_tensors=\"tf\"))\n",
    "input_ids = encoded_query[\"input_ids\"]\n",
    "attention_mask = encoded_query[\"attention_mask\"]\n",
    "generated_answer = model.generate(input_ids, attention_mask=attention_mask)\n",
    "decoded_answer = tokenizer.decode(generated_answer.numpy()[0])\n",
    "\n",
    "print(x_test[idx])\n",
    "print(y_test[idx])\n",
    "print(decoded_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

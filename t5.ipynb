{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danendra\\anaconda3\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set up the T5 tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "# Load the pre-trained T5 model\n",
    "#model = TFT5ForConditionalGeneration.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_id = model.config.pad_token_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>triplet</th>\n",
       "      <th>label</th>\n",
       "      <th>quadruplet_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>(place,good,NEG)</td>\n",
       "      <td>('place', 'restaurant general', 'negative')</td>\n",
       "      <td>(place, good, NEG, restaurant general)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We , there were four of us , arrived at noon -...</td>\n",
       "      <td>(staff,rude,NEG)</td>\n",
       "      <td>('staff', 'service general', 'negative')</td>\n",
       "      <td>(staff, rude, NEG, service general)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>(food,lousy,NEG);(food,too sweet,NEG);(food,to...</td>\n",
       "      <td>('food', 'food quality', 'negative'), ('portio...</td>\n",
       "      <td>(food, lousy, NEG, food quality);(food, too sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avoid this place</td>\n",
       "      <td>(place,Avoid,NEG)</td>\n",
       "      <td>('place', 'restaurant general', 'negative')</td>\n",
       "      <td>(place, Avoid, NEG, restaurant general)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have eaten at Saul , many times , the food i...</td>\n",
       "      <td>(food,good,POS)</td>\n",
       "      <td>('food', 'food quality', 'positive')</td>\n",
       "      <td>(food, good, POS, food quality)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  Judging from previous posts this used to be a ...   \n",
       "1  We , there were four of us , arrived at noon -...   \n",
       "2  The food was lousy - too sweet or too salty an...   \n",
       "3                                  Avoid this place    \n",
       "4  I have eaten at Saul , many times , the food i...   \n",
       "\n",
       "                                             triplet  \\\n",
       "0                                   (place,good,NEG)   \n",
       "1                                   (staff,rude,NEG)   \n",
       "2  (food,lousy,NEG);(food,too sweet,NEG);(food,to...   \n",
       "3                                  (place,Avoid,NEG)   \n",
       "4                                    (food,good,POS)   \n",
       "\n",
       "                                               label  \\\n",
       "0        ('place', 'restaurant general', 'negative')   \n",
       "1           ('staff', 'service general', 'negative')   \n",
       "2  ('food', 'food quality', 'negative'), ('portio...   \n",
       "3        ('place', 'restaurant general', 'negative')   \n",
       "4               ('food', 'food quality', 'positive')   \n",
       "\n",
       "                                    quadruplet_label  \n",
       "0             (place, good, NEG, restaurant general)  \n",
       "1                (staff, rude, NEG, service general)  \n",
       "2  (food, lousy, NEG, food quality);(food, too sw...  \n",
       "3            (place, Avoid, NEG, restaurant general)  \n",
       "4                    (food, good, POS, food quality)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:/Kuliah/S2/Tesis/Code/Generative-ABSA-main/data/quadruplet/rest15/all_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(x, y, pad_id):\n",
    "    input_encodings = dict(tokenizer(x, padding=True, truncation=True, return_tensors=\"pt\"))\n",
    "    target_encodings = dict(tokenizer(y, padding=True, truncation=True, return_tensors=\"pt\"))\n",
    "    decoder_input_ids = target_encodings['input_ids']\n",
    "    labels = decoder_input_ids.masked_fill_(decoder_input_ids == pad_id, -100)\n",
    "    encodings = {\n",
    "        'input_ids': tf.convert_to_tensor(input_encodings['input_ids'].numpy()),\n",
    "        'attention_mask': tf.convert_to_tensor(input_encodings['attention_mask'].numpy()),\n",
    "        'decoder_input_ids': tf.convert_to_tensor(decoder_input_ids.numpy()),\n",
    "        'labels': tf.convert_to_tensor(labels.numpy()),\n",
    "    }\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test pakai cara bart\n",
    "x = df['input'].values.tolist()\n",
    "y = df['quadruplet_label'].values.tolist()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "# train_inputs = make_data(x_train, y_train, pad_id)\n",
    "# test_inputs = make_data(x_test, y_test, pad_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training data and pre-process it with the tokenizer\n",
    "train_inputs = dict(tokenizer(x_train, padding=True, truncation=True, return_tensors=\"tf\"))\n",
    "train_outputs = dict(tokenizer(y_train, padding=True, truncation=True, return_tensors=\"tf\"))\n",
    "\n",
    "test_inputs = dict(tokenizer(x_test, padding=True, truncation=True, return_tensors=\"tf\"))\n",
    "test_outputs = dict(tokenizer(y_test, padding=True, truncation=True, return_tensors=\"tf\"))\n",
    "\n",
    "train_inputs = {**train_inputs, \"labels\": train_outputs[\"input_ids\"], 'decoder_attention_mask':train_outputs['attention_mask']} \n",
    "test_inputs = {**test_inputs, \"labels\": test_outputs[\"input_ids\"], 'decoder_attention_mask':test_outputs['attention_mask']}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'tf-t5-many-epoch-quadruplet'\n",
    "checkpoint_filepath = save_path + \"/\" + \"T5-{epoch:04d}-{val_loss:.4f}.ckpt\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "callbacks = [model_checkpoint_callback] \n",
    "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "# Define the fine-tuning parameters\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "model.compile(optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 2.0230 - accuracy: 0.8032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0001-1.1564.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0001-1.1564.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 140s 2s/step - loss: 2.0230 - accuracy: 0.8032 - val_loss: 1.1564 - val_accuracy: 0.8881\n",
      "Epoch 2/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.9335"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0002-0.6651.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0002-0.6651.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 119s 1s/step - loss: 0.6854 - accuracy: 0.9335 - val_loss: 0.6651 - val_accuracy: 0.9419\n",
      "Epoch 3/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.9626"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0003-0.3861.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0003-0.3861.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 113s 1s/step - loss: 0.4376 - accuracy: 0.9626 - val_loss: 0.3861 - val_accuracy: 0.9738\n",
      "Epoch 4/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2940 - accuracy: 0.9780"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0004-0.2553.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0004-0.2553.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 118s 1s/step - loss: 0.2940 - accuracy: 0.9780 - val_loss: 0.2553 - val_accuracy: 0.9837\n",
      "Epoch 5/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.9857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0005-0.1871.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0005-0.1871.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 109s 1s/step - loss: 0.2148 - accuracy: 0.9857 - val_loss: 0.1871 - val_accuracy: 0.9904\n",
      "Epoch 6/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.1678 - accuracy: 0.9904"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0006-0.1489.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0006-0.1489.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 113s 1s/step - loss: 0.1678 - accuracy: 0.9904 - val_loss: 0.1489 - val_accuracy: 0.9934\n",
      "Epoch 7/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9929"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0007-0.1298.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0007-0.1298.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 113s 1s/step - loss: 0.1362 - accuracy: 0.9929 - val_loss: 0.1298 - val_accuracy: 0.9948\n",
      "Epoch 8/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9946"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0008-0.1170.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0008-0.1170.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 113s 1s/step - loss: 0.1140 - accuracy: 0.9946 - val_loss: 0.1170 - val_accuracy: 0.9958\n",
      "Epoch 9/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.9960"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0009-0.1095.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0009-0.1095.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 112s 1s/step - loss: 0.1007 - accuracy: 0.9960 - val_loss: 0.1095 - val_accuracy: 0.9962\n",
      "Epoch 10/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9961"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0010-0.1027.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0010-0.1027.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 111s 1s/step - loss: 0.0924 - accuracy: 0.9961 - val_loss: 0.1027 - val_accuracy: 0.9962\n",
      "Epoch 11/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9971"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0011-0.0987.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0011-0.0987.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 113s 1s/step - loss: 0.0825 - accuracy: 0.9971 - val_loss: 0.0987 - val_accuracy: 0.9969\n",
      "Epoch 12/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0012-0.0955.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0012-0.0955.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 116s 1s/step - loss: 0.0751 - accuracy: 0.9976 - val_loss: 0.0955 - val_accuracy: 0.9968\n",
      "Epoch 13/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9980"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0013-0.0918.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0013-0.0918.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 114s 1s/step - loss: 0.0667 - accuracy: 0.9980 - val_loss: 0.0918 - val_accuracy: 0.9969\n",
      "Epoch 14/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0014-0.0908.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0014-0.0908.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 101s 1s/step - loss: 0.0608 - accuracy: 0.9983 - val_loss: 0.0908 - val_accuracy: 0.9967\n",
      "Epoch 15/200\n",
      "82/82 [==============================] - 19s 231ms/step - loss: 0.0576 - accuracy: 0.9984 - val_loss: 0.0921 - val_accuracy: 0.9965\n",
      "Epoch 16/200\n",
      "82/82 [==============================] - 19s 230ms/step - loss: 0.0523 - accuracy: 0.9986 - val_loss: 0.0908 - val_accuracy: 0.9966\n",
      "Epoch 17/200\n",
      "82/82 [==============================] - 19s 230ms/step - loss: 0.0494 - accuracy: 0.9988 - val_loss: 0.0918 - val_accuracy: 0.9966\n",
      "Epoch 18/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9991"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0018-0.0893.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0018-0.0893.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 79s 971ms/step - loss: 0.0454 - accuracy: 0.9991 - val_loss: 0.0893 - val_accuracy: 0.9970\n",
      "Epoch 19/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9992"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0019-0.0850.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0019-0.0850.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 83s 1s/step - loss: 0.0426 - accuracy: 0.9992 - val_loss: 0.0850 - val_accuracy: 0.9972\n",
      "Epoch 20/200\n",
      "82/82 [==============================] - 19s 224ms/step - loss: 0.0396 - accuracy: 0.9993 - val_loss: 0.0864 - val_accuracy: 0.9975\n",
      "Epoch 21/200\n",
      "82/82 [==============================] - 19s 229ms/step - loss: 0.0374 - accuracy: 0.9994 - val_loss: 0.0856 - val_accuracy: 0.9973\n",
      "Epoch 22/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0022-0.0848.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0022-0.0848.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 77s 942ms/step - loss: 0.0354 - accuracy: 0.9995 - val_loss: 0.0848 - val_accuracy: 0.9974\n",
      "Epoch 23/200\n",
      "82/82 [==============================] - 18s 221ms/step - loss: 0.0333 - accuracy: 0.9995 - val_loss: 0.0849 - val_accuracy: 0.9974\n",
      "Epoch 24/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0024-0.0830.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0024-0.0830.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 82s 1s/step - loss: 0.0324 - accuracy: 0.9995 - val_loss: 0.0830 - val_accuracy: 0.9972\n",
      "Epoch 25/200\n",
      "82/82 [==============================] - 18s 221ms/step - loss: 0.0290 - accuracy: 0.9995 - val_loss: 0.0873 - val_accuracy: 0.9973\n",
      "Epoch 26/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_48_layer_call_fn, dropout_48_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1040). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0026-0.0825.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf-t5-many-epoch-quadruplet\\T5-0026-0.0825.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 81s 991ms/step - loss: 0.0294 - accuracy: 0.9996 - val_loss: 0.0825 - val_accuracy: 0.9976\n",
      "Epoch 27/200\n",
      "82/82 [==============================] - 18s 221ms/step - loss: 0.0266 - accuracy: 0.9996 - val_loss: 0.0840 - val_accuracy: 0.9976\n",
      "Epoch 28/200\n",
      "82/82 [==============================] - 18s 221ms/step - loss: 0.0251 - accuracy: 0.9997 - val_loss: 0.0838 - val_accuracy: 0.9976\n",
      "Epoch 29/200\n",
      "82/82 [==============================] - 18s 221ms/step - loss: 0.0238 - accuracy: 0.9998 - val_loss: 0.0871 - val_accuracy: 0.9974\n",
      "Epoch 30/200\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.0223 - accuracy: 0.9997 - val_loss: 0.0856 - val_accuracy: 0.9973\n",
      "Epoch 31/200\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.0206 - accuracy: 0.9998 - val_loss: 0.0862 - val_accuracy: 0.9975\n",
      "Epoch 32/200\n",
      "82/82 [==============================] - 18s 221ms/step - loss: 0.0203 - accuracy: 0.9998 - val_loss: 0.0878 - val_accuracy: 0.9973\n",
      "Epoch 33/200\n",
      "82/82 [==============================] - 18s 221ms/step - loss: 0.0194 - accuracy: 0.9998 - val_loss: 0.0874 - val_accuracy: 0.9973\n",
      "Epoch 34/200\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.0184 - accuracy: 0.9999 - val_loss: 0.0839 - val_accuracy: 0.9973\n",
      "Epoch 35/200\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.0162 - accuracy: 0.9999 - val_loss: 0.0832 - val_accuracy: 0.9977\n",
      "Epoch 36/200\n",
      "82/82 [==============================] - 18s 221ms/step - loss: 0.0168 - accuracy: 0.9999 - val_loss: 0.0841 - val_accuracy: 0.9975\n",
      "Epoch 37/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 0.0156 - accuracy: 0.9999 - val_loss: 0.0859 - val_accuracy: 0.9973\n",
      "Epoch 38/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0147 - accuracy: 0.9999 - val_loss: 0.0901 - val_accuracy: 0.9972\n",
      "Epoch 39/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 0.0145 - accuracy: 0.9999 - val_loss: 0.0867 - val_accuracy: 0.9972\n",
      "Epoch 40/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0132 - accuracy: 0.9999 - val_loss: 0.0877 - val_accuracy: 0.9975\n",
      "Epoch 41/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0130 - accuracy: 0.9999 - val_loss: 0.0864 - val_accuracy: 0.9972\n",
      "Epoch 42/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9973\n",
      "Epoch 43/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0116 - accuracy: 0.9999 - val_loss: 0.0887 - val_accuracy: 0.9975\n",
      "Epoch 44/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0102 - accuracy: 0.9999 - val_loss: 0.0915 - val_accuracy: 0.9972\n",
      "Epoch 45/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9974\n",
      "Epoch 46/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9976\n",
      "Epoch 47/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0090 - accuracy: 0.9999 - val_loss: 0.0917 - val_accuracy: 0.9975\n",
      "Epoch 48/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9975\n",
      "Epoch 49/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0089 - accuracy: 0.9999 - val_loss: 0.0923 - val_accuracy: 0.9976\n",
      "Epoch 50/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9972\n",
      "Epoch 51/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0932 - val_accuracy: 0.9974\n",
      "Epoch 52/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 0.0076 - accuracy: 0.9999 - val_loss: 0.0939 - val_accuracy: 0.9971\n",
      "Epoch 53/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9973\n",
      "Epoch 54/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9972\n",
      "Epoch 55/200\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9975\n",
      "Epoch 56/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9974\n",
      "Epoch 57/200\n",
      "82/82 [==============================] - 18s 221ms/step - loss: 0.0064 - accuracy: 0.9999 - val_loss: 0.0953 - val_accuracy: 0.9972\n",
      "Epoch 58/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9971\n",
      "Epoch 59/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9970\n",
      "Epoch 60/200\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9974\n",
      "Epoch 61/200\n",
      "82/82 [==============================] - 18s 221ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0962 - val_accuracy: 0.9972\n",
      "Epoch 62/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9972\n",
      "Epoch 63/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9970\n",
      "Epoch 64/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9972\n",
      "Epoch 65/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9977\n",
      "Epoch 66/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9971\n",
      "Epoch 67/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9971\n",
      "Epoch 68/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 0.9970\n",
      "Epoch 69/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9969\n",
      "Epoch 70/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9972\n",
      "Epoch 71/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9972\n",
      "Epoch 72/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9973\n",
      "Epoch 73/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9971\n",
      "Epoch 74/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9968\n",
      "Epoch 75/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9969\n",
      "Epoch 76/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 0.9970\n",
      "Epoch 77/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9971\n",
      "Epoch 78/200\n",
      "82/82 [==============================] - 18s 225ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9974\n",
      "Epoch 79/200\n",
      "82/82 [==============================] - 19s 226ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9971\n",
      "Epoch 80/200\n",
      "82/82 [==============================] - 19s 229ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9976\n",
      "Epoch 81/200\n",
      "82/82 [==============================] - 19s 229ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.1076 - val_accuracy: 0.9973\n",
      "Epoch 82/200\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9971\n",
      "Epoch 83/200\n",
      "82/82 [==============================] - 18s 225ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 0.9969\n",
      "Epoch 84/200\n",
      "82/82 [==============================] - 19s 234ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9971\n",
      "Epoch 85/200\n",
      "82/82 [==============================] - 19s 236ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9975\n",
      "Epoch 86/200\n",
      "82/82 [==============================] - 19s 235ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 0.9974\n",
      "Epoch 87/200\n",
      "82/82 [==============================] - 19s 231ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9974\n",
      "Epoch 88/200\n",
      "82/82 [==============================] - 19s 234ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9980\n",
      "Epoch 89/200\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9971\n",
      "Epoch 90/200\n",
      "82/82 [==============================] - 19s 233ms/step - loss: 0.0058 - accuracy: 0.9996 - val_loss: 0.1119 - val_accuracy: 0.9971\n",
      "Epoch 91/200\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9972\n",
      "Epoch 92/200\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 0.9972\n",
      "Epoch 93/200\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9969\n",
      "Epoch 94/200\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 0.9969\n",
      "Epoch 95/200\n",
      "82/82 [==============================] - 19s 233ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9968\n",
      "Epoch 96/200\n",
      "82/82 [==============================] - 19s 233ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1191 - val_accuracy: 0.9968\n",
      "Epoch 97/200\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9965\n",
      "Epoch 98/200\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9973\n",
      "Epoch 99/200\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9970\n",
      "Epoch 100/200\n",
      "82/82 [==============================] - 19s 231ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9971\n",
      "Epoch 101/200\n",
      "82/82 [==============================] - 19s 229ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9972\n",
      "Epoch 102/200\n",
      "82/82 [==============================] - 19s 230ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9970\n",
      "Epoch 103/200\n",
      "82/82 [==============================] - 19s 235ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 0.9968\n",
      "Epoch 104/200\n",
      "82/82 [==============================] - 19s 233ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9969\n",
      "Epoch 105/200\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9971\n",
      "Epoch 106/200\n",
      "82/82 [==============================] - 19s 235ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9971\n",
      "Epoch 107/200\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9966\n",
      "Epoch 108/200\n",
      "82/82 [==============================] - 20s 239ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9972\n",
      "Epoch 109/200\n",
      "82/82 [==============================] - 20s 238ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1165 - val_accuracy: 0.9969\n",
      "Epoch 110/200\n",
      "82/82 [==============================] - 20s 245ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.1185 - val_accuracy: 0.9973\n",
      "Epoch 111/200\n",
      "82/82 [==============================] - 21s 252ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9972\n",
      "Epoch 112/200\n",
      "82/82 [==============================] - 20s 243ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9971\n",
      "Epoch 113/200\n",
      "82/82 [==============================] - 19s 230ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 0.9967\n",
      "Epoch 114/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9969\n",
      "Epoch 115/200\n",
      "82/82 [==============================] - 19s 228ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9970\n",
      "Epoch 116/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9969\n",
      "Epoch 117/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 7.7832e-04 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9970\n",
      "Epoch 118/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 6.8473e-04 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 0.9966\n",
      "Epoch 119/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9971\n",
      "Epoch 120/200\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9970\n",
      "Epoch 121/200\n",
      "82/82 [==============================] - 18s 226ms/step - loss: 8.8846e-04 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9971\n",
      "Epoch 122/200\n",
      "82/82 [==============================] - 18s 225ms/step - loss: 7.5899e-04 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 0.9969\n",
      "Epoch 123/200\n",
      "82/82 [==============================] - 18s 224ms/step - loss: 6.9718e-04 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9969\n",
      "Epoch 124/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 7.6226e-04 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9965\n",
      "Epoch 125/200\n",
      "82/82 [==============================] - 18s 226ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9968\n",
      "Epoch 126/200\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9967\n",
      "Epoch 127/200\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9968\n",
      "Epoch 128/200\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9967\n",
      "Epoch 129/200\n",
      "82/82 [==============================] - 19s 234ms/step - loss: 7.0367e-04 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9974\n",
      "Epoch 130/200\n",
      "82/82 [==============================] - 19s 230ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9972\n",
      "Epoch 131/200\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9963\n",
      "Epoch 132/200\n",
      "82/82 [==============================] - 19s 229ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9966\n",
      "Epoch 133/200\n",
      "82/82 [==============================] - 19s 229ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9965\n",
      "Epoch 134/200\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9972\n",
      "Epoch 135/200\n",
      "82/82 [==============================] - 18s 216ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9971\n",
      "Epoch 136/200\n",
      "82/82 [==============================] - 18s 216ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9970\n",
      "Epoch 137/200\n",
      "82/82 [==============================] - 18s 218ms/step - loss: 7.1534e-04 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9963\n",
      "Epoch 138/200\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 8.1063e-04 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9964\n",
      "Epoch 139/200\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 6.1319e-04 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9965\n",
      "Epoch 140/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 5.3327e-04 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9965\n",
      "Epoch 141/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 5.6320e-04 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9967\n",
      "Epoch 142/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9968\n",
      "Epoch 143/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9965\n",
      "Epoch 144/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 8.3680e-04 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9964\n",
      "Epoch 145/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 6.8930e-04 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.9971\n",
      "Epoch 146/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 8.9328e-04 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9969\n",
      "Epoch 147/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 6.5142e-04 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9969\n",
      "Epoch 148/200\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.9976\n",
      "Epoch 149/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 7.6500e-04 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9970\n",
      "Epoch 150/200\n",
      "82/82 [==============================] - 18s 224ms/step - loss: 6.1244e-04 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9964\n",
      "Epoch 151/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.1341 - val_accuracy: 0.9967\n",
      "Epoch 152/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 7.9502e-04 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9969\n",
      "Epoch 153/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 9.1507e-04 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9967\n",
      "Epoch 154/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9968\n",
      "Epoch 155/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 9.2389e-04 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9969\n",
      "Epoch 156/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 5.7960e-04 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9968\n",
      "Epoch 157/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 7.2740e-04 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9966\n",
      "Epoch 158/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 7.3309e-04 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9971\n",
      "Epoch 159/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 5.3383e-04 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9970\n",
      "Epoch 160/200\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9962\n",
      "Epoch 161/200\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 7.0043e-04 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9965\n",
      "Epoch 162/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 3.8661e-04 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9962\n",
      "Epoch 163/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 5.4422e-04 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9962\n",
      "Epoch 164/200\n",
      "82/82 [==============================] - 19s 228ms/step - loss: 7.8901e-04 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9970\n",
      "Epoch 165/200\n",
      "82/82 [==============================] - 19s 228ms/step - loss: 4.2361e-04 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9971\n",
      "Epoch 166/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 6.1533e-04 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9968\n",
      "Epoch 167/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 5.0608e-04 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9966\n",
      "Epoch 168/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 4.6097e-04 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9970\n",
      "Epoch 169/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 5.9429e-04 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9968\n",
      "Epoch 170/200\n",
      "82/82 [==============================] - 19s 231ms/step - loss: 8.8302e-04 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9965\n",
      "Epoch 171/200\n",
      "82/82 [==============================] - 19s 230ms/step - loss: 5.3756e-04 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 0.9966\n",
      "Epoch 172/200\n",
      "82/82 [==============================] - 19s 228ms/step - loss: 7.9192e-04 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9960\n",
      "Epoch 173/200\n",
      "82/82 [==============================] - 19s 228ms/step - loss: 2.8118e-04 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9964\n",
      "Epoch 174/200\n",
      "82/82 [==============================] - 19s 228ms/step - loss: 4.1520e-04 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9964\n",
      "Epoch 175/200\n",
      "82/82 [==============================] - 18s 221ms/step - loss: 4.7595e-04 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9963\n",
      "Epoch 176/200\n",
      "82/82 [==============================] - 19s 229ms/step - loss: 4.7382e-04 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9968\n",
      "Epoch 177/200\n",
      "82/82 [==============================] - 19s 231ms/step - loss: 6.7206e-04 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9965\n",
      "Epoch 178/200\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 6.9302e-04 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9971\n",
      "Epoch 179/200\n",
      "82/82 [==============================] - 19s 234ms/step - loss: 7.3584e-04 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9968\n",
      "Epoch 180/200\n",
      "82/82 [==============================] - 19s 228ms/step - loss: 6.2544e-04 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9966\n",
      "Epoch 181/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 7.5645e-04 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9969\n",
      "Epoch 182/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 5.9075e-04 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9966\n",
      "Epoch 183/200\n",
      "82/82 [==============================] - 19s 228ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9965\n",
      "Epoch 184/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 8.4251e-04 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9970\n",
      "Epoch 185/200\n",
      "82/82 [==============================] - 19s 228ms/step - loss: 9.4528e-04 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9968\n",
      "Epoch 186/200\n",
      "82/82 [==============================] - 19s 230ms/step - loss: 5.4237e-04 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.9969\n",
      "Epoch 187/200\n",
      "82/82 [==============================] - 19s 229ms/step - loss: 6.4904e-04 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.9964\n",
      "Epoch 188/200\n",
      "82/82 [==============================] - 19s 230ms/step - loss: 5.9234e-04 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9968\n",
      "Epoch 189/200\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 6.5380e-04 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 0.9968\n",
      "Epoch 190/200\n",
      "82/82 [==============================] - 19s 229ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.1287 - val_accuracy: 0.9968\n",
      "Epoch 191/200\n",
      "82/82 [==============================] - 18s 225ms/step - loss: 2.2045e-04 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9968\n",
      "Epoch 192/200\n",
      "82/82 [==============================] - 19s 230ms/step - loss: 4.1607e-04 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9969\n",
      "Epoch 193/200\n",
      "82/82 [==============================] - 19s 229ms/step - loss: 7.4365e-04 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9967\n",
      "Epoch 194/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 5.1567e-04 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9967\n",
      "Epoch 195/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 5.6382e-04 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9969\n",
      "Epoch 196/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 3.6894e-04 - accuracy: 1.0000 - val_loss: 0.1312 - val_accuracy: 0.9969\n",
      "Epoch 197/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 5.3846e-04 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 0.9969\n",
      "Epoch 198/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 5.7737e-04 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9969\n",
      "Epoch 199/200\n",
      "82/82 [==============================] - 19s 230ms/step - loss: 3.6150e-04 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9969\n",
      "Epoch 200/200\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 2.7584e-04 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9966\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "history = model.fit(x = train_inputs, epochs=200, batch_size=8, callbacks=callbacks,\n",
    "validation_data=test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at tf-t5-many-epoch-quadruplet.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "save_path = 'tf-t5-many-epoch-quadruplet'\n",
    "loaded_model = TFT5ForConditionalGeneration.from_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masukkan:  The place is beautiful \n",
      "Label sebenarnya:  (place, beautiful, POS, ambience general)\n",
      "Hasil prediksi model:  <pad> (place, beautiful, POS, ambience general)</s>\n",
      "------------------------------------------------------------\n",
      "Masukkan:  I fell in love with the egg noodles in the beef broth with shrimp dumplings and slices of BBQ roast pork \n",
      "Label sebenarnya:  (egg noodles in the beef broth with shrimp dumplings and slices of BBQ roast pork, love, POS, food quality)\n",
      "Hasil prediksi model:  <pad> (egg noodles in the beef broth with shrimp dumplings and slices of BBQ roast pork, fell in love, POS, food quality)</s>\n",
      "------------------------------------------------------------\n",
      "Masukkan:  The atmosphere is nothing special , but it feels like a Sushi establishment in Tokyo \n",
      "Label sebenarnya:  (atmosphere, nothing special, POS, ambience general)\n",
      "Hasil prediksi model:  <pad> (atmosphere, nothing special, NEU, ambience general)</s>\n",
      "------------------------------------------------------------\n",
      "Masukkan:  The place 's decor and hidden bathrooms made for a good laugh \n",
      "Label sebenarnya:  (decor, good laugh, POS, ambience general);(hidden bathrooms, good laugh, POS, ambience general)\n",
      "Hasil prediksi model:  <pad> (decor, good, POS, ambience general);(bathrooms, hidden, POS, ambience general)</s>\n",
      "------------------------------------------------------------\n",
      "Masukkan:  The exotic food is beautifully presented and is a delight in delicious combinations \n",
      "Label sebenarnya:  (exotic food, beautifully presented, POS, food quality);(exotic food, delight, POS, food quality)\n",
      "Hasil prediksi model:  <pad> (exotic food, beautifully presented, POS, food style_options);(combination, delicious, POS, food style_options)</s>\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    idx = random.randint(0, len(x_test))\n",
    "    input_text =  x_test[idx]\n",
    "    encoded_query = dict(tokenizer(input_text, padding=True, truncation=True, return_tensors=\"tf\"))\n",
    "    input_ids = encoded_query[\"input_ids\"]\n",
    "    attention_mask = encoded_query[\"attention_mask\"]\n",
    "    generated_answer = loaded_model.generate(input_ids, attention_mask=attention_mask, max_length=150)\n",
    "    decoded_answer = tokenizer.decode(generated_answer.numpy()[0])\n",
    "\n",
    "    print('Masukkan: ',x_test[idx])\n",
    "    print('Label sebenarnya: ',y_test[idx])\n",
    "    print('Hasil prediksi model: ',decoded_answer)\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danendra\\anaconda3\\lib\\site-packages\\transformers\\generation\\tf_utils.py:702: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pred_quadruplet = []\n",
    "for i in range(len(x_test)):\n",
    "    input_text =  x_test[i]\n",
    "    encoded_query = dict(tokenizer(input_text, padding=True, truncation=True, return_tensors=\"tf\"))\n",
    "    input_ids = encoded_query[\"input_ids\"]\n",
    "    attention_mask = encoded_query[\"attention_mask\"]\n",
    "    generated_answer = loaded_model.generate(input_ids, attention_mask=attention_mask)\n",
    "    decoded_answer = tokenizer.decode(generated_answer.numpy()[0])\n",
    "    pred_quadruplet.append(decoded_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\n",
    "    'input' : x_test,\n",
    "    'output': y_test,\n",
    "    'predicted' : pred_quadruplet\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('rest15_quadruplet.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract quadruplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quadruplet(label):\n",
    "    sample = [quadruplet.replace('(', '[').replace(')', ']') for quadruplet in label.split(';')]\n",
    "    sample = [re.findall('\\[(.*?)\\]', quadruplet) for quadruplet in sample]\n",
    "    quadruplets = []\n",
    "    for quadruplet in sample:\n",
    "        #untuk menghindari quadruplet kosong dari label hasil prediksi\n",
    "        if quadruplet:\n",
    "            quadruplet = quadruplet[0].split(',')\n",
    "            quadruplets.append(tuple(quadruplet))\n",
    "    return quadruplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1_scores(pred_pt, gold_pt):\n",
    "    \"\"\"\n",
    "    Function to compute F1 scores with pred and gold pairs/triplets\n",
    "    The input needs to be already processed\n",
    "    \"\"\"\n",
    "    # number of true postive, gold standard, predicted aspect terms\n",
    "    n_tp, n_gold, n_pred = 0, 0, 0\n",
    "\n",
    "    for i in range(len(pred_pt)):\n",
    "        n_gold += len(gold_pt[i])\n",
    "        n_pred += len(pred_pt[i])\n",
    "\n",
    "        for t in pred_pt[i]:\n",
    "            if t in gold_pt[i]:\n",
    "                n_tp += 1\n",
    "\n",
    "    precision = float(n_tp) / float(n_pred) if n_pred != 0 else 0\n",
    "    recall = float(n_tp) / float(n_gold) if n_gold != 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision != 0 or recall != 0 else 0\n",
    "    scores = {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('service', ' quick', ' POS', ' service general')]\n",
      "[('service', ' quick', ' POS', ' service general'), ('service', ' friendly', ' POS', ' service general')]\n"
     ]
    }
   ],
   "source": [
    "idx = random.randint(0, len(x_test))\n",
    "print(extract_quadruplet(pred_quadruplet[idx]))\n",
    "print(extract_quadruplet(y_test[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.25, 'recall': 0.25, 'f1': 0.25}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = random.randint(0, len(x_test))\n",
    "pred_label = extract_quadruplet(pred_quadruplet[idx])\n",
    "true_label = extract_quadruplet(y_test[idx])\n",
    "compute_f1_scores(pred_label, true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(\"lewenstein\", \"levenshtein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 'b', 'c')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = ['a', 'b', 'c']\n",
    "tuple(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4179a95aa5b49abc81a1f9774c9389b2d4eba524b70fc2f22d886502bea2eb9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
